{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"acvr provides frame-accurate video access with an array-style interface. It is built on PyAV and focuses on reliable random access for variable-frame-rate assets. Highlights Array-style access ( reader[100] ) for frames Iteration over frames ( for frame in reader ) Context manager support ( with VideoReader(path) as reader ) Accurate seeking using timestamps and keyframe indexes Accurate, fast, and scrub read modes for latency/precision tradeoffs Optional LRU caches for decoded frames and scrub keyframe buckets Installation pip install acvr For development extras (OpenCV + pytest): pip install acvr[dev]","title":"Home"},{"location":"#highlights","text":"Array-style access ( reader[100] ) for frames Iteration over frames ( for frame in reader ) Context manager support ( with VideoReader(path) as reader ) Accurate seeking using timestamps and keyframe indexes Accurate, fast, and scrub read modes for latency/precision tradeoffs Optional LRU caches for decoded frames and scrub keyframe buckets","title":"Highlights"},{"location":"#installation","text":"pip install acvr For development extras (OpenCV + pytest): pip install acvr[dev]","title":"Installation"},{"location":"api/","text":"VideoReader High-level video reader with array-style access. Source code in acvr/reader.py class VideoReader: \"\"\"High-level video reader with array-style access.\"\"\" def __init__( self, path: str, video_stream_index: int = 0, *, build_index: bool = True, decoded_frame_cache_size: int = 0, scrub_bucket_ms: int = 25, scrub_bucket_lru_size: int = 4096, threading: bool = True, thread_count: int = 0, index_policy: str = \"decode\", ) -> None: \"\"\"Create a reader for the given video path. Args: path: Path to the video file to open. video_stream_index: Video stream index to decode. build_index: Whether to build a keyframe index on initialization (default True); can speed up accurate random seeks but adds upfront cost. speed up accurate random seeks but adds upfront cost. decoded_frame_cache_size: Number of decoded frames to keep in an in-memory LRU cache; helpful for repeated access to nearby frames. scrub_bucket_ms: Bucket size (milliseconds) used to group timestamps for fast scrub queries. scrub_bucket_lru_size: LRU size for the scrub bucket cache. threading: Whether to enable threaded decoding in the backend. thread_count: Number of decoding threads (0 lets backend decide). index_policy: Indexing policy, either ``\"decode\"`` for decode-order frames or ``\"timeline\"`` for timestamp-based access. Raises: ValueError: If ``index_policy`` is not ``\"decode\"`` or ``\"timeline\"``. \"\"\" self._backend = PyAVVideoBackend( path, video_stream_index=video_stream_index, build_index=build_index, decoded_frame_cache_size=decoded_frame_cache_size, scrub_bucket_ms=scrub_bucket_ms, scrub_bucket_lru_size=scrub_bucket_lru_size, threading=threading, thread_count=thread_count, ) if index_policy not in {\"decode\", \"timeline\"}: raise ValueError(\"index_policy must be 'decode' or 'timeline'\") self._index_policy = index_policy def close(self) -> None: \"\"\"Close the underlying video resources.\"\"\" self._backend.close() def __enter__(self) -> \"VideoReader\": \"\"\"Return self for context manager usage.\"\"\" return self def __exit__(self, exc_type, exc, tb) -> None: \"\"\"Close the reader when leaving a context manager. Args: exc_type: Exception type, if any. exc: Exception instance, if any. tb: Traceback, if any. \"\"\" self.close() def __len__(self) -> int: \"\"\"Return the number of frames in the video.\"\"\" return self.number_of_frames def __getitem__(self, key: IndexKey) -> Union[np.ndarray, List[np.ndarray]]: \"\"\"Return a frame or list of frames for the given index or slice. Indexing semantics are controlled by `index_policy`: - 'decode' (default): index refers to decode-order frame number. - 'timeline': index is mapped to timestamp using nominal FPS, and an accurate timestamp seek is performed. Args: key: Frame index or slice to retrieve. Returns: A single frame array or list of frame arrays. \"\"\" if isinstance(key, slice): start, stop, step = key.indices(self.number_of_frames) return [self[i] for i in range(start, stop, step)] i = int(key) if self._index_policy == \"decode\": return self._backend.frame_at_index(i) # timeline policy fps = self.nominal_frame_rate or self.frame_rate or 1.0 t_s = float(i) / fps return self._backend.read_frame_at(t_s).image def __iter__(self) -> Iterator[np.ndarray]: \"\"\"Iterate over all frames in the video.\"\"\" return self.iter_frames() @property def frame_height(self) -> int: \"\"\"Return the frame height in pixels.\"\"\" return self._backend.frame_height @property def frame_width(self) -> int: \"\"\"Return the frame width in pixels.\"\"\" return self._backend.frame_width @property def frame_rate(self) -> float: \"\"\"Return the video frame rate.\"\"\" return self._backend.frame_rate @property def nominal_frame_rate(self) -> float: \"\"\"Return the nominal video frame rate (guessed_rate when available).\"\"\" return self._backend.nominal_frame_rate @property def fourcc(self) -> int: \"\"\"Return the fourcc codec identifier.\"\"\" return self._backend.fourcc @property def frame_format(self) -> int: \"\"\"Return the pixel format identifier.\"\"\" return self._backend.frame_format @property def number_of_frames(self) -> int: \"\"\"Return the total number of frames.\"\"\" return self._backend.number_of_frames @property def frame_shape(self) -> tuple: \"\"\"Return the expected frame shape (H, W, C).\"\"\" return self._backend.frame_shape @property def current_frame_pos(self) -> float: \"\"\"Return the last accessed frame index.\"\"\" return self._backend.current_frame_pos def build_keyframe_index(self, *, max_packets: Optional[int] = None) -> List[KeyframeEntry]: \"\"\"Build a keyframe index for faster random access. Args: max_packets: Optional cap on packets to inspect. Returns: A list of keyframe entries. \"\"\" return self._backend.build_keyframe_index(max_packets=max_packets) def read_keyframe_at( self, t_s: float, *, mode: str = \"nearest\", decode_rgb: bool = True, ) -> DecodedFrame: \"\"\"Return a nearby keyframe for fast scrubbing. Args: t_s: Timestamp in seconds to seek around. mode: Selection mode (``\"nearest\"``, ``\"before\"``, or ``\"after\"``). decode_rgb: Whether to decode into RGB arrays. Returns: The decoded keyframe. \"\"\" return self._backend.read_keyframe_at(t_s, mode=mode, decode_rgb=decode_rgb) def read_frame_at( self, t_s: float, *, return_first_after: bool = True, max_decode_frames: int = 10_000, use_index: bool = True, ) -> DecodedFrame: \"\"\"Return a frame at a timestamp with accurate seeking. Args: t_s: Timestamp in seconds to seek to. return_first_after: Return the first frame after the timestamp. max_decode_frames: Cap on frames to decode while seeking. use_index: Whether to use the keyframe index if available. Returns: The decoded frame at the target timestamp. \"\"\" return self._backend.read_frame_at( t_s, return_first_after=return_first_after, max_decode_frames=max_decode_frames, use_index=use_index, ) def read_frame_fast( self, *, index: Optional[int] = None, t_s: Optional[float] = None, decode_rgb: bool = True, use_sequential: bool = True, ) -> DecodedFrame: \"\"\"Return a fast, approximate frame for an index or timestamp. Args: index: Decode-order frame index to seek to. t_s: Timestamp in seconds to seek to. decode_rgb: Whether to decode into RGB arrays. use_sequential: Allow sequential decoding when available. Returns: The decoded frame closest to the request. \"\"\" return self._backend.read_frame_fast( index=index, t_s=t_s, decode_rgb=decode_rgb, use_sequential=use_sequential, ) def read_next(self, *, decode_rgb: bool = True) -> np.ndarray: \"\"\"Return the next frame using sequential decoding. Args: decode_rgb: Whether to decode into RGB arrays. Returns: The next decoded frame image. \"\"\" return self._backend.read_next_frame(decode_rgb=decode_rgb).image def iter_frames(self, *, decode_rgb: bool = True) -> Iterator[np.ndarray]: \"\"\"Iterate frames sequentially without seeking.\"\"\" for frame in self._backend.iter_frames(decode_rgb=decode_rgb): yield frame.image # Public PTS/time helpers def pts_at_index(self, index: int) -> Optional[int]: \"\"\"Return the PTS for a given frame index.\"\"\" return self._backend.pts_at_index(int(index)) def time_at_index(self, index: int) -> float: \"\"\"Return the timestamp (seconds) for a given frame index.\"\"\" return self._backend.time_at_index(int(index)) def index_from_pts(self, pts: int) -> int: \"\"\"Return the nearest frame index for a PTS value.\"\"\" return self._backend.index_from_pts(int(pts)) def index_from_time(self, t_s: float) -> int: \"\"\"Return the nearest frame index for a timestamp in seconds.\"\"\" return self._backend.index_from_time(float(t_s)) def read_frame( self, *, index: Optional[int] = None, t_s: Optional[float] = None, mode: str = \"accurate\", decode_rgb: bool = True, keyframe_mode: str = \"nearest\", use_sequential: bool = True, ) -> DecodedFrame: \"\"\"Read a frame using a selectable access mode.\"\"\" return self._backend.read_frame( index=index, t_s=t_s, mode=mode, decode_rgb=decode_rgb, keyframe_mode=keyframe_mode, use_sequential=use_sequential, ) _backend = PyAVVideoBackend(path, video_stream_index=video_stream_index, build_index=build_index, decoded_frame_cache_size=decoded_frame_cache_size, scrub_bucket_ms=scrub_bucket_ms, scrub_bucket_lru_size=scrub_bucket_lru_size, threading=threading, thread_count=thread_count) instance-attribute _index_policy = index_policy instance-attribute current_frame_pos property Return the last accessed frame index. fourcc property Return the fourcc codec identifier. frame_format property Return the pixel format identifier. frame_height property Return the frame height in pixels. frame_rate property Return the video frame rate. frame_shape property Return the expected frame shape (H, W, C). frame_width property Return the frame width in pixels. nominal_frame_rate property Return the nominal video frame rate (guessed_rate when available). number_of_frames property Return the total number of frames. __enter__() Return self for context manager usage. Source code in acvr/reader.py def __enter__(self) -> \"VideoReader\": \"\"\"Return self for context manager usage.\"\"\" return self __exit__(exc_type, exc, tb) Close the reader when leaving a context manager. Parameters: Name Type Description Default exc_type Exception type, if any. required exc Exception instance, if any. required tb Traceback, if any. required Source code in acvr/reader.py def __exit__(self, exc_type, exc, tb) -> None: \"\"\"Close the reader when leaving a context manager. Args: exc_type: Exception type, if any. exc: Exception instance, if any. tb: Traceback, if any. \"\"\" self.close() __getitem__(key) Return a frame or list of frames for the given index or slice. Indexing semantics are controlled by index_policy : - 'decode' (default): index refers to decode-order frame number. - 'timeline': index is mapped to timestamp using nominal FPS, and an accurate timestamp seek is performed. Parameters: Name Type Description Default key IndexKey Frame index or slice to retrieve. required Returns: Type Description Union [ ndarray , List [ ndarray ]] A single frame array or list of frame arrays. Source code in acvr/reader.py def __getitem__(self, key: IndexKey) -> Union[np.ndarray, List[np.ndarray]]: \"\"\"Return a frame or list of frames for the given index or slice. Indexing semantics are controlled by `index_policy`: - 'decode' (default): index refers to decode-order frame number. - 'timeline': index is mapped to timestamp using nominal FPS, and an accurate timestamp seek is performed. Args: key: Frame index or slice to retrieve. Returns: A single frame array or list of frame arrays. \"\"\" if isinstance(key, slice): start, stop, step = key.indices(self.number_of_frames) return [self[i] for i in range(start, stop, step)] i = int(key) if self._index_policy == \"decode\": return self._backend.frame_at_index(i) # timeline policy fps = self.nominal_frame_rate or self.frame_rate or 1.0 t_s = float(i) / fps return self._backend.read_frame_at(t_s).image __init__(path, video_stream_index=0, *, build_index=True, decoded_frame_cache_size=0, scrub_bucket_ms=25, scrub_bucket_lru_size=4096, threading=True, thread_count=0, index_policy='decode') Create a reader for the given video path. Parameters: Name Type Description Default path str Path to the video file to open. required video_stream_index int Video stream index to decode. 0 build_index bool Whether to build a keyframe index on initialization (default True); can speed up accurate random seeks but adds upfront cost. speed up accurate random seeks but adds upfront cost. True decoded_frame_cache_size int Number of decoded frames to keep in an in-memory LRU cache; helpful for repeated access to nearby frames. 0 scrub_bucket_ms int Bucket size (milliseconds) used to group timestamps for fast scrub queries. 25 scrub_bucket_lru_size int LRU size for the scrub bucket cache. 4096 threading bool Whether to enable threaded decoding in the backend. True thread_count int Number of decoding threads (0 lets backend decide). 0 index_policy str Indexing policy, either \"decode\" for decode-order frames or \"timeline\" for timestamp-based access. 'decode' Raises: Type Description ValueError If index_policy is not \"decode\" or \"timeline\" . Source code in acvr/reader.py def __init__( self, path: str, video_stream_index: int = 0, *, build_index: bool = True, decoded_frame_cache_size: int = 0, scrub_bucket_ms: int = 25, scrub_bucket_lru_size: int = 4096, threading: bool = True, thread_count: int = 0, index_policy: str = \"decode\", ) -> None: \"\"\"Create a reader for the given video path. Args: path: Path to the video file to open. video_stream_index: Video stream index to decode. build_index: Whether to build a keyframe index on initialization (default True); can speed up accurate random seeks but adds upfront cost. speed up accurate random seeks but adds upfront cost. decoded_frame_cache_size: Number of decoded frames to keep in an in-memory LRU cache; helpful for repeated access to nearby frames. scrub_bucket_ms: Bucket size (milliseconds) used to group timestamps for fast scrub queries. scrub_bucket_lru_size: LRU size for the scrub bucket cache. threading: Whether to enable threaded decoding in the backend. thread_count: Number of decoding threads (0 lets backend decide). index_policy: Indexing policy, either ``\"decode\"`` for decode-order frames or ``\"timeline\"`` for timestamp-based access. Raises: ValueError: If ``index_policy`` is not ``\"decode\"`` or ``\"timeline\"``. \"\"\" self._backend = PyAVVideoBackend( path, video_stream_index=video_stream_index, build_index=build_index, decoded_frame_cache_size=decoded_frame_cache_size, scrub_bucket_ms=scrub_bucket_ms, scrub_bucket_lru_size=scrub_bucket_lru_size, threading=threading, thread_count=thread_count, ) if index_policy not in {\"decode\", \"timeline\"}: raise ValueError(\"index_policy must be 'decode' or 'timeline'\") self._index_policy = index_policy __iter__() Iterate over all frames in the video. Source code in acvr/reader.py def __iter__(self) -> Iterator[np.ndarray]: \"\"\"Iterate over all frames in the video.\"\"\" return self.iter_frames() __len__() Return the number of frames in the video. Source code in acvr/reader.py def __len__(self) -> int: \"\"\"Return the number of frames in the video.\"\"\" return self.number_of_frames build_keyframe_index(*, max_packets=None) Build a keyframe index for faster random access. Parameters: Name Type Description Default max_packets Optional [ int ] Optional cap on packets to inspect. None Returns: Type Description List [ KeyframeEntry ] A list of keyframe entries. Source code in acvr/reader.py def build_keyframe_index(self, *, max_packets: Optional[int] = None) -> List[KeyframeEntry]: \"\"\"Build a keyframe index for faster random access. Args: max_packets: Optional cap on packets to inspect. Returns: A list of keyframe entries. \"\"\" return self._backend.build_keyframe_index(max_packets=max_packets) close() Close the underlying video resources. Source code in acvr/reader.py def close(self) -> None: \"\"\"Close the underlying video resources.\"\"\" self._backend.close() index_from_pts(pts) Return the nearest frame index for a PTS value. Source code in acvr/reader.py def index_from_pts(self, pts: int) -> int: \"\"\"Return the nearest frame index for a PTS value.\"\"\" return self._backend.index_from_pts(int(pts)) index_from_time(t_s) Return the nearest frame index for a timestamp in seconds. Source code in acvr/reader.py def index_from_time(self, t_s: float) -> int: \"\"\"Return the nearest frame index for a timestamp in seconds.\"\"\" return self._backend.index_from_time(float(t_s)) iter_frames(*, decode_rgb=True) Iterate frames sequentially without seeking. Source code in acvr/reader.py def iter_frames(self, *, decode_rgb: bool = True) -> Iterator[np.ndarray]: \"\"\"Iterate frames sequentially without seeking.\"\"\" for frame in self._backend.iter_frames(decode_rgb=decode_rgb): yield frame.image pts_at_index(index) Return the PTS for a given frame index. Source code in acvr/reader.py def pts_at_index(self, index: int) -> Optional[int]: \"\"\"Return the PTS for a given frame index.\"\"\" return self._backend.pts_at_index(int(index)) read_frame(*, index=None, t_s=None, mode='accurate', decode_rgb=True, keyframe_mode='nearest', use_sequential=True) Read a frame using a selectable access mode. Source code in acvr/reader.py def read_frame( self, *, index: Optional[int] = None, t_s: Optional[float] = None, mode: str = \"accurate\", decode_rgb: bool = True, keyframe_mode: str = \"nearest\", use_sequential: bool = True, ) -> DecodedFrame: \"\"\"Read a frame using a selectable access mode.\"\"\" return self._backend.read_frame( index=index, t_s=t_s, mode=mode, decode_rgb=decode_rgb, keyframe_mode=keyframe_mode, use_sequential=use_sequential, ) read_frame_at(t_s, *, return_first_after=True, max_decode_frames=10000, use_index=True) Return a frame at a timestamp with accurate seeking. Parameters: Name Type Description Default t_s float Timestamp in seconds to seek to. required return_first_after bool Return the first frame after the timestamp. True max_decode_frames int Cap on frames to decode while seeking. 10000 use_index bool Whether to use the keyframe index if available. True Returns: Type Description DecodedFrame The decoded frame at the target timestamp. Source code in acvr/reader.py def read_frame_at( self, t_s: float, *, return_first_after: bool = True, max_decode_frames: int = 10_000, use_index: bool = True, ) -> DecodedFrame: \"\"\"Return a frame at a timestamp with accurate seeking. Args: t_s: Timestamp in seconds to seek to. return_first_after: Return the first frame after the timestamp. max_decode_frames: Cap on frames to decode while seeking. use_index: Whether to use the keyframe index if available. Returns: The decoded frame at the target timestamp. \"\"\" return self._backend.read_frame_at( t_s, return_first_after=return_first_after, max_decode_frames=max_decode_frames, use_index=use_index, ) read_frame_fast(*, index=None, t_s=None, decode_rgb=True, use_sequential=True) Return a fast, approximate frame for an index or timestamp. Parameters: Name Type Description Default index Optional [ int ] Decode-order frame index to seek to. None t_s Optional [ float ] Timestamp in seconds to seek to. None decode_rgb bool Whether to decode into RGB arrays. True use_sequential bool Allow sequential decoding when available. True Returns: Type Description DecodedFrame The decoded frame closest to the request. Source code in acvr/reader.py def read_frame_fast( self, *, index: Optional[int] = None, t_s: Optional[float] = None, decode_rgb: bool = True, use_sequential: bool = True, ) -> DecodedFrame: \"\"\"Return a fast, approximate frame for an index or timestamp. Args: index: Decode-order frame index to seek to. t_s: Timestamp in seconds to seek to. decode_rgb: Whether to decode into RGB arrays. use_sequential: Allow sequential decoding when available. Returns: The decoded frame closest to the request. \"\"\" return self._backend.read_frame_fast( index=index, t_s=t_s, decode_rgb=decode_rgb, use_sequential=use_sequential, ) read_keyframe_at(t_s, *, mode='nearest', decode_rgb=True) Return a nearby keyframe for fast scrubbing. Parameters: Name Type Description Default t_s float Timestamp in seconds to seek around. required mode str Selection mode ( \"nearest\" , \"before\" , or \"after\" ). 'nearest' decode_rgb bool Whether to decode into RGB arrays. True Returns: Type Description DecodedFrame The decoded keyframe. Source code in acvr/reader.py def read_keyframe_at( self, t_s: float, *, mode: str = \"nearest\", decode_rgb: bool = True, ) -> DecodedFrame: \"\"\"Return a nearby keyframe for fast scrubbing. Args: t_s: Timestamp in seconds to seek around. mode: Selection mode (``\"nearest\"``, ``\"before\"``, or ``\"after\"``). decode_rgb: Whether to decode into RGB arrays. Returns: The decoded keyframe. \"\"\" return self._backend.read_keyframe_at(t_s, mode=mode, decode_rgb=decode_rgb) read_next(*, decode_rgb=True) Return the next frame using sequential decoding. Parameters: Name Type Description Default decode_rgb bool Whether to decode into RGB arrays. True Returns: Type Description ndarray The next decoded frame image. Source code in acvr/reader.py def read_next(self, *, decode_rgb: bool = True) -> np.ndarray: \"\"\"Return the next frame using sequential decoding. Args: decode_rgb: Whether to decode into RGB arrays. Returns: The next decoded frame image. \"\"\" return self._backend.read_next_frame(decode_rgb=decode_rgb).image time_at_index(index) Return the timestamp (seconds) for a given frame index. Source code in acvr/reader.py def time_at_index(self, index: int) -> float: \"\"\"Return the timestamp (seconds) for a given frame index.\"\"\" return self._backend.time_at_index(int(index)) Backend implementation Frame-accurate seeking with keyframe index and scrub acceleration. Source code in acvr/_pyav_backend.py class PyAVVideoBackend: \"\"\"Frame-accurate seeking with keyframe index and scrub acceleration.\"\"\" def __init__( self, path: str, video_stream_index: int = 0, *, build_index: bool = False, decoded_frame_cache_size: int = 0, scrub_bucket_ms: int = 25, scrub_bucket_lru_size: int = 4096, threading: bool = True, thread_count: int = 0, ) -> None: \"\"\"Initialize the PyAV-backed decoder.\"\"\" self._path = path self._container = av.open(path) self._stream = self._container.streams.video[video_stream_index] self._codec_ctx = self._stream.codec_context self._fast_container: Optional[av.container.InputContainer] = None self._fast_stream: Optional[av.video.stream.VideoStream] = None self._fast_first_frame_number: Optional[int] = None self._fast_decoder = None self._fast_last_pts: Optional[int] = None self._seq_container: Optional[av.container.InputContainer] = None self._seq_stream: Optional[av.video.stream.VideoStream] = None self._seq_decoder = None self._seq_frame_index: int = 0 self._last_index: Optional[int] = None self._last_fast_index: Optional[int] = None self._time_base: Fraction = self._stream.time_base self._start_pts: int = self._stream.start_time if self._stream.start_time is not None else 0 self._keyframes: List[KeyframeEntry] = [] self._index_built: bool = False self._frame_pts: Optional[List[int]] = None self._frame_count: int = int(self._stream.frames or 0) self._current_frame_pos: float = 0.0 self._frame_cache = _LRU(decoded_frame_cache_size) self._scrub_bucket_ms = max(1, int(scrub_bucket_ms)) self._bucket_to_kfidx = _LRU(scrub_bucket_lru_size) self._threading = bool(threading) self._thread_count = int(thread_count) if build_index: self.build_keyframe_index() self._frame_height = int(self._stream.height or 0) self._frame_width = int(self._stream.width or 0) self._frame_shape = (self._frame_height, self._frame_width, 3) self._frame_rate = self._compute_frame_rate() self._nominal_frame_rate = self._compute_nominal_frame_rate() self._fourcc = self._compute_fourcc() self._frame_format = 0 def close(self) -> None: \"\"\"Close the underlying PyAV container.\"\"\" self._container.close() if self._fast_container is not None: self._fast_container.close() self._fast_container = None self._fast_stream = None self._fast_decoder = None self._fast_last_pts = None self._fast_first_frame_number = None if self._seq_container is not None: self._seq_container.close() self._seq_container = None self._seq_stream = None self._seq_decoder = None self._seq_frame_index = 0 self._last_index = None self._last_fast_index = None def __enter__(self) -> \"PyAVVideoBackend\": \"\"\"Return self for context manager usage.\"\"\" return self def __exit__(self, exc_type, exc, tb) -> None: \"\"\"Close the backend on exit from a context manager.\"\"\" self.close() def _secs_to_pts(self, t_s: float) -> int: \"\"\"Convert seconds to presentation timestamp units.\"\"\" ticks = int(round(t_s / float(self._time_base))) return self._start_pts + ticks def _pts_to_secs(self, pts: int) -> float: \"\"\"Convert presentation timestamp units to seconds.\"\"\" return float((pts - self._start_pts) * self._time_base) def _pts_to_frame_number(self, pts: Optional[int], fps: float) -> Optional[int]: \"\"\"Convert a PTS value to a rounded frame number.\"\"\" if pts is None: return None return int(round(self._pts_to_secs(int(pts)) * fps)) def _frame_time_s(self, pts: Optional[int]) -> float: \"\"\"Return the timestamp for a frame PTS.\"\"\" return float(\"nan\") if pts is None else self._pts_to_secs(pts) def _flush_decoder(self) -> None: \"\"\"Flush decoder buffers if supported.\"\"\" try: self._codec_ctx.flush_buffers() except Exception: pass def _compute_frame_rate(self) -> float: \"\"\"Compute the stream frame rate in frames per second.\"\"\" rate = self._stream.average_rate or self._stream.base_rate return float(rate) if rate is not None else 0.0 def _compute_nominal_frame_rate(self) -> float: \"\"\"Compute a nominal frame rate preferring guessed_rate (useful for VFR).\"\"\" rate = getattr(self._stream, \"guessed_rate\", None) or self._stream.average_rate or self._stream.base_rate return float(rate) if rate is not None else 0.0 @property def nominal_frame_rate(self) -> float: \"\"\"Return the nominal frame rate (guessed_rate when available).\"\"\" return self._nominal_frame_rate def _compute_fourcc(self) -> int: \"\"\"Compute a fourcc code from the stream codec tag.\"\"\" tag = self._stream.codec_context.codec_tag if isinstance(tag, str) and len(tag) >= 4: tag = tag[:4] return ( ord(tag[0]) | (ord(tag[1]) << 8) | (ord(tag[2]) << 16) | (ord(tag[3]) << 24) ) return 0 def _ensure_frame_pts(self) -> None: \"\"\"Decode the stream once to collect frame PTS values.\"\"\" if self._frame_pts is not None: return idx_container = av.open(self._path) idx_stream = idx_container.streams.video[self._stream.index] self._configure_codec_context(idx_stream) self._configure_codec_context(idx_stream) pts_list: List[int] = [] for frame in idx_container.decode(idx_stream): pts = frame.pts if frame.pts is not None else frame.dts if pts is None: pts = self._start_pts + len(pts_list) pts_list.append(int(pts)) idx_container.close() self._frame_pts = pts_list self._frame_count = len(pts_list) def _read_frame_by_pts(self, target_pts: int, *, decode_rgb: bool = True) -> DecodedFrame: \"\"\"Decode the first frame at or after a target PTS.\"\"\" cached = self._frame_cache.get(target_pts) if cached is not None: return cached # type: ignore[return-value] if self._index_built: idx = self._keyframe_index_at_or_before_pts(target_pts) seek_pts = self._keyframes[idx].pts else: seek_pts = target_pts container = av.open(self._path) stream = container.streams.video[self._stream.index] self._configure_codec_context(stream) try: container.seek(seek_pts, stream=stream, backward=True, any_frame=False) try: stream.codec_context.flush_buffers() except Exception: pass last: Optional[DecodedFrame] = None for packet in container.demux(stream): for frame in packet.decode(): pts = frame.pts image = frame.to_rgb().to_ndarray() if decode_rgb else frame.to_ndarray(format=\"bgr24\") cur = DecodedFrame( image=image, pts=pts, time_s=self._frame_time_s(pts), key_frame=bool(getattr(frame, \"key_frame\", False)), ) if pts is not None: self._frame_cache.put(int(pts), cur) if pts is None: last = cur continue if pts >= target_pts: return cur last = cur finally: container.close() if last is not None: return last raise RuntimeError(\"Could not decode any frames after seeking.\") def _read_frame_at_index( self, index: int, *, decode_rgb: bool = True, use_sequential: bool = True, ) -> DecodedFrame: \"\"\"Return the decoded frame at a zero-based index.\"\"\" if use_sequential and index >= 0: if self._seq_decoder is not None and index == self._seq_frame_index: return self.read_next_frame(decode_rgb=decode_rgb) if self._seq_decoder is None and index == 0: self.reset_sequence() return self.read_next_frame(decode_rgb=decode_rgb) self._ensure_frame_pts() assert self._frame_pts is not None if index < 0: index += self._frame_count if index < 0 or index >= self._frame_count: raise IndexError(\"frame index out of range\") target_pts = self._frame_pts[index] if use_sequential and self._seq_decoder is not None and index == self._seq_frame_index: try: decoded = self.read_next_frame(decode_rgb=decode_rgb) except StopIteration: decoded = self._seek_seq_to_pts(target_pts, target_index=index, decode_rgb=decode_rgb) elif use_sequential and self._last_index is not None and index == self._last_index + 1: decoded = self._seek_seq_to_pts(target_pts, target_index=index, decode_rgb=decode_rgb) else: decoded = self._read_frame_by_pts(target_pts, decode_rgb=decode_rgb) self._current_frame_pos = float(index) self._last_index = index return decoded def frame_at_index(self, index: int) -> np.ndarray: \"\"\"Return the decoded frame at a zero-based index.\"\"\" return self._read_frame_at_index(index, decode_rgb=True, use_sequential=True).image # # Public helpers for PTS/time mapping # def pts_at_index(self, index: int) -> Optional[int]: \"\"\"Return the presentation timestamp (PTS) for a frame index.\"\"\" self._ensure_frame_pts() assert self._frame_pts is not None if index < 0: index += self._frame_count if index < 0 or index >= self._frame_count: raise IndexError(\"frame index out of range\") return int(self._frame_pts[index]) def time_at_index(self, index: int) -> float: \"\"\"Return the timestamp in seconds for a frame index.\"\"\" pts = self.pts_at_index(index) return float(\"nan\") if pts is None else self._pts_to_secs(int(pts)) def index_from_pts(self, pts: int) -> int: \"\"\"Map a PTS value to the nearest frame index.\"\"\" self._ensure_frame_pts() assert self._frame_pts is not None fps = self._frame_pts if not fps: return 0 lo, hi = 0, len(fps) - 1 if pts <= fps[0]: return 0 if pts >= fps[-1]: return hi while lo <= hi: mid = (lo + hi) // 2 m = fps[mid] if m == pts: return mid if m < pts: lo = mid + 1 else: hi = mid - 1 # choose nearest between hi and lo if lo >= len(fps): return hi if hi < 0: return lo return lo if abs(fps[lo] - pts) < abs(fps[hi] - pts) else hi def index_from_time(self, t_s: float) -> int: \"\"\"Map a timestamp in seconds to the nearest frame index.\"\"\" pts = self._secs_to_pts(float(t_s)) return self.index_from_pts(int(pts)) @property def frame_height(self) -> int: \"\"\"Return the video frame height.\"\"\" return self._frame_height @property def frame_width(self) -> int: \"\"\"Return the video frame width.\"\"\" return self._frame_width @property def frame_rate(self) -> float: \"\"\"Return the reported frame rate in frames per second.\"\"\" return self._frame_rate @property def fourcc(self) -> int: \"\"\"Return the fourcc codec identifier.\"\"\" return self._fourcc @property def frame_format(self) -> int: \"\"\"Return the frame format identifier.\"\"\" return self._frame_format @property def number_of_frames(self) -> int: \"\"\"Return the total number of frames, decoding if needed.\"\"\" if self._frame_count <= 0: self._ensure_frame_pts() return self._frame_count @property def frame_shape(self) -> tuple: \"\"\"Return the expected frame shape (H, W, C).\"\"\" return self._frame_shape @property def current_frame_pos(self) -> float: \"\"\"Return the last frame index accessed.\"\"\" return self._current_frame_pos def _seek_to_pts(self, pts: int, *, backward: bool) -> None: \"\"\"Seek to a timestamp in the stream.\"\"\" self._container.seek(pts, stream=self._stream, backward=backward, any_frame=False) self._flush_decoder() def _ensure_fast_container(self) -> None: \"\"\"Initialize the fast-seek container if needed.\"\"\" if self._fast_container is not None: return self._fast_container = av.open(self._path) self._fast_stream = self._fast_container.streams.video[self._stream.index] self._configure_codec_context(self._fast_stream) def _configure_codec_context(self, stream: av.video.stream.VideoStream) -> None: \"\"\"Apply conservative threading settings to a codec context.\"\"\" try: codec_ctx = stream.codec_context if self._threading: codec_ctx.thread_type = \"AUTO\" codec_ctx.thread_count = self._thread_count else: codec_ctx.thread_type = \"NONE\" codec_ctx.thread_count = 1 except Exception: pass def _fast_rewind(self) -> None: \"\"\"Rewind the fast-seek container and reset decoder state.\"\"\" self._ensure_fast_container() assert self._fast_container is not None assert self._fast_stream is not None self._fast_container.seek(0) self._fast_decoder = self._fast_container.decode(self._fast_stream) self._fast_last_pts = None def _fast_frame_to_pts(self, frame_index: int, fps: float) -> int: \"\"\"Convert a frame index to expected PTS for fast reads.\"\"\" if frame_index <= 0: return self._start_pts return self._secs_to_pts(frame_index / fps) def _read_frame_fast_like(self, target_frame: int, *, decode_rgb: bool) -> DecodedFrame: \"\"\"Approximate FastVideoReader behavior for fast sequential reads.\"\"\" fps = self._nominal_frame_rate or self._frame_rate or 1.0 pts_per_frame = 1.0 / (fps * float(self._time_base)) if fps else 1.0 wiggle = pts_per_frame / 10.0 if target_frame <= 0: self._fast_rewind() assert self._fast_decoder is not None frame = next(self._fast_decoder) pts = frame.pts if frame.pts is not None else frame.dts if pts is None: pts = self._fast_frame_to_pts(0, fps) img = frame.to_rgb().to_ndarray() if decode_rgb else frame.to_ndarray(format=\"bgr24\") cur = DecodedFrame( image=img, pts=pts, time_s=self._frame_time_s(pts), key_frame=bool(getattr(frame, \"key_frame\", False)), ) if pts is not None: self._frame_cache.put(int(pts), cur) return cur expected_prev_pts = self._fast_frame_to_pts(target_frame - 1, fps) if self._fast_decoder is not None and self._fast_last_pts == expected_prev_pts: try: frame = next(self._fast_decoder) except StopIteration: frame = None if frame is not None: pts = frame.pts if frame.pts is not None else frame.dts if pts is None: pts = self._fast_frame_to_pts(target_frame, fps) img = frame.to_rgb().to_ndarray() if decode_rgb else frame.to_ndarray(format=\"bgr24\") cur = DecodedFrame( image=img, pts=pts, time_s=self._frame_time_s(pts), key_frame=bool(getattr(frame, \"key_frame\", False)), ) if pts is not None: self._frame_cache.put(int(pts), cur) self._fast_last_pts = int(pts) if pts is not None else None return cur self._ensure_fast_container() assert self._fast_container is not None assert self._fast_stream is not None target_pts = self._fast_frame_to_pts(target_frame, fps) self._fast_container.seek( target_pts, stream=self._fast_stream, backward=True, any_frame=False, ) try: self._fast_stream.codec_context.flush_buffers() except Exception: pass self._fast_decoder = self._fast_container.decode(self._fast_stream) self._fast_last_pts = None try: frame = next(self._fast_decoder) except StopIteration: frame = None if frame is None: return self._read_frame_fast_simple(target_pts, decode_rgb=decode_rgb) cur_pts = frame.pts if frame.pts is not None else frame.dts if cur_pts is None: cur_pts = target_pts if cur_pts > target_pts: back = max(1, int(round(100))) back_pts = self._fast_frame_to_pts(max(0, target_frame - back), fps) self._fast_container.seek( back_pts, stream=self._fast_stream, backward=True, any_frame=False, ) try: self._fast_stream.codec_context.flush_buffers() except Exception: pass self._fast_decoder = self._fast_container.decode(self._fast_stream) try: frame = next(self._fast_decoder) except StopIteration: frame = None if frame is None: return self._read_frame_fast_simple(target_pts, decode_rgb=decode_rgb) cur_pts = frame.pts if frame.pts is not None else frame.dts if cur_pts is None: cur_pts = target_pts while float(cur_pts) < (float(target_pts) - wiggle): try: frame = next(self._fast_decoder) except StopIteration: frame = None break if frame is None: break cur_pts = frame.pts if frame.pts is not None else frame.dts if cur_pts is None: cur_pts = target_pts break if frame is None: return self._read_frame_fast_simple(target_pts, decode_rgb=decode_rgb) img = frame.to_rgb().to_ndarray() if decode_rgb else frame.to_ndarray(format=\"bgr24\") cur = DecodedFrame( image=img, pts=cur_pts, time_s=self._frame_time_s(cur_pts), key_frame=bool(getattr(frame, \"key_frame\", False)), ) if cur_pts is not None: self._frame_cache.put(int(cur_pts), cur) self._fast_last_pts = int(cur_pts) else: self._fast_last_pts = None return cur def _ensure_seq_container(self) -> None: \"\"\"Initialize a sequential decode container if needed.\"\"\" if self._seq_container is not None: return self._seq_container = av.open(self._path) self._seq_stream = self._seq_container.streams.video[self._stream.index] self._configure_codec_context(self._seq_stream) self._seq_decoder = self._seq_container.decode(self._seq_stream) self._seq_frame_index = 0 def reset_sequence(self) -> None: \"\"\"Reset sequential decoding to the first frame.\"\"\" self._ensure_seq_container() assert self._seq_container is not None assert self._seq_stream is not None try: self._seq_container.seek(0) except Exception: pass self._seq_decoder = self._seq_container.decode(self._seq_stream) self._seq_frame_index = 0 def _seek_seq_to_pts( self, target_pts: int, *, target_index: int, decode_rgb: bool, any_frame: bool = False, ) -> DecodedFrame: \"\"\"Seek the sequential decoder to a PTS and return the first match.\"\"\" self._ensure_seq_container() assert self._seq_container is not None assert self._seq_stream is not None seek_pts = target_pts if self._keyframes and not any_frame: idx = self._keyframe_index_at_or_before_pts(target_pts) seek_pts = self._keyframes[idx].pts self._seq_container.seek( seek_pts, stream=self._seq_stream, backward=True, any_frame=any_frame, ) try: self._seq_stream.codec_context.flush_buffers() except Exception: pass decoder = self._seq_container.decode(self._seq_stream) last: Optional[DecodedFrame] = None for frame in decoder: pts = frame.pts if frame.pts is not None else frame.dts img = frame.to_rgb().to_ndarray() if decode_rgb else frame.to_ndarray(format=\"bgr24\") cur = DecodedFrame( image=img, pts=pts, time_s=self._frame_time_s(pts), key_frame=bool(getattr(frame, \"key_frame\", False)), ) if pts is not None: self._frame_cache.put(int(pts), cur) if pts is None: last = cur continue if pts >= target_pts: self._seq_decoder = decoder self._seq_frame_index = target_index + 1 self._current_frame_pos = float(target_index) return cur last = cur if last is not None: self._seq_decoder = decoder self._seq_frame_index = target_index + 1 self._current_frame_pos = float(target_index) return last raise RuntimeError(\"Could not decode any frames after seeking.\") def build_keyframe_index(self, *, max_packets: Optional[int] = None) -> List[KeyframeEntry]: \"\"\"Scan packets and store keyframe pts/time.\"\"\" path = self._container.name idx_container = av.open(path) idx_stream = idx_container.streams.video[self._stream.index] key_pts: List[int] = [] n = 0 for packet in idx_container.demux(idx_stream): if packet.dts is None and packet.pts is None: continue if packet.is_keyframe: pts = packet.pts if packet.pts is not None else packet.dts if pts is not None: key_pts.append(int(pts)) n += 1 if max_packets is not None and n >= max_packets: break idx_container.close() key_pts = sorted(set(key_pts)) if not key_pts: key_pts = [self._start_pts] self._keyframes = [KeyframeEntry(pts=p, time_s=self._pts_to_secs(p)) for p in key_pts] self._index_built = True self._bucket_to_kfidx.clear() return self._keyframes def _keyframe_index_at_or_before_pts(self, target_pts: int) -> int: \"\"\"Return keyframe index at or before the target PTS.\"\"\" kf = self._keyframes if not self._index_built or not kf: return 0 if target_pts <= kf[0].pts: return 0 if target_pts >= kf[-1].pts: return len(kf) - 1 lo, hi = 0, len(kf) - 1 while lo <= hi: mid = (lo + hi) // 2 m = kf[mid].pts if m == target_pts: return mid if m < target_pts: lo = mid + 1 else: hi = mid - 1 return hi def _keyframe_index_nearest_pts(self, target_pts: int) -> int: \"\"\"Return nearest keyframe index to the target PTS.\"\"\" kf = self._keyframes if not self._index_built or not kf: return 0 i0 = self._keyframe_index_at_or_before_pts(target_pts) i1 = min(i0 + 1, len(kf) - 1) if i0 == i1: return i0 d0 = abs(kf[i0].pts - target_pts) d1 = abs(kf[i1].pts - target_pts) return i0 if d0 <= d1 else i1 def _bucket_key(self, t_s: float) -> int: \"\"\"Return a bucket key for the scrub acceleration cache.\"\"\" return int(round(t_s * 1000.0 / self._scrub_bucket_ms)) def _keyframe_index_for_time_fast(self, t_s: float, mode: str) -> int: \"\"\"Return a keyframe index using cached time buckets.\"\"\" if not self._index_built: raise RuntimeError(\"Keyframe index not built. Call build_keyframe_index() first.\") b = self._bucket_key(t_s) mode_tag = {\"previous\": 0, \"nearest\": 1, \"next\": 2}.get(mode) if mode_tag is None: raise ValueError(\"mode must be one of: 'previous', 'nearest', 'next'\") cache_key = (b << 2) | mode_tag cached = self._bucket_to_kfidx.get(cache_key) if cached is not None: return int(cached) target_pts = self._secs_to_pts(t_s) if mode == \"previous\": idx = self._keyframe_index_at_or_before_pts(target_pts) elif mode == \"nearest\": idx = self._keyframe_index_nearest_pts(target_pts) else: i_prev = self._keyframe_index_at_or_before_pts(target_pts) if self._keyframes[i_prev].pts >= target_pts: idx = i_prev else: idx = min(i_prev + 1, len(self._keyframes) - 1) self._bucket_to_kfidx.put(cache_key, idx) return idx def read_keyframe_at( self, t_s: Number, *, mode: str = \"nearest\", decode_rgb: bool = True, ) -> DecodedFrame: \"\"\"Return a nearby keyframe without GOP forward decoding.\"\"\" t_s = float(t_s) idx = self._keyframe_index_for_time_fast(t_s, mode) key_pts = self._keyframes[idx].pts cached = self._frame_cache.get(key_pts) if cached is not None: return cached # type: ignore[return-value] # Use a fresh container for reliable keyframe seek, avoiding stateful issues container = av.open(self._path) try: stream = container.streams.video[self._stream.index] self._configure_codec_context(stream) # Use backward seek to land on or before the requested keyframe PTS reliably container.seek(key_pts, stream=stream, backward=True, any_frame=False) try: stream.codec_context.flush_buffers() except Exception: pass for packet in container.demux(stream): for frame in packet.decode(): pts = frame.pts img = frame.to_rgb().to_ndarray() if decode_rgb else frame.to_ndarray() cur = DecodedFrame( image=img, pts=pts, time_s=self._frame_time_s(pts), key_frame=bool(getattr(frame, \"key_frame\", False)), ) if pts is not None: self._frame_cache.put(int(pts), cur) return cur finally: container.close() raise RuntimeError(\"Failed to decode a frame after keyframe seek.\") def read_frame_at( self, t_s: Number, *, return_first_after: bool = True, max_decode_frames: int = 10_000, use_index: bool = True, ) -> DecodedFrame: \"\"\"Decode a frame near a timestamp with accurate seeking. Simplified and robust: always uses a fresh container and backward keyframe seek. \"\"\" t_s = float(t_s) target_pts = self._secs_to_pts(t_s) cached = self._frame_cache.get(target_pts) if cached is not None: return cached # type: ignore[return-value] container = av.open(self._path) try: stream = container.streams.video[self._stream.index] self._configure_codec_context(stream) if use_index and self._index_built: idx = self._keyframe_index_at_or_before_pts(target_pts) anchor_pts = self._keyframes[idx].pts container.seek(anchor_pts, stream=stream, backward=True, any_frame=False) else: container.seek(target_pts, stream=stream, backward=True, any_frame=False) try: stream.codec_context.flush_buffers() except Exception: pass last: Optional[DecodedFrame] = None decoded = 0 for packet in container.demux(stream): for frame in packet.decode(): decoded += 1 if decoded > max_decode_frames: raise RuntimeError( \"Exceeded max_decode_frames while seeking; timestamps may be broken.\" ) pts = frame.pts cur = DecodedFrame( image=frame.to_rgb().to_ndarray(), pts=pts, time_s=self._frame_time_s(pts), key_frame=bool(getattr(frame, \"key_frame\", False)), ) if pts is not None: self._frame_cache.put(int(pts), cur) if pts is None: last = cur continue if return_first_after: if pts >= target_pts: return cur last = cur else: if pts <= target_pts: last = cur elif last is not None: return last if last is not None: return last raise RuntimeError(\"Could not decode any frames after seeking.\") finally: container.close() def _read_frame_fast_simple(self, target_pts: int, *, decode_rgb: bool) -> DecodedFrame: \"\"\"Fallback fast seek: seek and decode first frame after PTS.\"\"\" self._ensure_fast_container() assert self._fast_container is not None assert self._fast_stream is not None def grab_frame(container: av.container.InputContainer, stream: av.video.stream.VideoStream) -> Optional[DecodedFrame]: for frame in container.decode(stream): pts = frame.pts if frame.pts is not None else frame.dts if pts is None: target_reached = True else: target_reached = pts >= target_pts if not target_reached: continue if decode_rgb: img = frame.to_rgb().to_ndarray() else: img = frame.to_ndarray(format=\"bgr24\") cur = DecodedFrame( image=img, pts=pts, time_s=self._frame_time_s(pts), key_frame=bool(getattr(frame, \"key_frame\", False)), ) if pts is not None: self._frame_cache.put(int(pts), cur) return cur return None self._fast_container.seek( target_pts, stream=self._fast_stream, backward=True, any_frame=True, ) try: self._fast_stream.codec_context.flush_buffers() except Exception: pass grabbed = grab_frame(self._fast_container, self._fast_stream) if grabbed is not None: return grabbed self._fast_container.seek( target_pts, stream=self._fast_stream, backward=True, any_frame=False, ) try: self._fast_stream.codec_context.flush_buffers() except Exception: pass grabbed = grab_frame(self._fast_container, self._fast_stream) if grabbed is not None: return grabbed raise RuntimeError(\"Failed to decode a frame after fast seek.\") def _read_frame_fast_opencv_pyav(self, target_frame: int, *, decode_rgb: bool) -> DecodedFrame: \"\"\"Approximate OpenCV seek behavior using PyAV.\"\"\" fps = self._nominal_frame_rate or self._frame_rate or 1.0 self._ensure_fast_container() assert self._fast_container is not None assert self._fast_stream is not None def seek_to_frame(frame_index: int) -> None: target_pts = self._secs_to_pts(frame_index / fps) self._fast_container.seek( target_pts, stream=self._fast_stream, backward=True, any_frame=False, ) try: self._fast_stream.codec_context.flush_buffers() except Exception: pass def frame_number_from_pts(pts: Optional[int]) -> Optional[int]: num = self._pts_to_frame_number(pts, fps) if num is None: return None if self._fast_first_frame_number is None: return num return num - self._fast_first_frame_number first_frame = None if self._fast_first_frame_number is None: seek_to_frame(0) for frame in self._fast_container.decode(self._fast_stream): pts = frame.pts if frame.pts is not None else frame.dts self._fast_first_frame_number = self._pts_to_frame_number(pts, fps) or 0 first_frame = frame break if target_frame <= 0: if first_frame is None: seek_to_frame(0) for frame in self._fast_container.decode(self._fast_stream): first_frame = frame break if first_frame is None: raise RuntimeError(\"Failed to decode a frame after fast seek.\") pts = first_frame.pts if first_frame.pts is not None else first_frame.dts img = first_frame.to_rgb().to_ndarray() if decode_rgb else first_frame.to_ndarray(format=\"bgr24\") cur = DecodedFrame( image=img, pts=pts, time_s=self._frame_time_s(pts), key_frame=bool(getattr(first_frame, \"key_frame\", False)), ) if pts is not None: self._frame_cache.put(int(pts), cur) return cur delta = 16 attempts = 0 while True: start_frame = max(target_frame - delta, 0) seek_to_frame(start_frame) decoder = self._fast_container.decode(self._fast_stream) try: frame = next(decoder) except StopIteration: break pts = frame.pts if frame.pts is not None else frame.dts frame_number = frame_number_from_pts(pts) if frame_number is None: frame_number = start_frame if frame_number < 0 or frame_number > target_frame: if start_frame == 0 or delta >= 1 << 30 or attempts > 20: break delta = delta * 2 if delta < 16 else int(delta * 1.5) attempts += 1 continue while frame_number < target_frame: try: frame = next(decoder) except StopIteration: frame = None break pts = frame.pts if frame.pts is not None else frame.dts frame_number = frame_number_from_pts(pts) if frame_number is None: frame_number = target_frame if frame is None: break pts = frame.pts if frame.pts is not None else frame.dts img = frame.to_rgb().to_ndarray() if decode_rgb else frame.to_ndarray(format=\"bgr24\") cur = DecodedFrame( image=img, pts=pts, time_s=self._frame_time_s(pts), key_frame=bool(getattr(frame, \"key_frame\", False)), ) if pts is not None: self._frame_cache.put(int(pts), cur) return cur target_pts = self._secs_to_pts(target_frame / fps) return self._read_frame_fast_simple(target_pts, decode_rgb=decode_rgb) def read_frame_fast( self, *, index: Optional[int] = None, t_s: Optional[Number] = None, decode_rgb: bool = True, use_sequential: bool = True, ) -> DecodedFrame: \"\"\"Return a fast, approximate frame for an index or timestamp.\"\"\" if index is None and t_s is None: raise ValueError(\"Provide either index or t_s\") if index is not None and t_s is not None: raise ValueError(\"Provide only one of index or t_s\") if t_s is None: if index is None: raise ValueError(\"Provide either index or t_s\") if index < 0: index += self.number_of_frames target_frame = int(index) else: t_s = float(t_s) target_frame = int(round(t_s * (self._nominal_frame_rate or self._frame_rate or 1.0))) if use_sequential: decoded = self._read_frame_fast_like(target_frame, decode_rgb=decode_rgb) self._last_fast_index = target_frame return decoded fps = self._nominal_frame_rate or self._frame_rate or 1.0 target_pts = self._secs_to_pts(target_frame / fps) cached = self._frame_cache.get(target_pts) if cached is not None: self._last_fast_index = target_frame return cached # type: ignore[return-value] decoded = self._read_frame_fast_opencv_pyav(target_frame, decode_rgb=decode_rgb) self._last_fast_index = target_frame return decoded def read_frame( self, *, index: Optional[int] = None, t_s: Optional[Number] = None, mode: str = \"accurate\", decode_rgb: bool = True, keyframe_mode: str = \"nearest\", use_sequential: bool = True, ) -> DecodedFrame: \"\"\"Read a frame using a selectable access mode.\"\"\" if mode not in {\"accurate\", \"accurate_timeline\", \"fast\", \"scrub\"}: raise ValueError(\"mode must be one of: 'accurate', 'accurate_timeline', 'fast', 'scrub'\") if index is None and t_s is None: raise ValueError(\"Provide either index or t_s\") if index is not None and t_s is not None: raise ValueError(\"Provide only one of index or t_s\") if mode == \"accurate\": if index is not None: return self._read_frame_at_index( int(index), decode_rgb=decode_rgb, use_sequential=use_sequential, ) assert t_s is not None return self.read_frame_at(float(t_s), use_index=False) if mode == \"accurate_timeline\": if t_s is None: fps = self._nominal_frame_rate or self._frame_rate or 1.0 t_s = float(index) / fps return self.read_frame_at(float(t_s)) if mode == \"scrub\": if t_s is None: fps = self._frame_rate or 1.0 t_s = float(index) / fps return self.read_keyframe_at(float(t_s), mode=keyframe_mode, decode_rgb=decode_rgb) return self.read_frame_fast( index=index, t_s=t_s, decode_rgb=decode_rgb, use_sequential=use_sequential, ) def read_next_frame(self, *, decode_rgb: bool = True) -> DecodedFrame: \"\"\"Return the next frame using sequential decoding.\"\"\" self._ensure_seq_container() assert self._seq_decoder is not None try: frame = next(self._seq_decoder) except StopIteration: raise pts = frame.pts if frame.pts is not None else frame.dts img = frame.to_rgb().to_ndarray() if decode_rgb else frame.to_ndarray(format=\"bgr24\") cur = DecodedFrame( image=img, pts=pts, time_s=self._frame_time_s(pts), key_frame=bool(getattr(frame, \"key_frame\", False)), ) if pts is not None: self._frame_cache.put(int(pts), cur) self._current_frame_pos = float(self._seq_frame_index) self._last_index = int(self._seq_frame_index) self._last_fast_index = int(self._seq_frame_index) self._seq_frame_index += 1 return cur def iter_frames(self, *, decode_rgb: bool = True) -> Iterator[DecodedFrame]: \"\"\"Iterate through frames sequentially.\"\"\" self.reset_sequence() assert self._seq_decoder is not None for frame in self._seq_decoder: pts = frame.pts if frame.pts is not None else frame.dts img = frame.to_rgb().to_ndarray() if decode_rgb else frame.to_ndarray(format=\"bgr24\") cur = DecodedFrame( image=img, pts=pts, time_s=self._frame_time_s(pts), key_frame=bool(getattr(frame, \"key_frame\", False)), ) if pts is not None: self._frame_cache.put(int(pts), cur) self._current_frame_pos = float(self._seq_frame_index) self._seq_frame_index += 1 yield cur _bucket_to_kfidx = _LRU(scrub_bucket_lru_size) instance-attribute _codec_ctx = self._stream.codec_context instance-attribute _container = av.open(path) instance-attribute _current_frame_pos = 0.0 instance-attribute _fast_container = None instance-attribute _fast_decoder = None instance-attribute _fast_first_frame_number = None instance-attribute _fast_last_pts = None instance-attribute _fast_stream = None instance-attribute _fourcc = self._compute_fourcc() instance-attribute _frame_cache = _LRU(decoded_frame_cache_size) instance-attribute _frame_count = int(self._stream.frames or 0) instance-attribute _frame_format = 0 instance-attribute _frame_height = int(self._stream.height or 0) instance-attribute _frame_pts = None instance-attribute _frame_rate = self._compute_frame_rate() instance-attribute _frame_shape = (self._frame_height, self._frame_width, 3) instance-attribute _frame_width = int(self._stream.width or 0) instance-attribute _index_built = False instance-attribute _keyframes = [] instance-attribute _last_fast_index = None instance-attribute _last_index = None instance-attribute _nominal_frame_rate = self._compute_nominal_frame_rate() instance-attribute _path = path instance-attribute _scrub_bucket_ms = max(1, int(scrub_bucket_ms)) instance-attribute _seq_container = None instance-attribute _seq_decoder = None instance-attribute _seq_frame_index = 0 instance-attribute _seq_stream = None instance-attribute _start_pts = self._stream.start_time if self._stream.start_time is not None else 0 instance-attribute _stream = self._container.streams.video[video_stream_index] instance-attribute _thread_count = int(thread_count) instance-attribute _threading = bool(threading) instance-attribute _time_base = self._stream.time_base instance-attribute current_frame_pos property Return the last frame index accessed. fourcc property Return the fourcc codec identifier. frame_format property Return the frame format identifier. frame_height property Return the video frame height. frame_rate property Return the reported frame rate in frames per second. frame_shape property Return the expected frame shape (H, W, C). frame_width property Return the video frame width. nominal_frame_rate property Return the nominal frame rate (guessed_rate when available). number_of_frames property Return the total number of frames, decoding if needed. __enter__() Return self for context manager usage. Source code in acvr/_pyav_backend.py def __enter__(self) -> \"PyAVVideoBackend\": \"\"\"Return self for context manager usage.\"\"\" return self __exit__(exc_type, exc, tb) Close the backend on exit from a context manager. Source code in acvr/_pyav_backend.py def __exit__(self, exc_type, exc, tb) -> None: \"\"\"Close the backend on exit from a context manager.\"\"\" self.close() __init__(path, video_stream_index=0, *, build_index=False, decoded_frame_cache_size=0, scrub_bucket_ms=25, scrub_bucket_lru_size=4096, threading=True, thread_count=0) Initialize the PyAV-backed decoder. Source code in acvr/_pyav_backend.py def __init__( self, path: str, video_stream_index: int = 0, *, build_index: bool = False, decoded_frame_cache_size: int = 0, scrub_bucket_ms: int = 25, scrub_bucket_lru_size: int = 4096, threading: bool = True, thread_count: int = 0, ) -> None: \"\"\"Initialize the PyAV-backed decoder.\"\"\" self._path = path self._container = av.open(path) self._stream = self._container.streams.video[video_stream_index] self._codec_ctx = self._stream.codec_context self._fast_container: Optional[av.container.InputContainer] = None self._fast_stream: Optional[av.video.stream.VideoStream] = None self._fast_first_frame_number: Optional[int] = None self._fast_decoder = None self._fast_last_pts: Optional[int] = None self._seq_container: Optional[av.container.InputContainer] = None self._seq_stream: Optional[av.video.stream.VideoStream] = None self._seq_decoder = None self._seq_frame_index: int = 0 self._last_index: Optional[int] = None self._last_fast_index: Optional[int] = None self._time_base: Fraction = self._stream.time_base self._start_pts: int = self._stream.start_time if self._stream.start_time is not None else 0 self._keyframes: List[KeyframeEntry] = [] self._index_built: bool = False self._frame_pts: Optional[List[int]] = None self._frame_count: int = int(self._stream.frames or 0) self._current_frame_pos: float = 0.0 self._frame_cache = _LRU(decoded_frame_cache_size) self._scrub_bucket_ms = max(1, int(scrub_bucket_ms)) self._bucket_to_kfidx = _LRU(scrub_bucket_lru_size) self._threading = bool(threading) self._thread_count = int(thread_count) if build_index: self.build_keyframe_index() self._frame_height = int(self._stream.height or 0) self._frame_width = int(self._stream.width or 0) self._frame_shape = (self._frame_height, self._frame_width, 3) self._frame_rate = self._compute_frame_rate() self._nominal_frame_rate = self._compute_nominal_frame_rate() self._fourcc = self._compute_fourcc() self._frame_format = 0 _bucket_key(t_s) Return a bucket key for the scrub acceleration cache. Source code in acvr/_pyav_backend.py def _bucket_key(self, t_s: float) -> int: \"\"\"Return a bucket key for the scrub acceleration cache.\"\"\" return int(round(t_s * 1000.0 / self._scrub_bucket_ms)) _compute_fourcc() Compute a fourcc code from the stream codec tag. Source code in acvr/_pyav_backend.py def _compute_fourcc(self) -> int: \"\"\"Compute a fourcc code from the stream codec tag.\"\"\" tag = self._stream.codec_context.codec_tag if isinstance(tag, str) and len(tag) >= 4: tag = tag[:4] return ( ord(tag[0]) | (ord(tag[1]) << 8) | (ord(tag[2]) << 16) | (ord(tag[3]) << 24) ) return 0 _compute_frame_rate() Compute the stream frame rate in frames per second. Source code in acvr/_pyav_backend.py def _compute_frame_rate(self) -> float: \"\"\"Compute the stream frame rate in frames per second.\"\"\" rate = self._stream.average_rate or self._stream.base_rate return float(rate) if rate is not None else 0.0 _compute_nominal_frame_rate() Compute a nominal frame rate preferring guessed_rate (useful for VFR). Source code in acvr/_pyav_backend.py def _compute_nominal_frame_rate(self) -> float: \"\"\"Compute a nominal frame rate preferring guessed_rate (useful for VFR).\"\"\" rate = getattr(self._stream, \"guessed_rate\", None) or self._stream.average_rate or self._stream.base_rate return float(rate) if rate is not None else 0.0 _configure_codec_context(stream) Apply conservative threading settings to a codec context. Source code in acvr/_pyav_backend.py def _configure_codec_context(self, stream: av.video.stream.VideoStream) -> None: \"\"\"Apply conservative threading settings to a codec context.\"\"\" try: codec_ctx = stream.codec_context if self._threading: codec_ctx.thread_type = \"AUTO\" codec_ctx.thread_count = self._thread_count else: codec_ctx.thread_type = \"NONE\" codec_ctx.thread_count = 1 except Exception: pass _ensure_fast_container() Initialize the fast-seek container if needed. Source code in acvr/_pyav_backend.py def _ensure_fast_container(self) -> None: \"\"\"Initialize the fast-seek container if needed.\"\"\" if self._fast_container is not None: return self._fast_container = av.open(self._path) self._fast_stream = self._fast_container.streams.video[self._stream.index] self._configure_codec_context(self._fast_stream) _ensure_frame_pts() Decode the stream once to collect frame PTS values. Source code in acvr/_pyav_backend.py def _ensure_frame_pts(self) -> None: \"\"\"Decode the stream once to collect frame PTS values.\"\"\" if self._frame_pts is not None: return idx_container = av.open(self._path) idx_stream = idx_container.streams.video[self._stream.index] self._configure_codec_context(idx_stream) self._configure_codec_context(idx_stream) pts_list: List[int] = [] for frame in idx_container.decode(idx_stream): pts = frame.pts if frame.pts is not None else frame.dts if pts is None: pts = self._start_pts + len(pts_list) pts_list.append(int(pts)) idx_container.close() self._frame_pts = pts_list self._frame_count = len(pts_list) _ensure_seq_container() Initialize a sequential decode container if needed. Source code in acvr/_pyav_backend.py def _ensure_seq_container(self) -> None: \"\"\"Initialize a sequential decode container if needed.\"\"\" if self._seq_container is not None: return self._seq_container = av.open(self._path) self._seq_stream = self._seq_container.streams.video[self._stream.index] self._configure_codec_context(self._seq_stream) self._seq_decoder = self._seq_container.decode(self._seq_stream) self._seq_frame_index = 0 _fast_frame_to_pts(frame_index, fps) Convert a frame index to expected PTS for fast reads. Source code in acvr/_pyav_backend.py def _fast_frame_to_pts(self, frame_index: int, fps: float) -> int: \"\"\"Convert a frame index to expected PTS for fast reads.\"\"\" if frame_index <= 0: return self._start_pts return self._secs_to_pts(frame_index / fps) _fast_rewind() Rewind the fast-seek container and reset decoder state. Source code in acvr/_pyav_backend.py def _fast_rewind(self) -> None: \"\"\"Rewind the fast-seek container and reset decoder state.\"\"\" self._ensure_fast_container() assert self._fast_container is not None assert self._fast_stream is not None self._fast_container.seek(0) self._fast_decoder = self._fast_container.decode(self._fast_stream) self._fast_last_pts = None _flush_decoder() Flush decoder buffers if supported. Source code in acvr/_pyav_backend.py def _flush_decoder(self) -> None: \"\"\"Flush decoder buffers if supported.\"\"\" try: self._codec_ctx.flush_buffers() except Exception: pass _frame_time_s(pts) Return the timestamp for a frame PTS. Source code in acvr/_pyav_backend.py def _frame_time_s(self, pts: Optional[int]) -> float: \"\"\"Return the timestamp for a frame PTS.\"\"\" return float(\"nan\") if pts is None else self._pts_to_secs(pts) _keyframe_index_at_or_before_pts(target_pts) Return keyframe index at or before the target PTS. Source code in acvr/_pyav_backend.py def _keyframe_index_at_or_before_pts(self, target_pts: int) -> int: \"\"\"Return keyframe index at or before the target PTS.\"\"\" kf = self._keyframes if not self._index_built or not kf: return 0 if target_pts <= kf[0].pts: return 0 if target_pts >= kf[-1].pts: return len(kf) - 1 lo, hi = 0, len(kf) - 1 while lo <= hi: mid = (lo + hi) // 2 m = kf[mid].pts if m == target_pts: return mid if m < target_pts: lo = mid + 1 else: hi = mid - 1 return hi _keyframe_index_for_time_fast(t_s, mode) Return a keyframe index using cached time buckets. Source code in acvr/_pyav_backend.py def _keyframe_index_for_time_fast(self, t_s: float, mode: str) -> int: \"\"\"Return a keyframe index using cached time buckets.\"\"\" if not self._index_built: raise RuntimeError(\"Keyframe index not built. Call build_keyframe_index() first.\") b = self._bucket_key(t_s) mode_tag = {\"previous\": 0, \"nearest\": 1, \"next\": 2}.get(mode) if mode_tag is None: raise ValueError(\"mode must be one of: 'previous', 'nearest', 'next'\") cache_key = (b << 2) | mode_tag cached = self._bucket_to_kfidx.get(cache_key) if cached is not None: return int(cached) target_pts = self._secs_to_pts(t_s) if mode == \"previous\": idx = self._keyframe_index_at_or_before_pts(target_pts) elif mode == \"nearest\": idx = self._keyframe_index_nearest_pts(target_pts) else: i_prev = self._keyframe_index_at_or_before_pts(target_pts) if self._keyframes[i_prev].pts >= target_pts: idx = i_prev else: idx = min(i_prev + 1, len(self._keyframes) - 1) self._bucket_to_kfidx.put(cache_key, idx) return idx _keyframe_index_nearest_pts(target_pts) Return nearest keyframe index to the target PTS. Source code in acvr/_pyav_backend.py def _keyframe_index_nearest_pts(self, target_pts: int) -> int: \"\"\"Return nearest keyframe index to the target PTS.\"\"\" kf = self._keyframes if not self._index_built or not kf: return 0 i0 = self._keyframe_index_at_or_before_pts(target_pts) i1 = min(i0 + 1, len(kf) - 1) if i0 == i1: return i0 d0 = abs(kf[i0].pts - target_pts) d1 = abs(kf[i1].pts - target_pts) return i0 if d0 <= d1 else i1 _pts_to_frame_number(pts, fps) Convert a PTS value to a rounded frame number. Source code in acvr/_pyav_backend.py def _pts_to_frame_number(self, pts: Optional[int], fps: float) -> Optional[int]: \"\"\"Convert a PTS value to a rounded frame number.\"\"\" if pts is None: return None return int(round(self._pts_to_secs(int(pts)) * fps)) _pts_to_secs(pts) Convert presentation timestamp units to seconds. Source code in acvr/_pyav_backend.py def _pts_to_secs(self, pts: int) -> float: \"\"\"Convert presentation timestamp units to seconds.\"\"\" return float((pts - self._start_pts) * self._time_base) _read_frame_at_index(index, *, decode_rgb=True, use_sequential=True) Return the decoded frame at a zero-based index. Source code in acvr/_pyav_backend.py def _read_frame_at_index( self, index: int, *, decode_rgb: bool = True, use_sequential: bool = True, ) -> DecodedFrame: \"\"\"Return the decoded frame at a zero-based index.\"\"\" if use_sequential and index >= 0: if self._seq_decoder is not None and index == self._seq_frame_index: return self.read_next_frame(decode_rgb=decode_rgb) if self._seq_decoder is None and index == 0: self.reset_sequence() return self.read_next_frame(decode_rgb=decode_rgb) self._ensure_frame_pts() assert self._frame_pts is not None if index < 0: index += self._frame_count if index < 0 or index >= self._frame_count: raise IndexError(\"frame index out of range\") target_pts = self._frame_pts[index] if use_sequential and self._seq_decoder is not None and index == self._seq_frame_index: try: decoded = self.read_next_frame(decode_rgb=decode_rgb) except StopIteration: decoded = self._seek_seq_to_pts(target_pts, target_index=index, decode_rgb=decode_rgb) elif use_sequential and self._last_index is not None and index == self._last_index + 1: decoded = self._seek_seq_to_pts(target_pts, target_index=index, decode_rgb=decode_rgb) else: decoded = self._read_frame_by_pts(target_pts, decode_rgb=decode_rgb) self._current_frame_pos = float(index) self._last_index = index return decoded _read_frame_by_pts(target_pts, *, decode_rgb=True) Decode the first frame at or after a target PTS. Source code in acvr/_pyav_backend.py def _read_frame_by_pts(self, target_pts: int, *, decode_rgb: bool = True) -> DecodedFrame: \"\"\"Decode the first frame at or after a target PTS.\"\"\" cached = self._frame_cache.get(target_pts) if cached is not None: return cached # type: ignore[return-value] if self._index_built: idx = self._keyframe_index_at_or_before_pts(target_pts) seek_pts = self._keyframes[idx].pts else: seek_pts = target_pts container = av.open(self._path) stream = container.streams.video[self._stream.index] self._configure_codec_context(stream) try: container.seek(seek_pts, stream=stream, backward=True, any_frame=False) try: stream.codec_context.flush_buffers() except Exception: pass last: Optional[DecodedFrame] = None for packet in container.demux(stream): for frame in packet.decode(): pts = frame.pts image = frame.to_rgb().to_ndarray() if decode_rgb else frame.to_ndarray(format=\"bgr24\") cur = DecodedFrame( image=image, pts=pts, time_s=self._frame_time_s(pts), key_frame=bool(getattr(frame, \"key_frame\", False)), ) if pts is not None: self._frame_cache.put(int(pts), cur) if pts is None: last = cur continue if pts >= target_pts: return cur last = cur finally: container.close() if last is not None: return last raise RuntimeError(\"Could not decode any frames after seeking.\") _read_frame_fast_like(target_frame, *, decode_rgb) Approximate FastVideoReader behavior for fast sequential reads. Source code in acvr/_pyav_backend.py def _read_frame_fast_like(self, target_frame: int, *, decode_rgb: bool) -> DecodedFrame: \"\"\"Approximate FastVideoReader behavior for fast sequential reads.\"\"\" fps = self._nominal_frame_rate or self._frame_rate or 1.0 pts_per_frame = 1.0 / (fps * float(self._time_base)) if fps else 1.0 wiggle = pts_per_frame / 10.0 if target_frame <= 0: self._fast_rewind() assert self._fast_decoder is not None frame = next(self._fast_decoder) pts = frame.pts if frame.pts is not None else frame.dts if pts is None: pts = self._fast_frame_to_pts(0, fps) img = frame.to_rgb().to_ndarray() if decode_rgb else frame.to_ndarray(format=\"bgr24\") cur = DecodedFrame( image=img, pts=pts, time_s=self._frame_time_s(pts), key_frame=bool(getattr(frame, \"key_frame\", False)), ) if pts is not None: self._frame_cache.put(int(pts), cur) return cur expected_prev_pts = self._fast_frame_to_pts(target_frame - 1, fps) if self._fast_decoder is not None and self._fast_last_pts == expected_prev_pts: try: frame = next(self._fast_decoder) except StopIteration: frame = None if frame is not None: pts = frame.pts if frame.pts is not None else frame.dts if pts is None: pts = self._fast_frame_to_pts(target_frame, fps) img = frame.to_rgb().to_ndarray() if decode_rgb else frame.to_ndarray(format=\"bgr24\") cur = DecodedFrame( image=img, pts=pts, time_s=self._frame_time_s(pts), key_frame=bool(getattr(frame, \"key_frame\", False)), ) if pts is not None: self._frame_cache.put(int(pts), cur) self._fast_last_pts = int(pts) if pts is not None else None return cur self._ensure_fast_container() assert self._fast_container is not None assert self._fast_stream is not None target_pts = self._fast_frame_to_pts(target_frame, fps) self._fast_container.seek( target_pts, stream=self._fast_stream, backward=True, any_frame=False, ) try: self._fast_stream.codec_context.flush_buffers() except Exception: pass self._fast_decoder = self._fast_container.decode(self._fast_stream) self._fast_last_pts = None try: frame = next(self._fast_decoder) except StopIteration: frame = None if frame is None: return self._read_frame_fast_simple(target_pts, decode_rgb=decode_rgb) cur_pts = frame.pts if frame.pts is not None else frame.dts if cur_pts is None: cur_pts = target_pts if cur_pts > target_pts: back = max(1, int(round(100))) back_pts = self._fast_frame_to_pts(max(0, target_frame - back), fps) self._fast_container.seek( back_pts, stream=self._fast_stream, backward=True, any_frame=False, ) try: self._fast_stream.codec_context.flush_buffers() except Exception: pass self._fast_decoder = self._fast_container.decode(self._fast_stream) try: frame = next(self._fast_decoder) except StopIteration: frame = None if frame is None: return self._read_frame_fast_simple(target_pts, decode_rgb=decode_rgb) cur_pts = frame.pts if frame.pts is not None else frame.dts if cur_pts is None: cur_pts = target_pts while float(cur_pts) < (float(target_pts) - wiggle): try: frame = next(self._fast_decoder) except StopIteration: frame = None break if frame is None: break cur_pts = frame.pts if frame.pts is not None else frame.dts if cur_pts is None: cur_pts = target_pts break if frame is None: return self._read_frame_fast_simple(target_pts, decode_rgb=decode_rgb) img = frame.to_rgb().to_ndarray() if decode_rgb else frame.to_ndarray(format=\"bgr24\") cur = DecodedFrame( image=img, pts=cur_pts, time_s=self._frame_time_s(cur_pts), key_frame=bool(getattr(frame, \"key_frame\", False)), ) if cur_pts is not None: self._frame_cache.put(int(cur_pts), cur) self._fast_last_pts = int(cur_pts) else: self._fast_last_pts = None return cur _read_frame_fast_opencv_pyav(target_frame, *, decode_rgb) Approximate OpenCV seek behavior using PyAV. Source code in acvr/_pyav_backend.py def _read_frame_fast_opencv_pyav(self, target_frame: int, *, decode_rgb: bool) -> DecodedFrame: \"\"\"Approximate OpenCV seek behavior using PyAV.\"\"\" fps = self._nominal_frame_rate or self._frame_rate or 1.0 self._ensure_fast_container() assert self._fast_container is not None assert self._fast_stream is not None def seek_to_frame(frame_index: int) -> None: target_pts = self._secs_to_pts(frame_index / fps) self._fast_container.seek( target_pts, stream=self._fast_stream, backward=True, any_frame=False, ) try: self._fast_stream.codec_context.flush_buffers() except Exception: pass def frame_number_from_pts(pts: Optional[int]) -> Optional[int]: num = self._pts_to_frame_number(pts, fps) if num is None: return None if self._fast_first_frame_number is None: return num return num - self._fast_first_frame_number first_frame = None if self._fast_first_frame_number is None: seek_to_frame(0) for frame in self._fast_container.decode(self._fast_stream): pts = frame.pts if frame.pts is not None else frame.dts self._fast_first_frame_number = self._pts_to_frame_number(pts, fps) or 0 first_frame = frame break if target_frame <= 0: if first_frame is None: seek_to_frame(0) for frame in self._fast_container.decode(self._fast_stream): first_frame = frame break if first_frame is None: raise RuntimeError(\"Failed to decode a frame after fast seek.\") pts = first_frame.pts if first_frame.pts is not None else first_frame.dts img = first_frame.to_rgb().to_ndarray() if decode_rgb else first_frame.to_ndarray(format=\"bgr24\") cur = DecodedFrame( image=img, pts=pts, time_s=self._frame_time_s(pts), key_frame=bool(getattr(first_frame, \"key_frame\", False)), ) if pts is not None: self._frame_cache.put(int(pts), cur) return cur delta = 16 attempts = 0 while True: start_frame = max(target_frame - delta, 0) seek_to_frame(start_frame) decoder = self._fast_container.decode(self._fast_stream) try: frame = next(decoder) except StopIteration: break pts = frame.pts if frame.pts is not None else frame.dts frame_number = frame_number_from_pts(pts) if frame_number is None: frame_number = start_frame if frame_number < 0 or frame_number > target_frame: if start_frame == 0 or delta >= 1 << 30 or attempts > 20: break delta = delta * 2 if delta < 16 else int(delta * 1.5) attempts += 1 continue while frame_number < target_frame: try: frame = next(decoder) except StopIteration: frame = None break pts = frame.pts if frame.pts is not None else frame.dts frame_number = frame_number_from_pts(pts) if frame_number is None: frame_number = target_frame if frame is None: break pts = frame.pts if frame.pts is not None else frame.dts img = frame.to_rgb().to_ndarray() if decode_rgb else frame.to_ndarray(format=\"bgr24\") cur = DecodedFrame( image=img, pts=pts, time_s=self._frame_time_s(pts), key_frame=bool(getattr(frame, \"key_frame\", False)), ) if pts is not None: self._frame_cache.put(int(pts), cur) return cur target_pts = self._secs_to_pts(target_frame / fps) return self._read_frame_fast_simple(target_pts, decode_rgb=decode_rgb) _read_frame_fast_simple(target_pts, *, decode_rgb) Fallback fast seek: seek and decode first frame after PTS. Source code in acvr/_pyav_backend.py def _read_frame_fast_simple(self, target_pts: int, *, decode_rgb: bool) -> DecodedFrame: \"\"\"Fallback fast seek: seek and decode first frame after PTS.\"\"\" self._ensure_fast_container() assert self._fast_container is not None assert self._fast_stream is not None def grab_frame(container: av.container.InputContainer, stream: av.video.stream.VideoStream) -> Optional[DecodedFrame]: for frame in container.decode(stream): pts = frame.pts if frame.pts is not None else frame.dts if pts is None: target_reached = True else: target_reached = pts >= target_pts if not target_reached: continue if decode_rgb: img = frame.to_rgb().to_ndarray() else: img = frame.to_ndarray(format=\"bgr24\") cur = DecodedFrame( image=img, pts=pts, time_s=self._frame_time_s(pts), key_frame=bool(getattr(frame, \"key_frame\", False)), ) if pts is not None: self._frame_cache.put(int(pts), cur) return cur return None self._fast_container.seek( target_pts, stream=self._fast_stream, backward=True, any_frame=True, ) try: self._fast_stream.codec_context.flush_buffers() except Exception: pass grabbed = grab_frame(self._fast_container, self._fast_stream) if grabbed is not None: return grabbed self._fast_container.seek( target_pts, stream=self._fast_stream, backward=True, any_frame=False, ) try: self._fast_stream.codec_context.flush_buffers() except Exception: pass grabbed = grab_frame(self._fast_container, self._fast_stream) if grabbed is not None: return grabbed raise RuntimeError(\"Failed to decode a frame after fast seek.\") _secs_to_pts(t_s) Convert seconds to presentation timestamp units. Source code in acvr/_pyav_backend.py def _secs_to_pts(self, t_s: float) -> int: \"\"\"Convert seconds to presentation timestamp units.\"\"\" ticks = int(round(t_s / float(self._time_base))) return self._start_pts + ticks _seek_seq_to_pts(target_pts, *, target_index, decode_rgb, any_frame=False) Seek the sequential decoder to a PTS and return the first match. Source code in acvr/_pyav_backend.py def _seek_seq_to_pts( self, target_pts: int, *, target_index: int, decode_rgb: bool, any_frame: bool = False, ) -> DecodedFrame: \"\"\"Seek the sequential decoder to a PTS and return the first match.\"\"\" self._ensure_seq_container() assert self._seq_container is not None assert self._seq_stream is not None seek_pts = target_pts if self._keyframes and not any_frame: idx = self._keyframe_index_at_or_before_pts(target_pts) seek_pts = self._keyframes[idx].pts self._seq_container.seek( seek_pts, stream=self._seq_stream, backward=True, any_frame=any_frame, ) try: self._seq_stream.codec_context.flush_buffers() except Exception: pass decoder = self._seq_container.decode(self._seq_stream) last: Optional[DecodedFrame] = None for frame in decoder: pts = frame.pts if frame.pts is not None else frame.dts img = frame.to_rgb().to_ndarray() if decode_rgb else frame.to_ndarray(format=\"bgr24\") cur = DecodedFrame( image=img, pts=pts, time_s=self._frame_time_s(pts), key_frame=bool(getattr(frame, \"key_frame\", False)), ) if pts is not None: self._frame_cache.put(int(pts), cur) if pts is None: last = cur continue if pts >= target_pts: self._seq_decoder = decoder self._seq_frame_index = target_index + 1 self._current_frame_pos = float(target_index) return cur last = cur if last is not None: self._seq_decoder = decoder self._seq_frame_index = target_index + 1 self._current_frame_pos = float(target_index) return last raise RuntimeError(\"Could not decode any frames after seeking.\") _seek_to_pts(pts, *, backward) Seek to a timestamp in the stream. Source code in acvr/_pyav_backend.py def _seek_to_pts(self, pts: int, *, backward: bool) -> None: \"\"\"Seek to a timestamp in the stream.\"\"\" self._container.seek(pts, stream=self._stream, backward=backward, any_frame=False) self._flush_decoder() build_keyframe_index(*, max_packets=None) Scan packets and store keyframe pts/time. Source code in acvr/_pyav_backend.py def build_keyframe_index(self, *, max_packets: Optional[int] = None) -> List[KeyframeEntry]: \"\"\"Scan packets and store keyframe pts/time.\"\"\" path = self._container.name idx_container = av.open(path) idx_stream = idx_container.streams.video[self._stream.index] key_pts: List[int] = [] n = 0 for packet in idx_container.demux(idx_stream): if packet.dts is None and packet.pts is None: continue if packet.is_keyframe: pts = packet.pts if packet.pts is not None else packet.dts if pts is not None: key_pts.append(int(pts)) n += 1 if max_packets is not None and n >= max_packets: break idx_container.close() key_pts = sorted(set(key_pts)) if not key_pts: key_pts = [self._start_pts] self._keyframes = [KeyframeEntry(pts=p, time_s=self._pts_to_secs(p)) for p in key_pts] self._index_built = True self._bucket_to_kfidx.clear() return self._keyframes close() Close the underlying PyAV container. Source code in acvr/_pyav_backend.py def close(self) -> None: \"\"\"Close the underlying PyAV container.\"\"\" self._container.close() if self._fast_container is not None: self._fast_container.close() self._fast_container = None self._fast_stream = None self._fast_decoder = None self._fast_last_pts = None self._fast_first_frame_number = None if self._seq_container is not None: self._seq_container.close() self._seq_container = None self._seq_stream = None self._seq_decoder = None self._seq_frame_index = 0 self._last_index = None self._last_fast_index = None frame_at_index(index) Return the decoded frame at a zero-based index. Source code in acvr/_pyav_backend.py def frame_at_index(self, index: int) -> np.ndarray: \"\"\"Return the decoded frame at a zero-based index.\"\"\" return self._read_frame_at_index(index, decode_rgb=True, use_sequential=True).image index_from_pts(pts) Map a PTS value to the nearest frame index. Source code in acvr/_pyav_backend.py def index_from_pts(self, pts: int) -> int: \"\"\"Map a PTS value to the nearest frame index.\"\"\" self._ensure_frame_pts() assert self._frame_pts is not None fps = self._frame_pts if not fps: return 0 lo, hi = 0, len(fps) - 1 if pts <= fps[0]: return 0 if pts >= fps[-1]: return hi while lo <= hi: mid = (lo + hi) // 2 m = fps[mid] if m == pts: return mid if m < pts: lo = mid + 1 else: hi = mid - 1 # choose nearest between hi and lo if lo >= len(fps): return hi if hi < 0: return lo return lo if abs(fps[lo] - pts) < abs(fps[hi] - pts) else hi index_from_time(t_s) Map a timestamp in seconds to the nearest frame index. Source code in acvr/_pyav_backend.py def index_from_time(self, t_s: float) -> int: \"\"\"Map a timestamp in seconds to the nearest frame index.\"\"\" pts = self._secs_to_pts(float(t_s)) return self.index_from_pts(int(pts)) iter_frames(*, decode_rgb=True) Iterate through frames sequentially. Source code in acvr/_pyav_backend.py def iter_frames(self, *, decode_rgb: bool = True) -> Iterator[DecodedFrame]: \"\"\"Iterate through frames sequentially.\"\"\" self.reset_sequence() assert self._seq_decoder is not None for frame in self._seq_decoder: pts = frame.pts if frame.pts is not None else frame.dts img = frame.to_rgb().to_ndarray() if decode_rgb else frame.to_ndarray(format=\"bgr24\") cur = DecodedFrame( image=img, pts=pts, time_s=self._frame_time_s(pts), key_frame=bool(getattr(frame, \"key_frame\", False)), ) if pts is not None: self._frame_cache.put(int(pts), cur) self._current_frame_pos = float(self._seq_frame_index) self._seq_frame_index += 1 yield cur pts_at_index(index) Return the presentation timestamp (PTS) for a frame index. Source code in acvr/_pyav_backend.py def pts_at_index(self, index: int) -> Optional[int]: \"\"\"Return the presentation timestamp (PTS) for a frame index.\"\"\" self._ensure_frame_pts() assert self._frame_pts is not None if index < 0: index += self._frame_count if index < 0 or index >= self._frame_count: raise IndexError(\"frame index out of range\") return int(self._frame_pts[index]) read_frame(*, index=None, t_s=None, mode='accurate', decode_rgb=True, keyframe_mode='nearest', use_sequential=True) Read a frame using a selectable access mode. Source code in acvr/_pyav_backend.py def read_frame( self, *, index: Optional[int] = None, t_s: Optional[Number] = None, mode: str = \"accurate\", decode_rgb: bool = True, keyframe_mode: str = \"nearest\", use_sequential: bool = True, ) -> DecodedFrame: \"\"\"Read a frame using a selectable access mode.\"\"\" if mode not in {\"accurate\", \"accurate_timeline\", \"fast\", \"scrub\"}: raise ValueError(\"mode must be one of: 'accurate', 'accurate_timeline', 'fast', 'scrub'\") if index is None and t_s is None: raise ValueError(\"Provide either index or t_s\") if index is not None and t_s is not None: raise ValueError(\"Provide only one of index or t_s\") if mode == \"accurate\": if index is not None: return self._read_frame_at_index( int(index), decode_rgb=decode_rgb, use_sequential=use_sequential, ) assert t_s is not None return self.read_frame_at(float(t_s), use_index=False) if mode == \"accurate_timeline\": if t_s is None: fps = self._nominal_frame_rate or self._frame_rate or 1.0 t_s = float(index) / fps return self.read_frame_at(float(t_s)) if mode == \"scrub\": if t_s is None: fps = self._frame_rate or 1.0 t_s = float(index) / fps return self.read_keyframe_at(float(t_s), mode=keyframe_mode, decode_rgb=decode_rgb) return self.read_frame_fast( index=index, t_s=t_s, decode_rgb=decode_rgb, use_sequential=use_sequential, ) read_frame_at(t_s, *, return_first_after=True, max_decode_frames=10000, use_index=True) Decode a frame near a timestamp with accurate seeking. Simplified and robust: always uses a fresh container and backward keyframe seek. Source code in acvr/_pyav_backend.py def read_frame_at( self, t_s: Number, *, return_first_after: bool = True, max_decode_frames: int = 10_000, use_index: bool = True, ) -> DecodedFrame: \"\"\"Decode a frame near a timestamp with accurate seeking. Simplified and robust: always uses a fresh container and backward keyframe seek. \"\"\" t_s = float(t_s) target_pts = self._secs_to_pts(t_s) cached = self._frame_cache.get(target_pts) if cached is not None: return cached # type: ignore[return-value] container = av.open(self._path) try: stream = container.streams.video[self._stream.index] self._configure_codec_context(stream) if use_index and self._index_built: idx = self._keyframe_index_at_or_before_pts(target_pts) anchor_pts = self._keyframes[idx].pts container.seek(anchor_pts, stream=stream, backward=True, any_frame=False) else: container.seek(target_pts, stream=stream, backward=True, any_frame=False) try: stream.codec_context.flush_buffers() except Exception: pass last: Optional[DecodedFrame] = None decoded = 0 for packet in container.demux(stream): for frame in packet.decode(): decoded += 1 if decoded > max_decode_frames: raise RuntimeError( \"Exceeded max_decode_frames while seeking; timestamps may be broken.\" ) pts = frame.pts cur = DecodedFrame( image=frame.to_rgb().to_ndarray(), pts=pts, time_s=self._frame_time_s(pts), key_frame=bool(getattr(frame, \"key_frame\", False)), ) if pts is not None: self._frame_cache.put(int(pts), cur) if pts is None: last = cur continue if return_first_after: if pts >= target_pts: return cur last = cur else: if pts <= target_pts: last = cur elif last is not None: return last if last is not None: return last raise RuntimeError(\"Could not decode any frames after seeking.\") finally: container.close() read_frame_fast(*, index=None, t_s=None, decode_rgb=True, use_sequential=True) Return a fast, approximate frame for an index or timestamp. Source code in acvr/_pyav_backend.py def read_frame_fast( self, *, index: Optional[int] = None, t_s: Optional[Number] = None, decode_rgb: bool = True, use_sequential: bool = True, ) -> DecodedFrame: \"\"\"Return a fast, approximate frame for an index or timestamp.\"\"\" if index is None and t_s is None: raise ValueError(\"Provide either index or t_s\") if index is not None and t_s is not None: raise ValueError(\"Provide only one of index or t_s\") if t_s is None: if index is None: raise ValueError(\"Provide either index or t_s\") if index < 0: index += self.number_of_frames target_frame = int(index) else: t_s = float(t_s) target_frame = int(round(t_s * (self._nominal_frame_rate or self._frame_rate or 1.0))) if use_sequential: decoded = self._read_frame_fast_like(target_frame, decode_rgb=decode_rgb) self._last_fast_index = target_frame return decoded fps = self._nominal_frame_rate or self._frame_rate or 1.0 target_pts = self._secs_to_pts(target_frame / fps) cached = self._frame_cache.get(target_pts) if cached is not None: self._last_fast_index = target_frame return cached # type: ignore[return-value] decoded = self._read_frame_fast_opencv_pyav(target_frame, decode_rgb=decode_rgb) self._last_fast_index = target_frame return decoded read_keyframe_at(t_s, *, mode='nearest', decode_rgb=True) Return a nearby keyframe without GOP forward decoding. Source code in acvr/_pyav_backend.py def read_keyframe_at( self, t_s: Number, *, mode: str = \"nearest\", decode_rgb: bool = True, ) -> DecodedFrame: \"\"\"Return a nearby keyframe without GOP forward decoding.\"\"\" t_s = float(t_s) idx = self._keyframe_index_for_time_fast(t_s, mode) key_pts = self._keyframes[idx].pts cached = self._frame_cache.get(key_pts) if cached is not None: return cached # type: ignore[return-value] # Use a fresh container for reliable keyframe seek, avoiding stateful issues container = av.open(self._path) try: stream = container.streams.video[self._stream.index] self._configure_codec_context(stream) # Use backward seek to land on or before the requested keyframe PTS reliably container.seek(key_pts, stream=stream, backward=True, any_frame=False) try: stream.codec_context.flush_buffers() except Exception: pass for packet in container.demux(stream): for frame in packet.decode(): pts = frame.pts img = frame.to_rgb().to_ndarray() if decode_rgb else frame.to_ndarray() cur = DecodedFrame( image=img, pts=pts, time_s=self._frame_time_s(pts), key_frame=bool(getattr(frame, \"key_frame\", False)), ) if pts is not None: self._frame_cache.put(int(pts), cur) return cur finally: container.close() raise RuntimeError(\"Failed to decode a frame after keyframe seek.\") read_next_frame(*, decode_rgb=True) Return the next frame using sequential decoding. Source code in acvr/_pyav_backend.py def read_next_frame(self, *, decode_rgb: bool = True) -> DecodedFrame: \"\"\"Return the next frame using sequential decoding.\"\"\" self._ensure_seq_container() assert self._seq_decoder is not None try: frame = next(self._seq_decoder) except StopIteration: raise pts = frame.pts if frame.pts is not None else frame.dts img = frame.to_rgb().to_ndarray() if decode_rgb else frame.to_ndarray(format=\"bgr24\") cur = DecodedFrame( image=img, pts=pts, time_s=self._frame_time_s(pts), key_frame=bool(getattr(frame, \"key_frame\", False)), ) if pts is not None: self._frame_cache.put(int(pts), cur) self._current_frame_pos = float(self._seq_frame_index) self._last_index = int(self._seq_frame_index) self._last_fast_index = int(self._seq_frame_index) self._seq_frame_index += 1 return cur reset_sequence() Reset sequential decoding to the first frame. Source code in acvr/_pyav_backend.py def reset_sequence(self) -> None: \"\"\"Reset sequential decoding to the first frame.\"\"\" self._ensure_seq_container() assert self._seq_container is not None assert self._seq_stream is not None try: self._seq_container.seek(0) except Exception: pass self._seq_decoder = self._seq_container.decode(self._seq_stream) self._seq_frame_index = 0 time_at_index(index) Return the timestamp in seconds for a frame index. Source code in acvr/_pyav_backend.py def time_at_index(self, index: int) -> float: \"\"\"Return the timestamp in seconds for a frame index.\"\"\" pts = self.pts_at_index(index) return float(\"nan\") if pts is None else self._pts_to_secs(int(pts))","title":"API"},{"location":"api/#videoreader","text":"High-level video reader with array-style access. Source code in acvr/reader.py class VideoReader: \"\"\"High-level video reader with array-style access.\"\"\" def __init__( self, path: str, video_stream_index: int = 0, *, build_index: bool = True, decoded_frame_cache_size: int = 0, scrub_bucket_ms: int = 25, scrub_bucket_lru_size: int = 4096, threading: bool = True, thread_count: int = 0, index_policy: str = \"decode\", ) -> None: \"\"\"Create a reader for the given video path. Args: path: Path to the video file to open. video_stream_index: Video stream index to decode. build_index: Whether to build a keyframe index on initialization (default True); can speed up accurate random seeks but adds upfront cost. speed up accurate random seeks but adds upfront cost. decoded_frame_cache_size: Number of decoded frames to keep in an in-memory LRU cache; helpful for repeated access to nearby frames. scrub_bucket_ms: Bucket size (milliseconds) used to group timestamps for fast scrub queries. scrub_bucket_lru_size: LRU size for the scrub bucket cache. threading: Whether to enable threaded decoding in the backend. thread_count: Number of decoding threads (0 lets backend decide). index_policy: Indexing policy, either ``\"decode\"`` for decode-order frames or ``\"timeline\"`` for timestamp-based access. Raises: ValueError: If ``index_policy`` is not ``\"decode\"`` or ``\"timeline\"``. \"\"\" self._backend = PyAVVideoBackend( path, video_stream_index=video_stream_index, build_index=build_index, decoded_frame_cache_size=decoded_frame_cache_size, scrub_bucket_ms=scrub_bucket_ms, scrub_bucket_lru_size=scrub_bucket_lru_size, threading=threading, thread_count=thread_count, ) if index_policy not in {\"decode\", \"timeline\"}: raise ValueError(\"index_policy must be 'decode' or 'timeline'\") self._index_policy = index_policy def close(self) -> None: \"\"\"Close the underlying video resources.\"\"\" self._backend.close() def __enter__(self) -> \"VideoReader\": \"\"\"Return self for context manager usage.\"\"\" return self def __exit__(self, exc_type, exc, tb) -> None: \"\"\"Close the reader when leaving a context manager. Args: exc_type: Exception type, if any. exc: Exception instance, if any. tb: Traceback, if any. \"\"\" self.close() def __len__(self) -> int: \"\"\"Return the number of frames in the video.\"\"\" return self.number_of_frames def __getitem__(self, key: IndexKey) -> Union[np.ndarray, List[np.ndarray]]: \"\"\"Return a frame or list of frames for the given index or slice. Indexing semantics are controlled by `index_policy`: - 'decode' (default): index refers to decode-order frame number. - 'timeline': index is mapped to timestamp using nominal FPS, and an accurate timestamp seek is performed. Args: key: Frame index or slice to retrieve. Returns: A single frame array or list of frame arrays. \"\"\" if isinstance(key, slice): start, stop, step = key.indices(self.number_of_frames) return [self[i] for i in range(start, stop, step)] i = int(key) if self._index_policy == \"decode\": return self._backend.frame_at_index(i) # timeline policy fps = self.nominal_frame_rate or self.frame_rate or 1.0 t_s = float(i) / fps return self._backend.read_frame_at(t_s).image def __iter__(self) -> Iterator[np.ndarray]: \"\"\"Iterate over all frames in the video.\"\"\" return self.iter_frames() @property def frame_height(self) -> int: \"\"\"Return the frame height in pixels.\"\"\" return self._backend.frame_height @property def frame_width(self) -> int: \"\"\"Return the frame width in pixels.\"\"\" return self._backend.frame_width @property def frame_rate(self) -> float: \"\"\"Return the video frame rate.\"\"\" return self._backend.frame_rate @property def nominal_frame_rate(self) -> float: \"\"\"Return the nominal video frame rate (guessed_rate when available).\"\"\" return self._backend.nominal_frame_rate @property def fourcc(self) -> int: \"\"\"Return the fourcc codec identifier.\"\"\" return self._backend.fourcc @property def frame_format(self) -> int: \"\"\"Return the pixel format identifier.\"\"\" return self._backend.frame_format @property def number_of_frames(self) -> int: \"\"\"Return the total number of frames.\"\"\" return self._backend.number_of_frames @property def frame_shape(self) -> tuple: \"\"\"Return the expected frame shape (H, W, C).\"\"\" return self._backend.frame_shape @property def current_frame_pos(self) -> float: \"\"\"Return the last accessed frame index.\"\"\" return self._backend.current_frame_pos def build_keyframe_index(self, *, max_packets: Optional[int] = None) -> List[KeyframeEntry]: \"\"\"Build a keyframe index for faster random access. Args: max_packets: Optional cap on packets to inspect. Returns: A list of keyframe entries. \"\"\" return self._backend.build_keyframe_index(max_packets=max_packets) def read_keyframe_at( self, t_s: float, *, mode: str = \"nearest\", decode_rgb: bool = True, ) -> DecodedFrame: \"\"\"Return a nearby keyframe for fast scrubbing. Args: t_s: Timestamp in seconds to seek around. mode: Selection mode (``\"nearest\"``, ``\"before\"``, or ``\"after\"``). decode_rgb: Whether to decode into RGB arrays. Returns: The decoded keyframe. \"\"\" return self._backend.read_keyframe_at(t_s, mode=mode, decode_rgb=decode_rgb) def read_frame_at( self, t_s: float, *, return_first_after: bool = True, max_decode_frames: int = 10_000, use_index: bool = True, ) -> DecodedFrame: \"\"\"Return a frame at a timestamp with accurate seeking. Args: t_s: Timestamp in seconds to seek to. return_first_after: Return the first frame after the timestamp. max_decode_frames: Cap on frames to decode while seeking. use_index: Whether to use the keyframe index if available. Returns: The decoded frame at the target timestamp. \"\"\" return self._backend.read_frame_at( t_s, return_first_after=return_first_after, max_decode_frames=max_decode_frames, use_index=use_index, ) def read_frame_fast( self, *, index: Optional[int] = None, t_s: Optional[float] = None, decode_rgb: bool = True, use_sequential: bool = True, ) -> DecodedFrame: \"\"\"Return a fast, approximate frame for an index or timestamp. Args: index: Decode-order frame index to seek to. t_s: Timestamp in seconds to seek to. decode_rgb: Whether to decode into RGB arrays. use_sequential: Allow sequential decoding when available. Returns: The decoded frame closest to the request. \"\"\" return self._backend.read_frame_fast( index=index, t_s=t_s, decode_rgb=decode_rgb, use_sequential=use_sequential, ) def read_next(self, *, decode_rgb: bool = True) -> np.ndarray: \"\"\"Return the next frame using sequential decoding. Args: decode_rgb: Whether to decode into RGB arrays. Returns: The next decoded frame image. \"\"\" return self._backend.read_next_frame(decode_rgb=decode_rgb).image def iter_frames(self, *, decode_rgb: bool = True) -> Iterator[np.ndarray]: \"\"\"Iterate frames sequentially without seeking.\"\"\" for frame in self._backend.iter_frames(decode_rgb=decode_rgb): yield frame.image # Public PTS/time helpers def pts_at_index(self, index: int) -> Optional[int]: \"\"\"Return the PTS for a given frame index.\"\"\" return self._backend.pts_at_index(int(index)) def time_at_index(self, index: int) -> float: \"\"\"Return the timestamp (seconds) for a given frame index.\"\"\" return self._backend.time_at_index(int(index)) def index_from_pts(self, pts: int) -> int: \"\"\"Return the nearest frame index for a PTS value.\"\"\" return self._backend.index_from_pts(int(pts)) def index_from_time(self, t_s: float) -> int: \"\"\"Return the nearest frame index for a timestamp in seconds.\"\"\" return self._backend.index_from_time(float(t_s)) def read_frame( self, *, index: Optional[int] = None, t_s: Optional[float] = None, mode: str = \"accurate\", decode_rgb: bool = True, keyframe_mode: str = \"nearest\", use_sequential: bool = True, ) -> DecodedFrame: \"\"\"Read a frame using a selectable access mode.\"\"\" return self._backend.read_frame( index=index, t_s=t_s, mode=mode, decode_rgb=decode_rgb, keyframe_mode=keyframe_mode, use_sequential=use_sequential, )","title":"VideoReader"},{"location":"api/#acvr.reader.VideoReader._backend","text":"","title":"_backend"},{"location":"api/#acvr.reader.VideoReader._index_policy","text":"","title":"_index_policy"},{"location":"api/#acvr.reader.VideoReader.current_frame_pos","text":"Return the last accessed frame index.","title":"current_frame_pos"},{"location":"api/#acvr.reader.VideoReader.fourcc","text":"Return the fourcc codec identifier.","title":"fourcc"},{"location":"api/#acvr.reader.VideoReader.frame_format","text":"Return the pixel format identifier.","title":"frame_format"},{"location":"api/#acvr.reader.VideoReader.frame_height","text":"Return the frame height in pixels.","title":"frame_height"},{"location":"api/#acvr.reader.VideoReader.frame_rate","text":"Return the video frame rate.","title":"frame_rate"},{"location":"api/#acvr.reader.VideoReader.frame_shape","text":"Return the expected frame shape (H, W, C).","title":"frame_shape"},{"location":"api/#acvr.reader.VideoReader.frame_width","text":"Return the frame width in pixels.","title":"frame_width"},{"location":"api/#acvr.reader.VideoReader.nominal_frame_rate","text":"Return the nominal video frame rate (guessed_rate when available).","title":"nominal_frame_rate"},{"location":"api/#acvr.reader.VideoReader.number_of_frames","text":"Return the total number of frames.","title":"number_of_frames"},{"location":"api/#acvr.reader.VideoReader.__enter__","text":"Return self for context manager usage. Source code in acvr/reader.py def __enter__(self) -> \"VideoReader\": \"\"\"Return self for context manager usage.\"\"\" return self","title":"__enter__"},{"location":"api/#acvr.reader.VideoReader.__exit__","text":"Close the reader when leaving a context manager. Parameters: Name Type Description Default exc_type Exception type, if any. required exc Exception instance, if any. required tb Traceback, if any. required Source code in acvr/reader.py def __exit__(self, exc_type, exc, tb) -> None: \"\"\"Close the reader when leaving a context manager. Args: exc_type: Exception type, if any. exc: Exception instance, if any. tb: Traceback, if any. \"\"\" self.close()","title":"__exit__"},{"location":"api/#acvr.reader.VideoReader.__getitem__","text":"Return a frame or list of frames for the given index or slice. Indexing semantics are controlled by index_policy : - 'decode' (default): index refers to decode-order frame number. - 'timeline': index is mapped to timestamp using nominal FPS, and an accurate timestamp seek is performed. Parameters: Name Type Description Default key IndexKey Frame index or slice to retrieve. required Returns: Type Description Union [ ndarray , List [ ndarray ]] A single frame array or list of frame arrays. Source code in acvr/reader.py def __getitem__(self, key: IndexKey) -> Union[np.ndarray, List[np.ndarray]]: \"\"\"Return a frame or list of frames for the given index or slice. Indexing semantics are controlled by `index_policy`: - 'decode' (default): index refers to decode-order frame number. - 'timeline': index is mapped to timestamp using nominal FPS, and an accurate timestamp seek is performed. Args: key: Frame index or slice to retrieve. Returns: A single frame array or list of frame arrays. \"\"\" if isinstance(key, slice): start, stop, step = key.indices(self.number_of_frames) return [self[i] for i in range(start, stop, step)] i = int(key) if self._index_policy == \"decode\": return self._backend.frame_at_index(i) # timeline policy fps = self.nominal_frame_rate or self.frame_rate or 1.0 t_s = float(i) / fps return self._backend.read_frame_at(t_s).image","title":"__getitem__"},{"location":"api/#acvr.reader.VideoReader.__init__","text":"Create a reader for the given video path. Parameters: Name Type Description Default path str Path to the video file to open. required video_stream_index int Video stream index to decode. 0 build_index bool Whether to build a keyframe index on initialization (default True); can speed up accurate random seeks but adds upfront cost. speed up accurate random seeks but adds upfront cost. True decoded_frame_cache_size int Number of decoded frames to keep in an in-memory LRU cache; helpful for repeated access to nearby frames. 0 scrub_bucket_ms int Bucket size (milliseconds) used to group timestamps for fast scrub queries. 25 scrub_bucket_lru_size int LRU size for the scrub bucket cache. 4096 threading bool Whether to enable threaded decoding in the backend. True thread_count int Number of decoding threads (0 lets backend decide). 0 index_policy str Indexing policy, either \"decode\" for decode-order frames or \"timeline\" for timestamp-based access. 'decode' Raises: Type Description ValueError If index_policy is not \"decode\" or \"timeline\" . Source code in acvr/reader.py def __init__( self, path: str, video_stream_index: int = 0, *, build_index: bool = True, decoded_frame_cache_size: int = 0, scrub_bucket_ms: int = 25, scrub_bucket_lru_size: int = 4096, threading: bool = True, thread_count: int = 0, index_policy: str = \"decode\", ) -> None: \"\"\"Create a reader for the given video path. Args: path: Path to the video file to open. video_stream_index: Video stream index to decode. build_index: Whether to build a keyframe index on initialization (default True); can speed up accurate random seeks but adds upfront cost. speed up accurate random seeks but adds upfront cost. decoded_frame_cache_size: Number of decoded frames to keep in an in-memory LRU cache; helpful for repeated access to nearby frames. scrub_bucket_ms: Bucket size (milliseconds) used to group timestamps for fast scrub queries. scrub_bucket_lru_size: LRU size for the scrub bucket cache. threading: Whether to enable threaded decoding in the backend. thread_count: Number of decoding threads (0 lets backend decide). index_policy: Indexing policy, either ``\"decode\"`` for decode-order frames or ``\"timeline\"`` for timestamp-based access. Raises: ValueError: If ``index_policy`` is not ``\"decode\"`` or ``\"timeline\"``. \"\"\" self._backend = PyAVVideoBackend( path, video_stream_index=video_stream_index, build_index=build_index, decoded_frame_cache_size=decoded_frame_cache_size, scrub_bucket_ms=scrub_bucket_ms, scrub_bucket_lru_size=scrub_bucket_lru_size, threading=threading, thread_count=thread_count, ) if index_policy not in {\"decode\", \"timeline\"}: raise ValueError(\"index_policy must be 'decode' or 'timeline'\") self._index_policy = index_policy","title":"__init__"},{"location":"api/#acvr.reader.VideoReader.__iter__","text":"Iterate over all frames in the video. Source code in acvr/reader.py def __iter__(self) -> Iterator[np.ndarray]: \"\"\"Iterate over all frames in the video.\"\"\" return self.iter_frames()","title":"__iter__"},{"location":"api/#acvr.reader.VideoReader.__len__","text":"Return the number of frames in the video. Source code in acvr/reader.py def __len__(self) -> int: \"\"\"Return the number of frames in the video.\"\"\" return self.number_of_frames","title":"__len__"},{"location":"api/#acvr.reader.VideoReader.build_keyframe_index","text":"Build a keyframe index for faster random access. Parameters: Name Type Description Default max_packets Optional [ int ] Optional cap on packets to inspect. None Returns: Type Description List [ KeyframeEntry ] A list of keyframe entries. Source code in acvr/reader.py def build_keyframe_index(self, *, max_packets: Optional[int] = None) -> List[KeyframeEntry]: \"\"\"Build a keyframe index for faster random access. Args: max_packets: Optional cap on packets to inspect. Returns: A list of keyframe entries. \"\"\" return self._backend.build_keyframe_index(max_packets=max_packets)","title":"build_keyframe_index"},{"location":"api/#acvr.reader.VideoReader.close","text":"Close the underlying video resources. Source code in acvr/reader.py def close(self) -> None: \"\"\"Close the underlying video resources.\"\"\" self._backend.close()","title":"close"},{"location":"api/#acvr.reader.VideoReader.index_from_pts","text":"Return the nearest frame index for a PTS value. Source code in acvr/reader.py def index_from_pts(self, pts: int) -> int: \"\"\"Return the nearest frame index for a PTS value.\"\"\" return self._backend.index_from_pts(int(pts))","title":"index_from_pts"},{"location":"api/#acvr.reader.VideoReader.index_from_time","text":"Return the nearest frame index for a timestamp in seconds. Source code in acvr/reader.py def index_from_time(self, t_s: float) -> int: \"\"\"Return the nearest frame index for a timestamp in seconds.\"\"\" return self._backend.index_from_time(float(t_s))","title":"index_from_time"},{"location":"api/#acvr.reader.VideoReader.iter_frames","text":"Iterate frames sequentially without seeking. Source code in acvr/reader.py def iter_frames(self, *, decode_rgb: bool = True) -> Iterator[np.ndarray]: \"\"\"Iterate frames sequentially without seeking.\"\"\" for frame in self._backend.iter_frames(decode_rgb=decode_rgb): yield frame.image","title":"iter_frames"},{"location":"api/#acvr.reader.VideoReader.pts_at_index","text":"Return the PTS for a given frame index. Source code in acvr/reader.py def pts_at_index(self, index: int) -> Optional[int]: \"\"\"Return the PTS for a given frame index.\"\"\" return self._backend.pts_at_index(int(index))","title":"pts_at_index"},{"location":"api/#acvr.reader.VideoReader.read_frame","text":"Read a frame using a selectable access mode. Source code in acvr/reader.py def read_frame( self, *, index: Optional[int] = None, t_s: Optional[float] = None, mode: str = \"accurate\", decode_rgb: bool = True, keyframe_mode: str = \"nearest\", use_sequential: bool = True, ) -> DecodedFrame: \"\"\"Read a frame using a selectable access mode.\"\"\" return self._backend.read_frame( index=index, t_s=t_s, mode=mode, decode_rgb=decode_rgb, keyframe_mode=keyframe_mode, use_sequential=use_sequential, )","title":"read_frame"},{"location":"api/#acvr.reader.VideoReader.read_frame_at","text":"Return a frame at a timestamp with accurate seeking. Parameters: Name Type Description Default t_s float Timestamp in seconds to seek to. required return_first_after bool Return the first frame after the timestamp. True max_decode_frames int Cap on frames to decode while seeking. 10000 use_index bool Whether to use the keyframe index if available. True Returns: Type Description DecodedFrame The decoded frame at the target timestamp. Source code in acvr/reader.py def read_frame_at( self, t_s: float, *, return_first_after: bool = True, max_decode_frames: int = 10_000, use_index: bool = True, ) -> DecodedFrame: \"\"\"Return a frame at a timestamp with accurate seeking. Args: t_s: Timestamp in seconds to seek to. return_first_after: Return the first frame after the timestamp. max_decode_frames: Cap on frames to decode while seeking. use_index: Whether to use the keyframe index if available. Returns: The decoded frame at the target timestamp. \"\"\" return self._backend.read_frame_at( t_s, return_first_after=return_first_after, max_decode_frames=max_decode_frames, use_index=use_index, )","title":"read_frame_at"},{"location":"api/#acvr.reader.VideoReader.read_frame_fast","text":"Return a fast, approximate frame for an index or timestamp. Parameters: Name Type Description Default index Optional [ int ] Decode-order frame index to seek to. None t_s Optional [ float ] Timestamp in seconds to seek to. None decode_rgb bool Whether to decode into RGB arrays. True use_sequential bool Allow sequential decoding when available. True Returns: Type Description DecodedFrame The decoded frame closest to the request. Source code in acvr/reader.py def read_frame_fast( self, *, index: Optional[int] = None, t_s: Optional[float] = None, decode_rgb: bool = True, use_sequential: bool = True, ) -> DecodedFrame: \"\"\"Return a fast, approximate frame for an index or timestamp. Args: index: Decode-order frame index to seek to. t_s: Timestamp in seconds to seek to. decode_rgb: Whether to decode into RGB arrays. use_sequential: Allow sequential decoding when available. Returns: The decoded frame closest to the request. \"\"\" return self._backend.read_frame_fast( index=index, t_s=t_s, decode_rgb=decode_rgb, use_sequential=use_sequential, )","title":"read_frame_fast"},{"location":"api/#acvr.reader.VideoReader.read_keyframe_at","text":"Return a nearby keyframe for fast scrubbing. Parameters: Name Type Description Default t_s float Timestamp in seconds to seek around. required mode str Selection mode ( \"nearest\" , \"before\" , or \"after\" ). 'nearest' decode_rgb bool Whether to decode into RGB arrays. True Returns: Type Description DecodedFrame The decoded keyframe. Source code in acvr/reader.py def read_keyframe_at( self, t_s: float, *, mode: str = \"nearest\", decode_rgb: bool = True, ) -> DecodedFrame: \"\"\"Return a nearby keyframe for fast scrubbing. Args: t_s: Timestamp in seconds to seek around. mode: Selection mode (``\"nearest\"``, ``\"before\"``, or ``\"after\"``). decode_rgb: Whether to decode into RGB arrays. Returns: The decoded keyframe. \"\"\" return self._backend.read_keyframe_at(t_s, mode=mode, decode_rgb=decode_rgb)","title":"read_keyframe_at"},{"location":"api/#acvr.reader.VideoReader.read_next","text":"Return the next frame using sequential decoding. Parameters: Name Type Description Default decode_rgb bool Whether to decode into RGB arrays. True Returns: Type Description ndarray The next decoded frame image. Source code in acvr/reader.py def read_next(self, *, decode_rgb: bool = True) -> np.ndarray: \"\"\"Return the next frame using sequential decoding. Args: decode_rgb: Whether to decode into RGB arrays. Returns: The next decoded frame image. \"\"\" return self._backend.read_next_frame(decode_rgb=decode_rgb).image","title":"read_next"},{"location":"api/#acvr.reader.VideoReader.time_at_index","text":"Return the timestamp (seconds) for a given frame index. Source code in acvr/reader.py def time_at_index(self, index: int) -> float: \"\"\"Return the timestamp (seconds) for a given frame index.\"\"\" return self._backend.time_at_index(int(index))","title":"time_at_index"},{"location":"api/#backend-implementation","text":"Frame-accurate seeking with keyframe index and scrub acceleration. Source code in acvr/_pyav_backend.py class PyAVVideoBackend: \"\"\"Frame-accurate seeking with keyframe index and scrub acceleration.\"\"\" def __init__( self, path: str, video_stream_index: int = 0, *, build_index: bool = False, decoded_frame_cache_size: int = 0, scrub_bucket_ms: int = 25, scrub_bucket_lru_size: int = 4096, threading: bool = True, thread_count: int = 0, ) -> None: \"\"\"Initialize the PyAV-backed decoder.\"\"\" self._path = path self._container = av.open(path) self._stream = self._container.streams.video[video_stream_index] self._codec_ctx = self._stream.codec_context self._fast_container: Optional[av.container.InputContainer] = None self._fast_stream: Optional[av.video.stream.VideoStream] = None self._fast_first_frame_number: Optional[int] = None self._fast_decoder = None self._fast_last_pts: Optional[int] = None self._seq_container: Optional[av.container.InputContainer] = None self._seq_stream: Optional[av.video.stream.VideoStream] = None self._seq_decoder = None self._seq_frame_index: int = 0 self._last_index: Optional[int] = None self._last_fast_index: Optional[int] = None self._time_base: Fraction = self._stream.time_base self._start_pts: int = self._stream.start_time if self._stream.start_time is not None else 0 self._keyframes: List[KeyframeEntry] = [] self._index_built: bool = False self._frame_pts: Optional[List[int]] = None self._frame_count: int = int(self._stream.frames or 0) self._current_frame_pos: float = 0.0 self._frame_cache = _LRU(decoded_frame_cache_size) self._scrub_bucket_ms = max(1, int(scrub_bucket_ms)) self._bucket_to_kfidx = _LRU(scrub_bucket_lru_size) self._threading = bool(threading) self._thread_count = int(thread_count) if build_index: self.build_keyframe_index() self._frame_height = int(self._stream.height or 0) self._frame_width = int(self._stream.width or 0) self._frame_shape = (self._frame_height, self._frame_width, 3) self._frame_rate = self._compute_frame_rate() self._nominal_frame_rate = self._compute_nominal_frame_rate() self._fourcc = self._compute_fourcc() self._frame_format = 0 def close(self) -> None: \"\"\"Close the underlying PyAV container.\"\"\" self._container.close() if self._fast_container is not None: self._fast_container.close() self._fast_container = None self._fast_stream = None self._fast_decoder = None self._fast_last_pts = None self._fast_first_frame_number = None if self._seq_container is not None: self._seq_container.close() self._seq_container = None self._seq_stream = None self._seq_decoder = None self._seq_frame_index = 0 self._last_index = None self._last_fast_index = None def __enter__(self) -> \"PyAVVideoBackend\": \"\"\"Return self for context manager usage.\"\"\" return self def __exit__(self, exc_type, exc, tb) -> None: \"\"\"Close the backend on exit from a context manager.\"\"\" self.close() def _secs_to_pts(self, t_s: float) -> int: \"\"\"Convert seconds to presentation timestamp units.\"\"\" ticks = int(round(t_s / float(self._time_base))) return self._start_pts + ticks def _pts_to_secs(self, pts: int) -> float: \"\"\"Convert presentation timestamp units to seconds.\"\"\" return float((pts - self._start_pts) * self._time_base) def _pts_to_frame_number(self, pts: Optional[int], fps: float) -> Optional[int]: \"\"\"Convert a PTS value to a rounded frame number.\"\"\" if pts is None: return None return int(round(self._pts_to_secs(int(pts)) * fps)) def _frame_time_s(self, pts: Optional[int]) -> float: \"\"\"Return the timestamp for a frame PTS.\"\"\" return float(\"nan\") if pts is None else self._pts_to_secs(pts) def _flush_decoder(self) -> None: \"\"\"Flush decoder buffers if supported.\"\"\" try: self._codec_ctx.flush_buffers() except Exception: pass def _compute_frame_rate(self) -> float: \"\"\"Compute the stream frame rate in frames per second.\"\"\" rate = self._stream.average_rate or self._stream.base_rate return float(rate) if rate is not None else 0.0 def _compute_nominal_frame_rate(self) -> float: \"\"\"Compute a nominal frame rate preferring guessed_rate (useful for VFR).\"\"\" rate = getattr(self._stream, \"guessed_rate\", None) or self._stream.average_rate or self._stream.base_rate return float(rate) if rate is not None else 0.0 @property def nominal_frame_rate(self) -> float: \"\"\"Return the nominal frame rate (guessed_rate when available).\"\"\" return self._nominal_frame_rate def _compute_fourcc(self) -> int: \"\"\"Compute a fourcc code from the stream codec tag.\"\"\" tag = self._stream.codec_context.codec_tag if isinstance(tag, str) and len(tag) >= 4: tag = tag[:4] return ( ord(tag[0]) | (ord(tag[1]) << 8) | (ord(tag[2]) << 16) | (ord(tag[3]) << 24) ) return 0 def _ensure_frame_pts(self) -> None: \"\"\"Decode the stream once to collect frame PTS values.\"\"\" if self._frame_pts is not None: return idx_container = av.open(self._path) idx_stream = idx_container.streams.video[self._stream.index] self._configure_codec_context(idx_stream) self._configure_codec_context(idx_stream) pts_list: List[int] = [] for frame in idx_container.decode(idx_stream): pts = frame.pts if frame.pts is not None else frame.dts if pts is None: pts = self._start_pts + len(pts_list) pts_list.append(int(pts)) idx_container.close() self._frame_pts = pts_list self._frame_count = len(pts_list) def _read_frame_by_pts(self, target_pts: int, *, decode_rgb: bool = True) -> DecodedFrame: \"\"\"Decode the first frame at or after a target PTS.\"\"\" cached = self._frame_cache.get(target_pts) if cached is not None: return cached # type: ignore[return-value] if self._index_built: idx = self._keyframe_index_at_or_before_pts(target_pts) seek_pts = self._keyframes[idx].pts else: seek_pts = target_pts container = av.open(self._path) stream = container.streams.video[self._stream.index] self._configure_codec_context(stream) try: container.seek(seek_pts, stream=stream, backward=True, any_frame=False) try: stream.codec_context.flush_buffers() except Exception: pass last: Optional[DecodedFrame] = None for packet in container.demux(stream): for frame in packet.decode(): pts = frame.pts image = frame.to_rgb().to_ndarray() if decode_rgb else frame.to_ndarray(format=\"bgr24\") cur = DecodedFrame( image=image, pts=pts, time_s=self._frame_time_s(pts), key_frame=bool(getattr(frame, \"key_frame\", False)), ) if pts is not None: self._frame_cache.put(int(pts), cur) if pts is None: last = cur continue if pts >= target_pts: return cur last = cur finally: container.close() if last is not None: return last raise RuntimeError(\"Could not decode any frames after seeking.\") def _read_frame_at_index( self, index: int, *, decode_rgb: bool = True, use_sequential: bool = True, ) -> DecodedFrame: \"\"\"Return the decoded frame at a zero-based index.\"\"\" if use_sequential and index >= 0: if self._seq_decoder is not None and index == self._seq_frame_index: return self.read_next_frame(decode_rgb=decode_rgb) if self._seq_decoder is None and index == 0: self.reset_sequence() return self.read_next_frame(decode_rgb=decode_rgb) self._ensure_frame_pts() assert self._frame_pts is not None if index < 0: index += self._frame_count if index < 0 or index >= self._frame_count: raise IndexError(\"frame index out of range\") target_pts = self._frame_pts[index] if use_sequential and self._seq_decoder is not None and index == self._seq_frame_index: try: decoded = self.read_next_frame(decode_rgb=decode_rgb) except StopIteration: decoded = self._seek_seq_to_pts(target_pts, target_index=index, decode_rgb=decode_rgb) elif use_sequential and self._last_index is not None and index == self._last_index + 1: decoded = self._seek_seq_to_pts(target_pts, target_index=index, decode_rgb=decode_rgb) else: decoded = self._read_frame_by_pts(target_pts, decode_rgb=decode_rgb) self._current_frame_pos = float(index) self._last_index = index return decoded def frame_at_index(self, index: int) -> np.ndarray: \"\"\"Return the decoded frame at a zero-based index.\"\"\" return self._read_frame_at_index(index, decode_rgb=True, use_sequential=True).image # # Public helpers for PTS/time mapping # def pts_at_index(self, index: int) -> Optional[int]: \"\"\"Return the presentation timestamp (PTS) for a frame index.\"\"\" self._ensure_frame_pts() assert self._frame_pts is not None if index < 0: index += self._frame_count if index < 0 or index >= self._frame_count: raise IndexError(\"frame index out of range\") return int(self._frame_pts[index]) def time_at_index(self, index: int) -> float: \"\"\"Return the timestamp in seconds for a frame index.\"\"\" pts = self.pts_at_index(index) return float(\"nan\") if pts is None else self._pts_to_secs(int(pts)) def index_from_pts(self, pts: int) -> int: \"\"\"Map a PTS value to the nearest frame index.\"\"\" self._ensure_frame_pts() assert self._frame_pts is not None fps = self._frame_pts if not fps: return 0 lo, hi = 0, len(fps) - 1 if pts <= fps[0]: return 0 if pts >= fps[-1]: return hi while lo <= hi: mid = (lo + hi) // 2 m = fps[mid] if m == pts: return mid if m < pts: lo = mid + 1 else: hi = mid - 1 # choose nearest between hi and lo if lo >= len(fps): return hi if hi < 0: return lo return lo if abs(fps[lo] - pts) < abs(fps[hi] - pts) else hi def index_from_time(self, t_s: float) -> int: \"\"\"Map a timestamp in seconds to the nearest frame index.\"\"\" pts = self._secs_to_pts(float(t_s)) return self.index_from_pts(int(pts)) @property def frame_height(self) -> int: \"\"\"Return the video frame height.\"\"\" return self._frame_height @property def frame_width(self) -> int: \"\"\"Return the video frame width.\"\"\" return self._frame_width @property def frame_rate(self) -> float: \"\"\"Return the reported frame rate in frames per second.\"\"\" return self._frame_rate @property def fourcc(self) -> int: \"\"\"Return the fourcc codec identifier.\"\"\" return self._fourcc @property def frame_format(self) -> int: \"\"\"Return the frame format identifier.\"\"\" return self._frame_format @property def number_of_frames(self) -> int: \"\"\"Return the total number of frames, decoding if needed.\"\"\" if self._frame_count <= 0: self._ensure_frame_pts() return self._frame_count @property def frame_shape(self) -> tuple: \"\"\"Return the expected frame shape (H, W, C).\"\"\" return self._frame_shape @property def current_frame_pos(self) -> float: \"\"\"Return the last frame index accessed.\"\"\" return self._current_frame_pos def _seek_to_pts(self, pts: int, *, backward: bool) -> None: \"\"\"Seek to a timestamp in the stream.\"\"\" self._container.seek(pts, stream=self._stream, backward=backward, any_frame=False) self._flush_decoder() def _ensure_fast_container(self) -> None: \"\"\"Initialize the fast-seek container if needed.\"\"\" if self._fast_container is not None: return self._fast_container = av.open(self._path) self._fast_stream = self._fast_container.streams.video[self._stream.index] self._configure_codec_context(self._fast_stream) def _configure_codec_context(self, stream: av.video.stream.VideoStream) -> None: \"\"\"Apply conservative threading settings to a codec context.\"\"\" try: codec_ctx = stream.codec_context if self._threading: codec_ctx.thread_type = \"AUTO\" codec_ctx.thread_count = self._thread_count else: codec_ctx.thread_type = \"NONE\" codec_ctx.thread_count = 1 except Exception: pass def _fast_rewind(self) -> None: \"\"\"Rewind the fast-seek container and reset decoder state.\"\"\" self._ensure_fast_container() assert self._fast_container is not None assert self._fast_stream is not None self._fast_container.seek(0) self._fast_decoder = self._fast_container.decode(self._fast_stream) self._fast_last_pts = None def _fast_frame_to_pts(self, frame_index: int, fps: float) -> int: \"\"\"Convert a frame index to expected PTS for fast reads.\"\"\" if frame_index <= 0: return self._start_pts return self._secs_to_pts(frame_index / fps) def _read_frame_fast_like(self, target_frame: int, *, decode_rgb: bool) -> DecodedFrame: \"\"\"Approximate FastVideoReader behavior for fast sequential reads.\"\"\" fps = self._nominal_frame_rate or self._frame_rate or 1.0 pts_per_frame = 1.0 / (fps * float(self._time_base)) if fps else 1.0 wiggle = pts_per_frame / 10.0 if target_frame <= 0: self._fast_rewind() assert self._fast_decoder is not None frame = next(self._fast_decoder) pts = frame.pts if frame.pts is not None else frame.dts if pts is None: pts = self._fast_frame_to_pts(0, fps) img = frame.to_rgb().to_ndarray() if decode_rgb else frame.to_ndarray(format=\"bgr24\") cur = DecodedFrame( image=img, pts=pts, time_s=self._frame_time_s(pts), key_frame=bool(getattr(frame, \"key_frame\", False)), ) if pts is not None: self._frame_cache.put(int(pts), cur) return cur expected_prev_pts = self._fast_frame_to_pts(target_frame - 1, fps) if self._fast_decoder is not None and self._fast_last_pts == expected_prev_pts: try: frame = next(self._fast_decoder) except StopIteration: frame = None if frame is not None: pts = frame.pts if frame.pts is not None else frame.dts if pts is None: pts = self._fast_frame_to_pts(target_frame, fps) img = frame.to_rgb().to_ndarray() if decode_rgb else frame.to_ndarray(format=\"bgr24\") cur = DecodedFrame( image=img, pts=pts, time_s=self._frame_time_s(pts), key_frame=bool(getattr(frame, \"key_frame\", False)), ) if pts is not None: self._frame_cache.put(int(pts), cur) self._fast_last_pts = int(pts) if pts is not None else None return cur self._ensure_fast_container() assert self._fast_container is not None assert self._fast_stream is not None target_pts = self._fast_frame_to_pts(target_frame, fps) self._fast_container.seek( target_pts, stream=self._fast_stream, backward=True, any_frame=False, ) try: self._fast_stream.codec_context.flush_buffers() except Exception: pass self._fast_decoder = self._fast_container.decode(self._fast_stream) self._fast_last_pts = None try: frame = next(self._fast_decoder) except StopIteration: frame = None if frame is None: return self._read_frame_fast_simple(target_pts, decode_rgb=decode_rgb) cur_pts = frame.pts if frame.pts is not None else frame.dts if cur_pts is None: cur_pts = target_pts if cur_pts > target_pts: back = max(1, int(round(100))) back_pts = self._fast_frame_to_pts(max(0, target_frame - back), fps) self._fast_container.seek( back_pts, stream=self._fast_stream, backward=True, any_frame=False, ) try: self._fast_stream.codec_context.flush_buffers() except Exception: pass self._fast_decoder = self._fast_container.decode(self._fast_stream) try: frame = next(self._fast_decoder) except StopIteration: frame = None if frame is None: return self._read_frame_fast_simple(target_pts, decode_rgb=decode_rgb) cur_pts = frame.pts if frame.pts is not None else frame.dts if cur_pts is None: cur_pts = target_pts while float(cur_pts) < (float(target_pts) - wiggle): try: frame = next(self._fast_decoder) except StopIteration: frame = None break if frame is None: break cur_pts = frame.pts if frame.pts is not None else frame.dts if cur_pts is None: cur_pts = target_pts break if frame is None: return self._read_frame_fast_simple(target_pts, decode_rgb=decode_rgb) img = frame.to_rgb().to_ndarray() if decode_rgb else frame.to_ndarray(format=\"bgr24\") cur = DecodedFrame( image=img, pts=cur_pts, time_s=self._frame_time_s(cur_pts), key_frame=bool(getattr(frame, \"key_frame\", False)), ) if cur_pts is not None: self._frame_cache.put(int(cur_pts), cur) self._fast_last_pts = int(cur_pts) else: self._fast_last_pts = None return cur def _ensure_seq_container(self) -> None: \"\"\"Initialize a sequential decode container if needed.\"\"\" if self._seq_container is not None: return self._seq_container = av.open(self._path) self._seq_stream = self._seq_container.streams.video[self._stream.index] self._configure_codec_context(self._seq_stream) self._seq_decoder = self._seq_container.decode(self._seq_stream) self._seq_frame_index = 0 def reset_sequence(self) -> None: \"\"\"Reset sequential decoding to the first frame.\"\"\" self._ensure_seq_container() assert self._seq_container is not None assert self._seq_stream is not None try: self._seq_container.seek(0) except Exception: pass self._seq_decoder = self._seq_container.decode(self._seq_stream) self._seq_frame_index = 0 def _seek_seq_to_pts( self, target_pts: int, *, target_index: int, decode_rgb: bool, any_frame: bool = False, ) -> DecodedFrame: \"\"\"Seek the sequential decoder to a PTS and return the first match.\"\"\" self._ensure_seq_container() assert self._seq_container is not None assert self._seq_stream is not None seek_pts = target_pts if self._keyframes and not any_frame: idx = self._keyframe_index_at_or_before_pts(target_pts) seek_pts = self._keyframes[idx].pts self._seq_container.seek( seek_pts, stream=self._seq_stream, backward=True, any_frame=any_frame, ) try: self._seq_stream.codec_context.flush_buffers() except Exception: pass decoder = self._seq_container.decode(self._seq_stream) last: Optional[DecodedFrame] = None for frame in decoder: pts = frame.pts if frame.pts is not None else frame.dts img = frame.to_rgb().to_ndarray() if decode_rgb else frame.to_ndarray(format=\"bgr24\") cur = DecodedFrame( image=img, pts=pts, time_s=self._frame_time_s(pts), key_frame=bool(getattr(frame, \"key_frame\", False)), ) if pts is not None: self._frame_cache.put(int(pts), cur) if pts is None: last = cur continue if pts >= target_pts: self._seq_decoder = decoder self._seq_frame_index = target_index + 1 self._current_frame_pos = float(target_index) return cur last = cur if last is not None: self._seq_decoder = decoder self._seq_frame_index = target_index + 1 self._current_frame_pos = float(target_index) return last raise RuntimeError(\"Could not decode any frames after seeking.\") def build_keyframe_index(self, *, max_packets: Optional[int] = None) -> List[KeyframeEntry]: \"\"\"Scan packets and store keyframe pts/time.\"\"\" path = self._container.name idx_container = av.open(path) idx_stream = idx_container.streams.video[self._stream.index] key_pts: List[int] = [] n = 0 for packet in idx_container.demux(idx_stream): if packet.dts is None and packet.pts is None: continue if packet.is_keyframe: pts = packet.pts if packet.pts is not None else packet.dts if pts is not None: key_pts.append(int(pts)) n += 1 if max_packets is not None and n >= max_packets: break idx_container.close() key_pts = sorted(set(key_pts)) if not key_pts: key_pts = [self._start_pts] self._keyframes = [KeyframeEntry(pts=p, time_s=self._pts_to_secs(p)) for p in key_pts] self._index_built = True self._bucket_to_kfidx.clear() return self._keyframes def _keyframe_index_at_or_before_pts(self, target_pts: int) -> int: \"\"\"Return keyframe index at or before the target PTS.\"\"\" kf = self._keyframes if not self._index_built or not kf: return 0 if target_pts <= kf[0].pts: return 0 if target_pts >= kf[-1].pts: return len(kf) - 1 lo, hi = 0, len(kf) - 1 while lo <= hi: mid = (lo + hi) // 2 m = kf[mid].pts if m == target_pts: return mid if m < target_pts: lo = mid + 1 else: hi = mid - 1 return hi def _keyframe_index_nearest_pts(self, target_pts: int) -> int: \"\"\"Return nearest keyframe index to the target PTS.\"\"\" kf = self._keyframes if not self._index_built or not kf: return 0 i0 = self._keyframe_index_at_or_before_pts(target_pts) i1 = min(i0 + 1, len(kf) - 1) if i0 == i1: return i0 d0 = abs(kf[i0].pts - target_pts) d1 = abs(kf[i1].pts - target_pts) return i0 if d0 <= d1 else i1 def _bucket_key(self, t_s: float) -> int: \"\"\"Return a bucket key for the scrub acceleration cache.\"\"\" return int(round(t_s * 1000.0 / self._scrub_bucket_ms)) def _keyframe_index_for_time_fast(self, t_s: float, mode: str) -> int: \"\"\"Return a keyframe index using cached time buckets.\"\"\" if not self._index_built: raise RuntimeError(\"Keyframe index not built. Call build_keyframe_index() first.\") b = self._bucket_key(t_s) mode_tag = {\"previous\": 0, \"nearest\": 1, \"next\": 2}.get(mode) if mode_tag is None: raise ValueError(\"mode must be one of: 'previous', 'nearest', 'next'\") cache_key = (b << 2) | mode_tag cached = self._bucket_to_kfidx.get(cache_key) if cached is not None: return int(cached) target_pts = self._secs_to_pts(t_s) if mode == \"previous\": idx = self._keyframe_index_at_or_before_pts(target_pts) elif mode == \"nearest\": idx = self._keyframe_index_nearest_pts(target_pts) else: i_prev = self._keyframe_index_at_or_before_pts(target_pts) if self._keyframes[i_prev].pts >= target_pts: idx = i_prev else: idx = min(i_prev + 1, len(self._keyframes) - 1) self._bucket_to_kfidx.put(cache_key, idx) return idx def read_keyframe_at( self, t_s: Number, *, mode: str = \"nearest\", decode_rgb: bool = True, ) -> DecodedFrame: \"\"\"Return a nearby keyframe without GOP forward decoding.\"\"\" t_s = float(t_s) idx = self._keyframe_index_for_time_fast(t_s, mode) key_pts = self._keyframes[idx].pts cached = self._frame_cache.get(key_pts) if cached is not None: return cached # type: ignore[return-value] # Use a fresh container for reliable keyframe seek, avoiding stateful issues container = av.open(self._path) try: stream = container.streams.video[self._stream.index] self._configure_codec_context(stream) # Use backward seek to land on or before the requested keyframe PTS reliably container.seek(key_pts, stream=stream, backward=True, any_frame=False) try: stream.codec_context.flush_buffers() except Exception: pass for packet in container.demux(stream): for frame in packet.decode(): pts = frame.pts img = frame.to_rgb().to_ndarray() if decode_rgb else frame.to_ndarray() cur = DecodedFrame( image=img, pts=pts, time_s=self._frame_time_s(pts), key_frame=bool(getattr(frame, \"key_frame\", False)), ) if pts is not None: self._frame_cache.put(int(pts), cur) return cur finally: container.close() raise RuntimeError(\"Failed to decode a frame after keyframe seek.\") def read_frame_at( self, t_s: Number, *, return_first_after: bool = True, max_decode_frames: int = 10_000, use_index: bool = True, ) -> DecodedFrame: \"\"\"Decode a frame near a timestamp with accurate seeking. Simplified and robust: always uses a fresh container and backward keyframe seek. \"\"\" t_s = float(t_s) target_pts = self._secs_to_pts(t_s) cached = self._frame_cache.get(target_pts) if cached is not None: return cached # type: ignore[return-value] container = av.open(self._path) try: stream = container.streams.video[self._stream.index] self._configure_codec_context(stream) if use_index and self._index_built: idx = self._keyframe_index_at_or_before_pts(target_pts) anchor_pts = self._keyframes[idx].pts container.seek(anchor_pts, stream=stream, backward=True, any_frame=False) else: container.seek(target_pts, stream=stream, backward=True, any_frame=False) try: stream.codec_context.flush_buffers() except Exception: pass last: Optional[DecodedFrame] = None decoded = 0 for packet in container.demux(stream): for frame in packet.decode(): decoded += 1 if decoded > max_decode_frames: raise RuntimeError( \"Exceeded max_decode_frames while seeking; timestamps may be broken.\" ) pts = frame.pts cur = DecodedFrame( image=frame.to_rgb().to_ndarray(), pts=pts, time_s=self._frame_time_s(pts), key_frame=bool(getattr(frame, \"key_frame\", False)), ) if pts is not None: self._frame_cache.put(int(pts), cur) if pts is None: last = cur continue if return_first_after: if pts >= target_pts: return cur last = cur else: if pts <= target_pts: last = cur elif last is not None: return last if last is not None: return last raise RuntimeError(\"Could not decode any frames after seeking.\") finally: container.close() def _read_frame_fast_simple(self, target_pts: int, *, decode_rgb: bool) -> DecodedFrame: \"\"\"Fallback fast seek: seek and decode first frame after PTS.\"\"\" self._ensure_fast_container() assert self._fast_container is not None assert self._fast_stream is not None def grab_frame(container: av.container.InputContainer, stream: av.video.stream.VideoStream) -> Optional[DecodedFrame]: for frame in container.decode(stream): pts = frame.pts if frame.pts is not None else frame.dts if pts is None: target_reached = True else: target_reached = pts >= target_pts if not target_reached: continue if decode_rgb: img = frame.to_rgb().to_ndarray() else: img = frame.to_ndarray(format=\"bgr24\") cur = DecodedFrame( image=img, pts=pts, time_s=self._frame_time_s(pts), key_frame=bool(getattr(frame, \"key_frame\", False)), ) if pts is not None: self._frame_cache.put(int(pts), cur) return cur return None self._fast_container.seek( target_pts, stream=self._fast_stream, backward=True, any_frame=True, ) try: self._fast_stream.codec_context.flush_buffers() except Exception: pass grabbed = grab_frame(self._fast_container, self._fast_stream) if grabbed is not None: return grabbed self._fast_container.seek( target_pts, stream=self._fast_stream, backward=True, any_frame=False, ) try: self._fast_stream.codec_context.flush_buffers() except Exception: pass grabbed = grab_frame(self._fast_container, self._fast_stream) if grabbed is not None: return grabbed raise RuntimeError(\"Failed to decode a frame after fast seek.\") def _read_frame_fast_opencv_pyav(self, target_frame: int, *, decode_rgb: bool) -> DecodedFrame: \"\"\"Approximate OpenCV seek behavior using PyAV.\"\"\" fps = self._nominal_frame_rate or self._frame_rate or 1.0 self._ensure_fast_container() assert self._fast_container is not None assert self._fast_stream is not None def seek_to_frame(frame_index: int) -> None: target_pts = self._secs_to_pts(frame_index / fps) self._fast_container.seek( target_pts, stream=self._fast_stream, backward=True, any_frame=False, ) try: self._fast_stream.codec_context.flush_buffers() except Exception: pass def frame_number_from_pts(pts: Optional[int]) -> Optional[int]: num = self._pts_to_frame_number(pts, fps) if num is None: return None if self._fast_first_frame_number is None: return num return num - self._fast_first_frame_number first_frame = None if self._fast_first_frame_number is None: seek_to_frame(0) for frame in self._fast_container.decode(self._fast_stream): pts = frame.pts if frame.pts is not None else frame.dts self._fast_first_frame_number = self._pts_to_frame_number(pts, fps) or 0 first_frame = frame break if target_frame <= 0: if first_frame is None: seek_to_frame(0) for frame in self._fast_container.decode(self._fast_stream): first_frame = frame break if first_frame is None: raise RuntimeError(\"Failed to decode a frame after fast seek.\") pts = first_frame.pts if first_frame.pts is not None else first_frame.dts img = first_frame.to_rgb().to_ndarray() if decode_rgb else first_frame.to_ndarray(format=\"bgr24\") cur = DecodedFrame( image=img, pts=pts, time_s=self._frame_time_s(pts), key_frame=bool(getattr(first_frame, \"key_frame\", False)), ) if pts is not None: self._frame_cache.put(int(pts), cur) return cur delta = 16 attempts = 0 while True: start_frame = max(target_frame - delta, 0) seek_to_frame(start_frame) decoder = self._fast_container.decode(self._fast_stream) try: frame = next(decoder) except StopIteration: break pts = frame.pts if frame.pts is not None else frame.dts frame_number = frame_number_from_pts(pts) if frame_number is None: frame_number = start_frame if frame_number < 0 or frame_number > target_frame: if start_frame == 0 or delta >= 1 << 30 or attempts > 20: break delta = delta * 2 if delta < 16 else int(delta * 1.5) attempts += 1 continue while frame_number < target_frame: try: frame = next(decoder) except StopIteration: frame = None break pts = frame.pts if frame.pts is not None else frame.dts frame_number = frame_number_from_pts(pts) if frame_number is None: frame_number = target_frame if frame is None: break pts = frame.pts if frame.pts is not None else frame.dts img = frame.to_rgb().to_ndarray() if decode_rgb else frame.to_ndarray(format=\"bgr24\") cur = DecodedFrame( image=img, pts=pts, time_s=self._frame_time_s(pts), key_frame=bool(getattr(frame, \"key_frame\", False)), ) if pts is not None: self._frame_cache.put(int(pts), cur) return cur target_pts = self._secs_to_pts(target_frame / fps) return self._read_frame_fast_simple(target_pts, decode_rgb=decode_rgb) def read_frame_fast( self, *, index: Optional[int] = None, t_s: Optional[Number] = None, decode_rgb: bool = True, use_sequential: bool = True, ) -> DecodedFrame: \"\"\"Return a fast, approximate frame for an index or timestamp.\"\"\" if index is None and t_s is None: raise ValueError(\"Provide either index or t_s\") if index is not None and t_s is not None: raise ValueError(\"Provide only one of index or t_s\") if t_s is None: if index is None: raise ValueError(\"Provide either index or t_s\") if index < 0: index += self.number_of_frames target_frame = int(index) else: t_s = float(t_s) target_frame = int(round(t_s * (self._nominal_frame_rate or self._frame_rate or 1.0))) if use_sequential: decoded = self._read_frame_fast_like(target_frame, decode_rgb=decode_rgb) self._last_fast_index = target_frame return decoded fps = self._nominal_frame_rate or self._frame_rate or 1.0 target_pts = self._secs_to_pts(target_frame / fps) cached = self._frame_cache.get(target_pts) if cached is not None: self._last_fast_index = target_frame return cached # type: ignore[return-value] decoded = self._read_frame_fast_opencv_pyav(target_frame, decode_rgb=decode_rgb) self._last_fast_index = target_frame return decoded def read_frame( self, *, index: Optional[int] = None, t_s: Optional[Number] = None, mode: str = \"accurate\", decode_rgb: bool = True, keyframe_mode: str = \"nearest\", use_sequential: bool = True, ) -> DecodedFrame: \"\"\"Read a frame using a selectable access mode.\"\"\" if mode not in {\"accurate\", \"accurate_timeline\", \"fast\", \"scrub\"}: raise ValueError(\"mode must be one of: 'accurate', 'accurate_timeline', 'fast', 'scrub'\") if index is None and t_s is None: raise ValueError(\"Provide either index or t_s\") if index is not None and t_s is not None: raise ValueError(\"Provide only one of index or t_s\") if mode == \"accurate\": if index is not None: return self._read_frame_at_index( int(index), decode_rgb=decode_rgb, use_sequential=use_sequential, ) assert t_s is not None return self.read_frame_at(float(t_s), use_index=False) if mode == \"accurate_timeline\": if t_s is None: fps = self._nominal_frame_rate or self._frame_rate or 1.0 t_s = float(index) / fps return self.read_frame_at(float(t_s)) if mode == \"scrub\": if t_s is None: fps = self._frame_rate or 1.0 t_s = float(index) / fps return self.read_keyframe_at(float(t_s), mode=keyframe_mode, decode_rgb=decode_rgb) return self.read_frame_fast( index=index, t_s=t_s, decode_rgb=decode_rgb, use_sequential=use_sequential, ) def read_next_frame(self, *, decode_rgb: bool = True) -> DecodedFrame: \"\"\"Return the next frame using sequential decoding.\"\"\" self._ensure_seq_container() assert self._seq_decoder is not None try: frame = next(self._seq_decoder) except StopIteration: raise pts = frame.pts if frame.pts is not None else frame.dts img = frame.to_rgb().to_ndarray() if decode_rgb else frame.to_ndarray(format=\"bgr24\") cur = DecodedFrame( image=img, pts=pts, time_s=self._frame_time_s(pts), key_frame=bool(getattr(frame, \"key_frame\", False)), ) if pts is not None: self._frame_cache.put(int(pts), cur) self._current_frame_pos = float(self._seq_frame_index) self._last_index = int(self._seq_frame_index) self._last_fast_index = int(self._seq_frame_index) self._seq_frame_index += 1 return cur def iter_frames(self, *, decode_rgb: bool = True) -> Iterator[DecodedFrame]: \"\"\"Iterate through frames sequentially.\"\"\" self.reset_sequence() assert self._seq_decoder is not None for frame in self._seq_decoder: pts = frame.pts if frame.pts is not None else frame.dts img = frame.to_rgb().to_ndarray() if decode_rgb else frame.to_ndarray(format=\"bgr24\") cur = DecodedFrame( image=img, pts=pts, time_s=self._frame_time_s(pts), key_frame=bool(getattr(frame, \"key_frame\", False)), ) if pts is not None: self._frame_cache.put(int(pts), cur) self._current_frame_pos = float(self._seq_frame_index) self._seq_frame_index += 1 yield cur","title":"Backend implementation"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._bucket_to_kfidx","text":"","title":"_bucket_to_kfidx"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._codec_ctx","text":"","title":"_codec_ctx"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._container","text":"","title":"_container"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._current_frame_pos","text":"","title":"_current_frame_pos"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._fast_container","text":"","title":"_fast_container"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._fast_decoder","text":"","title":"_fast_decoder"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._fast_first_frame_number","text":"","title":"_fast_first_frame_number"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._fast_last_pts","text":"","title":"_fast_last_pts"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._fast_stream","text":"","title":"_fast_stream"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._fourcc","text":"","title":"_fourcc"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._frame_cache","text":"","title":"_frame_cache"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._frame_count","text":"","title":"_frame_count"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._frame_format","text":"","title":"_frame_format"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._frame_height","text":"","title":"_frame_height"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._frame_pts","text":"","title":"_frame_pts"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._frame_rate","text":"","title":"_frame_rate"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._frame_shape","text":"","title":"_frame_shape"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._frame_width","text":"","title":"_frame_width"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._index_built","text":"","title":"_index_built"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._keyframes","text":"","title":"_keyframes"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._last_fast_index","text":"","title":"_last_fast_index"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._last_index","text":"","title":"_last_index"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._nominal_frame_rate","text":"","title":"_nominal_frame_rate"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._path","text":"","title":"_path"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._scrub_bucket_ms","text":"","title":"_scrub_bucket_ms"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._seq_container","text":"","title":"_seq_container"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._seq_decoder","text":"","title":"_seq_decoder"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._seq_frame_index","text":"","title":"_seq_frame_index"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._seq_stream","text":"","title":"_seq_stream"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._start_pts","text":"","title":"_start_pts"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._stream","text":"","title":"_stream"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._thread_count","text":"","title":"_thread_count"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._threading","text":"","title":"_threading"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._time_base","text":"","title":"_time_base"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend.current_frame_pos","text":"Return the last frame index accessed.","title":"current_frame_pos"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend.fourcc","text":"Return the fourcc codec identifier.","title":"fourcc"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend.frame_format","text":"Return the frame format identifier.","title":"frame_format"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend.frame_height","text":"Return the video frame height.","title":"frame_height"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend.frame_rate","text":"Return the reported frame rate in frames per second.","title":"frame_rate"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend.frame_shape","text":"Return the expected frame shape (H, W, C).","title":"frame_shape"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend.frame_width","text":"Return the video frame width.","title":"frame_width"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend.nominal_frame_rate","text":"Return the nominal frame rate (guessed_rate when available).","title":"nominal_frame_rate"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend.number_of_frames","text":"Return the total number of frames, decoding if needed.","title":"number_of_frames"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend.__enter__","text":"Return self for context manager usage. Source code in acvr/_pyav_backend.py def __enter__(self) -> \"PyAVVideoBackend\": \"\"\"Return self for context manager usage.\"\"\" return self","title":"__enter__"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend.__exit__","text":"Close the backend on exit from a context manager. Source code in acvr/_pyav_backend.py def __exit__(self, exc_type, exc, tb) -> None: \"\"\"Close the backend on exit from a context manager.\"\"\" self.close()","title":"__exit__"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend.__init__","text":"Initialize the PyAV-backed decoder. Source code in acvr/_pyav_backend.py def __init__( self, path: str, video_stream_index: int = 0, *, build_index: bool = False, decoded_frame_cache_size: int = 0, scrub_bucket_ms: int = 25, scrub_bucket_lru_size: int = 4096, threading: bool = True, thread_count: int = 0, ) -> None: \"\"\"Initialize the PyAV-backed decoder.\"\"\" self._path = path self._container = av.open(path) self._stream = self._container.streams.video[video_stream_index] self._codec_ctx = self._stream.codec_context self._fast_container: Optional[av.container.InputContainer] = None self._fast_stream: Optional[av.video.stream.VideoStream] = None self._fast_first_frame_number: Optional[int] = None self._fast_decoder = None self._fast_last_pts: Optional[int] = None self._seq_container: Optional[av.container.InputContainer] = None self._seq_stream: Optional[av.video.stream.VideoStream] = None self._seq_decoder = None self._seq_frame_index: int = 0 self._last_index: Optional[int] = None self._last_fast_index: Optional[int] = None self._time_base: Fraction = self._stream.time_base self._start_pts: int = self._stream.start_time if self._stream.start_time is not None else 0 self._keyframes: List[KeyframeEntry] = [] self._index_built: bool = False self._frame_pts: Optional[List[int]] = None self._frame_count: int = int(self._stream.frames or 0) self._current_frame_pos: float = 0.0 self._frame_cache = _LRU(decoded_frame_cache_size) self._scrub_bucket_ms = max(1, int(scrub_bucket_ms)) self._bucket_to_kfidx = _LRU(scrub_bucket_lru_size) self._threading = bool(threading) self._thread_count = int(thread_count) if build_index: self.build_keyframe_index() self._frame_height = int(self._stream.height or 0) self._frame_width = int(self._stream.width or 0) self._frame_shape = (self._frame_height, self._frame_width, 3) self._frame_rate = self._compute_frame_rate() self._nominal_frame_rate = self._compute_nominal_frame_rate() self._fourcc = self._compute_fourcc() self._frame_format = 0","title":"__init__"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._bucket_key","text":"Return a bucket key for the scrub acceleration cache. Source code in acvr/_pyav_backend.py def _bucket_key(self, t_s: float) -> int: \"\"\"Return a bucket key for the scrub acceleration cache.\"\"\" return int(round(t_s * 1000.0 / self._scrub_bucket_ms))","title":"_bucket_key"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._compute_fourcc","text":"Compute a fourcc code from the stream codec tag. Source code in acvr/_pyav_backend.py def _compute_fourcc(self) -> int: \"\"\"Compute a fourcc code from the stream codec tag.\"\"\" tag = self._stream.codec_context.codec_tag if isinstance(tag, str) and len(tag) >= 4: tag = tag[:4] return ( ord(tag[0]) | (ord(tag[1]) << 8) | (ord(tag[2]) << 16) | (ord(tag[3]) << 24) ) return 0","title":"_compute_fourcc"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._compute_frame_rate","text":"Compute the stream frame rate in frames per second. Source code in acvr/_pyav_backend.py def _compute_frame_rate(self) -> float: \"\"\"Compute the stream frame rate in frames per second.\"\"\" rate = self._stream.average_rate or self._stream.base_rate return float(rate) if rate is not None else 0.0","title":"_compute_frame_rate"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._compute_nominal_frame_rate","text":"Compute a nominal frame rate preferring guessed_rate (useful for VFR). Source code in acvr/_pyav_backend.py def _compute_nominal_frame_rate(self) -> float: \"\"\"Compute a nominal frame rate preferring guessed_rate (useful for VFR).\"\"\" rate = getattr(self._stream, \"guessed_rate\", None) or self._stream.average_rate or self._stream.base_rate return float(rate) if rate is not None else 0.0","title":"_compute_nominal_frame_rate"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._configure_codec_context","text":"Apply conservative threading settings to a codec context. Source code in acvr/_pyav_backend.py def _configure_codec_context(self, stream: av.video.stream.VideoStream) -> None: \"\"\"Apply conservative threading settings to a codec context.\"\"\" try: codec_ctx = stream.codec_context if self._threading: codec_ctx.thread_type = \"AUTO\" codec_ctx.thread_count = self._thread_count else: codec_ctx.thread_type = \"NONE\" codec_ctx.thread_count = 1 except Exception: pass","title":"_configure_codec_context"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._ensure_fast_container","text":"Initialize the fast-seek container if needed. Source code in acvr/_pyav_backend.py def _ensure_fast_container(self) -> None: \"\"\"Initialize the fast-seek container if needed.\"\"\" if self._fast_container is not None: return self._fast_container = av.open(self._path) self._fast_stream = self._fast_container.streams.video[self._stream.index] self._configure_codec_context(self._fast_stream)","title":"_ensure_fast_container"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._ensure_frame_pts","text":"Decode the stream once to collect frame PTS values. Source code in acvr/_pyav_backend.py def _ensure_frame_pts(self) -> None: \"\"\"Decode the stream once to collect frame PTS values.\"\"\" if self._frame_pts is not None: return idx_container = av.open(self._path) idx_stream = idx_container.streams.video[self._stream.index] self._configure_codec_context(idx_stream) self._configure_codec_context(idx_stream) pts_list: List[int] = [] for frame in idx_container.decode(idx_stream): pts = frame.pts if frame.pts is not None else frame.dts if pts is None: pts = self._start_pts + len(pts_list) pts_list.append(int(pts)) idx_container.close() self._frame_pts = pts_list self._frame_count = len(pts_list)","title":"_ensure_frame_pts"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._ensure_seq_container","text":"Initialize a sequential decode container if needed. Source code in acvr/_pyav_backend.py def _ensure_seq_container(self) -> None: \"\"\"Initialize a sequential decode container if needed.\"\"\" if self._seq_container is not None: return self._seq_container = av.open(self._path) self._seq_stream = self._seq_container.streams.video[self._stream.index] self._configure_codec_context(self._seq_stream) self._seq_decoder = self._seq_container.decode(self._seq_stream) self._seq_frame_index = 0","title":"_ensure_seq_container"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._fast_frame_to_pts","text":"Convert a frame index to expected PTS for fast reads. Source code in acvr/_pyav_backend.py def _fast_frame_to_pts(self, frame_index: int, fps: float) -> int: \"\"\"Convert a frame index to expected PTS for fast reads.\"\"\" if frame_index <= 0: return self._start_pts return self._secs_to_pts(frame_index / fps)","title":"_fast_frame_to_pts"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._fast_rewind","text":"Rewind the fast-seek container and reset decoder state. Source code in acvr/_pyav_backend.py def _fast_rewind(self) -> None: \"\"\"Rewind the fast-seek container and reset decoder state.\"\"\" self._ensure_fast_container() assert self._fast_container is not None assert self._fast_stream is not None self._fast_container.seek(0) self._fast_decoder = self._fast_container.decode(self._fast_stream) self._fast_last_pts = None","title":"_fast_rewind"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._flush_decoder","text":"Flush decoder buffers if supported. Source code in acvr/_pyav_backend.py def _flush_decoder(self) -> None: \"\"\"Flush decoder buffers if supported.\"\"\" try: self._codec_ctx.flush_buffers() except Exception: pass","title":"_flush_decoder"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._frame_time_s","text":"Return the timestamp for a frame PTS. Source code in acvr/_pyav_backend.py def _frame_time_s(self, pts: Optional[int]) -> float: \"\"\"Return the timestamp for a frame PTS.\"\"\" return float(\"nan\") if pts is None else self._pts_to_secs(pts)","title":"_frame_time_s"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._keyframe_index_at_or_before_pts","text":"Return keyframe index at or before the target PTS. Source code in acvr/_pyav_backend.py def _keyframe_index_at_or_before_pts(self, target_pts: int) -> int: \"\"\"Return keyframe index at or before the target PTS.\"\"\" kf = self._keyframes if not self._index_built or not kf: return 0 if target_pts <= kf[0].pts: return 0 if target_pts >= kf[-1].pts: return len(kf) - 1 lo, hi = 0, len(kf) - 1 while lo <= hi: mid = (lo + hi) // 2 m = kf[mid].pts if m == target_pts: return mid if m < target_pts: lo = mid + 1 else: hi = mid - 1 return hi","title":"_keyframe_index_at_or_before_pts"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._keyframe_index_for_time_fast","text":"Return a keyframe index using cached time buckets. Source code in acvr/_pyav_backend.py def _keyframe_index_for_time_fast(self, t_s: float, mode: str) -> int: \"\"\"Return a keyframe index using cached time buckets.\"\"\" if not self._index_built: raise RuntimeError(\"Keyframe index not built. Call build_keyframe_index() first.\") b = self._bucket_key(t_s) mode_tag = {\"previous\": 0, \"nearest\": 1, \"next\": 2}.get(mode) if mode_tag is None: raise ValueError(\"mode must be one of: 'previous', 'nearest', 'next'\") cache_key = (b << 2) | mode_tag cached = self._bucket_to_kfidx.get(cache_key) if cached is not None: return int(cached) target_pts = self._secs_to_pts(t_s) if mode == \"previous\": idx = self._keyframe_index_at_or_before_pts(target_pts) elif mode == \"nearest\": idx = self._keyframe_index_nearest_pts(target_pts) else: i_prev = self._keyframe_index_at_or_before_pts(target_pts) if self._keyframes[i_prev].pts >= target_pts: idx = i_prev else: idx = min(i_prev + 1, len(self._keyframes) - 1) self._bucket_to_kfidx.put(cache_key, idx) return idx","title":"_keyframe_index_for_time_fast"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._keyframe_index_nearest_pts","text":"Return nearest keyframe index to the target PTS. Source code in acvr/_pyav_backend.py def _keyframe_index_nearest_pts(self, target_pts: int) -> int: \"\"\"Return nearest keyframe index to the target PTS.\"\"\" kf = self._keyframes if not self._index_built or not kf: return 0 i0 = self._keyframe_index_at_or_before_pts(target_pts) i1 = min(i0 + 1, len(kf) - 1) if i0 == i1: return i0 d0 = abs(kf[i0].pts - target_pts) d1 = abs(kf[i1].pts - target_pts) return i0 if d0 <= d1 else i1","title":"_keyframe_index_nearest_pts"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._pts_to_frame_number","text":"Convert a PTS value to a rounded frame number. Source code in acvr/_pyav_backend.py def _pts_to_frame_number(self, pts: Optional[int], fps: float) -> Optional[int]: \"\"\"Convert a PTS value to a rounded frame number.\"\"\" if pts is None: return None return int(round(self._pts_to_secs(int(pts)) * fps))","title":"_pts_to_frame_number"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._pts_to_secs","text":"Convert presentation timestamp units to seconds. Source code in acvr/_pyav_backend.py def _pts_to_secs(self, pts: int) -> float: \"\"\"Convert presentation timestamp units to seconds.\"\"\" return float((pts - self._start_pts) * self._time_base)","title":"_pts_to_secs"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._read_frame_at_index","text":"Return the decoded frame at a zero-based index. Source code in acvr/_pyav_backend.py def _read_frame_at_index( self, index: int, *, decode_rgb: bool = True, use_sequential: bool = True, ) -> DecodedFrame: \"\"\"Return the decoded frame at a zero-based index.\"\"\" if use_sequential and index >= 0: if self._seq_decoder is not None and index == self._seq_frame_index: return self.read_next_frame(decode_rgb=decode_rgb) if self._seq_decoder is None and index == 0: self.reset_sequence() return self.read_next_frame(decode_rgb=decode_rgb) self._ensure_frame_pts() assert self._frame_pts is not None if index < 0: index += self._frame_count if index < 0 or index >= self._frame_count: raise IndexError(\"frame index out of range\") target_pts = self._frame_pts[index] if use_sequential and self._seq_decoder is not None and index == self._seq_frame_index: try: decoded = self.read_next_frame(decode_rgb=decode_rgb) except StopIteration: decoded = self._seek_seq_to_pts(target_pts, target_index=index, decode_rgb=decode_rgb) elif use_sequential and self._last_index is not None and index == self._last_index + 1: decoded = self._seek_seq_to_pts(target_pts, target_index=index, decode_rgb=decode_rgb) else: decoded = self._read_frame_by_pts(target_pts, decode_rgb=decode_rgb) self._current_frame_pos = float(index) self._last_index = index return decoded","title":"_read_frame_at_index"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._read_frame_by_pts","text":"Decode the first frame at or after a target PTS. Source code in acvr/_pyav_backend.py def _read_frame_by_pts(self, target_pts: int, *, decode_rgb: bool = True) -> DecodedFrame: \"\"\"Decode the first frame at or after a target PTS.\"\"\" cached = self._frame_cache.get(target_pts) if cached is not None: return cached # type: ignore[return-value] if self._index_built: idx = self._keyframe_index_at_or_before_pts(target_pts) seek_pts = self._keyframes[idx].pts else: seek_pts = target_pts container = av.open(self._path) stream = container.streams.video[self._stream.index] self._configure_codec_context(stream) try: container.seek(seek_pts, stream=stream, backward=True, any_frame=False) try: stream.codec_context.flush_buffers() except Exception: pass last: Optional[DecodedFrame] = None for packet in container.demux(stream): for frame in packet.decode(): pts = frame.pts image = frame.to_rgb().to_ndarray() if decode_rgb else frame.to_ndarray(format=\"bgr24\") cur = DecodedFrame( image=image, pts=pts, time_s=self._frame_time_s(pts), key_frame=bool(getattr(frame, \"key_frame\", False)), ) if pts is not None: self._frame_cache.put(int(pts), cur) if pts is None: last = cur continue if pts >= target_pts: return cur last = cur finally: container.close() if last is not None: return last raise RuntimeError(\"Could not decode any frames after seeking.\")","title":"_read_frame_by_pts"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._read_frame_fast_like","text":"Approximate FastVideoReader behavior for fast sequential reads. Source code in acvr/_pyav_backend.py def _read_frame_fast_like(self, target_frame: int, *, decode_rgb: bool) -> DecodedFrame: \"\"\"Approximate FastVideoReader behavior for fast sequential reads.\"\"\" fps = self._nominal_frame_rate or self._frame_rate or 1.0 pts_per_frame = 1.0 / (fps * float(self._time_base)) if fps else 1.0 wiggle = pts_per_frame / 10.0 if target_frame <= 0: self._fast_rewind() assert self._fast_decoder is not None frame = next(self._fast_decoder) pts = frame.pts if frame.pts is not None else frame.dts if pts is None: pts = self._fast_frame_to_pts(0, fps) img = frame.to_rgb().to_ndarray() if decode_rgb else frame.to_ndarray(format=\"bgr24\") cur = DecodedFrame( image=img, pts=pts, time_s=self._frame_time_s(pts), key_frame=bool(getattr(frame, \"key_frame\", False)), ) if pts is not None: self._frame_cache.put(int(pts), cur) return cur expected_prev_pts = self._fast_frame_to_pts(target_frame - 1, fps) if self._fast_decoder is not None and self._fast_last_pts == expected_prev_pts: try: frame = next(self._fast_decoder) except StopIteration: frame = None if frame is not None: pts = frame.pts if frame.pts is not None else frame.dts if pts is None: pts = self._fast_frame_to_pts(target_frame, fps) img = frame.to_rgb().to_ndarray() if decode_rgb else frame.to_ndarray(format=\"bgr24\") cur = DecodedFrame( image=img, pts=pts, time_s=self._frame_time_s(pts), key_frame=bool(getattr(frame, \"key_frame\", False)), ) if pts is not None: self._frame_cache.put(int(pts), cur) self._fast_last_pts = int(pts) if pts is not None else None return cur self._ensure_fast_container() assert self._fast_container is not None assert self._fast_stream is not None target_pts = self._fast_frame_to_pts(target_frame, fps) self._fast_container.seek( target_pts, stream=self._fast_stream, backward=True, any_frame=False, ) try: self._fast_stream.codec_context.flush_buffers() except Exception: pass self._fast_decoder = self._fast_container.decode(self._fast_stream) self._fast_last_pts = None try: frame = next(self._fast_decoder) except StopIteration: frame = None if frame is None: return self._read_frame_fast_simple(target_pts, decode_rgb=decode_rgb) cur_pts = frame.pts if frame.pts is not None else frame.dts if cur_pts is None: cur_pts = target_pts if cur_pts > target_pts: back = max(1, int(round(100))) back_pts = self._fast_frame_to_pts(max(0, target_frame - back), fps) self._fast_container.seek( back_pts, stream=self._fast_stream, backward=True, any_frame=False, ) try: self._fast_stream.codec_context.flush_buffers() except Exception: pass self._fast_decoder = self._fast_container.decode(self._fast_stream) try: frame = next(self._fast_decoder) except StopIteration: frame = None if frame is None: return self._read_frame_fast_simple(target_pts, decode_rgb=decode_rgb) cur_pts = frame.pts if frame.pts is not None else frame.dts if cur_pts is None: cur_pts = target_pts while float(cur_pts) < (float(target_pts) - wiggle): try: frame = next(self._fast_decoder) except StopIteration: frame = None break if frame is None: break cur_pts = frame.pts if frame.pts is not None else frame.dts if cur_pts is None: cur_pts = target_pts break if frame is None: return self._read_frame_fast_simple(target_pts, decode_rgb=decode_rgb) img = frame.to_rgb().to_ndarray() if decode_rgb else frame.to_ndarray(format=\"bgr24\") cur = DecodedFrame( image=img, pts=cur_pts, time_s=self._frame_time_s(cur_pts), key_frame=bool(getattr(frame, \"key_frame\", False)), ) if cur_pts is not None: self._frame_cache.put(int(cur_pts), cur) self._fast_last_pts = int(cur_pts) else: self._fast_last_pts = None return cur","title":"_read_frame_fast_like"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._read_frame_fast_opencv_pyav","text":"Approximate OpenCV seek behavior using PyAV. Source code in acvr/_pyav_backend.py def _read_frame_fast_opencv_pyav(self, target_frame: int, *, decode_rgb: bool) -> DecodedFrame: \"\"\"Approximate OpenCV seek behavior using PyAV.\"\"\" fps = self._nominal_frame_rate or self._frame_rate or 1.0 self._ensure_fast_container() assert self._fast_container is not None assert self._fast_stream is not None def seek_to_frame(frame_index: int) -> None: target_pts = self._secs_to_pts(frame_index / fps) self._fast_container.seek( target_pts, stream=self._fast_stream, backward=True, any_frame=False, ) try: self._fast_stream.codec_context.flush_buffers() except Exception: pass def frame_number_from_pts(pts: Optional[int]) -> Optional[int]: num = self._pts_to_frame_number(pts, fps) if num is None: return None if self._fast_first_frame_number is None: return num return num - self._fast_first_frame_number first_frame = None if self._fast_first_frame_number is None: seek_to_frame(0) for frame in self._fast_container.decode(self._fast_stream): pts = frame.pts if frame.pts is not None else frame.dts self._fast_first_frame_number = self._pts_to_frame_number(pts, fps) or 0 first_frame = frame break if target_frame <= 0: if first_frame is None: seek_to_frame(0) for frame in self._fast_container.decode(self._fast_stream): first_frame = frame break if first_frame is None: raise RuntimeError(\"Failed to decode a frame after fast seek.\") pts = first_frame.pts if first_frame.pts is not None else first_frame.dts img = first_frame.to_rgb().to_ndarray() if decode_rgb else first_frame.to_ndarray(format=\"bgr24\") cur = DecodedFrame( image=img, pts=pts, time_s=self._frame_time_s(pts), key_frame=bool(getattr(first_frame, \"key_frame\", False)), ) if pts is not None: self._frame_cache.put(int(pts), cur) return cur delta = 16 attempts = 0 while True: start_frame = max(target_frame - delta, 0) seek_to_frame(start_frame) decoder = self._fast_container.decode(self._fast_stream) try: frame = next(decoder) except StopIteration: break pts = frame.pts if frame.pts is not None else frame.dts frame_number = frame_number_from_pts(pts) if frame_number is None: frame_number = start_frame if frame_number < 0 or frame_number > target_frame: if start_frame == 0 or delta >= 1 << 30 or attempts > 20: break delta = delta * 2 if delta < 16 else int(delta * 1.5) attempts += 1 continue while frame_number < target_frame: try: frame = next(decoder) except StopIteration: frame = None break pts = frame.pts if frame.pts is not None else frame.dts frame_number = frame_number_from_pts(pts) if frame_number is None: frame_number = target_frame if frame is None: break pts = frame.pts if frame.pts is not None else frame.dts img = frame.to_rgb().to_ndarray() if decode_rgb else frame.to_ndarray(format=\"bgr24\") cur = DecodedFrame( image=img, pts=pts, time_s=self._frame_time_s(pts), key_frame=bool(getattr(frame, \"key_frame\", False)), ) if pts is not None: self._frame_cache.put(int(pts), cur) return cur target_pts = self._secs_to_pts(target_frame / fps) return self._read_frame_fast_simple(target_pts, decode_rgb=decode_rgb)","title":"_read_frame_fast_opencv_pyav"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._read_frame_fast_simple","text":"Fallback fast seek: seek and decode first frame after PTS. Source code in acvr/_pyav_backend.py def _read_frame_fast_simple(self, target_pts: int, *, decode_rgb: bool) -> DecodedFrame: \"\"\"Fallback fast seek: seek and decode first frame after PTS.\"\"\" self._ensure_fast_container() assert self._fast_container is not None assert self._fast_stream is not None def grab_frame(container: av.container.InputContainer, stream: av.video.stream.VideoStream) -> Optional[DecodedFrame]: for frame in container.decode(stream): pts = frame.pts if frame.pts is not None else frame.dts if pts is None: target_reached = True else: target_reached = pts >= target_pts if not target_reached: continue if decode_rgb: img = frame.to_rgb().to_ndarray() else: img = frame.to_ndarray(format=\"bgr24\") cur = DecodedFrame( image=img, pts=pts, time_s=self._frame_time_s(pts), key_frame=bool(getattr(frame, \"key_frame\", False)), ) if pts is not None: self._frame_cache.put(int(pts), cur) return cur return None self._fast_container.seek( target_pts, stream=self._fast_stream, backward=True, any_frame=True, ) try: self._fast_stream.codec_context.flush_buffers() except Exception: pass grabbed = grab_frame(self._fast_container, self._fast_stream) if grabbed is not None: return grabbed self._fast_container.seek( target_pts, stream=self._fast_stream, backward=True, any_frame=False, ) try: self._fast_stream.codec_context.flush_buffers() except Exception: pass grabbed = grab_frame(self._fast_container, self._fast_stream) if grabbed is not None: return grabbed raise RuntimeError(\"Failed to decode a frame after fast seek.\")","title":"_read_frame_fast_simple"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._secs_to_pts","text":"Convert seconds to presentation timestamp units. Source code in acvr/_pyav_backend.py def _secs_to_pts(self, t_s: float) -> int: \"\"\"Convert seconds to presentation timestamp units.\"\"\" ticks = int(round(t_s / float(self._time_base))) return self._start_pts + ticks","title":"_secs_to_pts"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._seek_seq_to_pts","text":"Seek the sequential decoder to a PTS and return the first match. Source code in acvr/_pyav_backend.py def _seek_seq_to_pts( self, target_pts: int, *, target_index: int, decode_rgb: bool, any_frame: bool = False, ) -> DecodedFrame: \"\"\"Seek the sequential decoder to a PTS and return the first match.\"\"\" self._ensure_seq_container() assert self._seq_container is not None assert self._seq_stream is not None seek_pts = target_pts if self._keyframes and not any_frame: idx = self._keyframe_index_at_or_before_pts(target_pts) seek_pts = self._keyframes[idx].pts self._seq_container.seek( seek_pts, stream=self._seq_stream, backward=True, any_frame=any_frame, ) try: self._seq_stream.codec_context.flush_buffers() except Exception: pass decoder = self._seq_container.decode(self._seq_stream) last: Optional[DecodedFrame] = None for frame in decoder: pts = frame.pts if frame.pts is not None else frame.dts img = frame.to_rgb().to_ndarray() if decode_rgb else frame.to_ndarray(format=\"bgr24\") cur = DecodedFrame( image=img, pts=pts, time_s=self._frame_time_s(pts), key_frame=bool(getattr(frame, \"key_frame\", False)), ) if pts is not None: self._frame_cache.put(int(pts), cur) if pts is None: last = cur continue if pts >= target_pts: self._seq_decoder = decoder self._seq_frame_index = target_index + 1 self._current_frame_pos = float(target_index) return cur last = cur if last is not None: self._seq_decoder = decoder self._seq_frame_index = target_index + 1 self._current_frame_pos = float(target_index) return last raise RuntimeError(\"Could not decode any frames after seeking.\")","title":"_seek_seq_to_pts"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend._seek_to_pts","text":"Seek to a timestamp in the stream. Source code in acvr/_pyav_backend.py def _seek_to_pts(self, pts: int, *, backward: bool) -> None: \"\"\"Seek to a timestamp in the stream.\"\"\" self._container.seek(pts, stream=self._stream, backward=backward, any_frame=False) self._flush_decoder()","title":"_seek_to_pts"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend.build_keyframe_index","text":"Scan packets and store keyframe pts/time. Source code in acvr/_pyav_backend.py def build_keyframe_index(self, *, max_packets: Optional[int] = None) -> List[KeyframeEntry]: \"\"\"Scan packets and store keyframe pts/time.\"\"\" path = self._container.name idx_container = av.open(path) idx_stream = idx_container.streams.video[self._stream.index] key_pts: List[int] = [] n = 0 for packet in idx_container.demux(idx_stream): if packet.dts is None and packet.pts is None: continue if packet.is_keyframe: pts = packet.pts if packet.pts is not None else packet.dts if pts is not None: key_pts.append(int(pts)) n += 1 if max_packets is not None and n >= max_packets: break idx_container.close() key_pts = sorted(set(key_pts)) if not key_pts: key_pts = [self._start_pts] self._keyframes = [KeyframeEntry(pts=p, time_s=self._pts_to_secs(p)) for p in key_pts] self._index_built = True self._bucket_to_kfidx.clear() return self._keyframes","title":"build_keyframe_index"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend.close","text":"Close the underlying PyAV container. Source code in acvr/_pyav_backend.py def close(self) -> None: \"\"\"Close the underlying PyAV container.\"\"\" self._container.close() if self._fast_container is not None: self._fast_container.close() self._fast_container = None self._fast_stream = None self._fast_decoder = None self._fast_last_pts = None self._fast_first_frame_number = None if self._seq_container is not None: self._seq_container.close() self._seq_container = None self._seq_stream = None self._seq_decoder = None self._seq_frame_index = 0 self._last_index = None self._last_fast_index = None","title":"close"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend.frame_at_index","text":"Return the decoded frame at a zero-based index. Source code in acvr/_pyav_backend.py def frame_at_index(self, index: int) -> np.ndarray: \"\"\"Return the decoded frame at a zero-based index.\"\"\" return self._read_frame_at_index(index, decode_rgb=True, use_sequential=True).image","title":"frame_at_index"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend.index_from_pts","text":"Map a PTS value to the nearest frame index. Source code in acvr/_pyav_backend.py def index_from_pts(self, pts: int) -> int: \"\"\"Map a PTS value to the nearest frame index.\"\"\" self._ensure_frame_pts() assert self._frame_pts is not None fps = self._frame_pts if not fps: return 0 lo, hi = 0, len(fps) - 1 if pts <= fps[0]: return 0 if pts >= fps[-1]: return hi while lo <= hi: mid = (lo + hi) // 2 m = fps[mid] if m == pts: return mid if m < pts: lo = mid + 1 else: hi = mid - 1 # choose nearest between hi and lo if lo >= len(fps): return hi if hi < 0: return lo return lo if abs(fps[lo] - pts) < abs(fps[hi] - pts) else hi","title":"index_from_pts"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend.index_from_time","text":"Map a timestamp in seconds to the nearest frame index. Source code in acvr/_pyav_backend.py def index_from_time(self, t_s: float) -> int: \"\"\"Map a timestamp in seconds to the nearest frame index.\"\"\" pts = self._secs_to_pts(float(t_s)) return self.index_from_pts(int(pts))","title":"index_from_time"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend.iter_frames","text":"Iterate through frames sequentially. Source code in acvr/_pyav_backend.py def iter_frames(self, *, decode_rgb: bool = True) -> Iterator[DecodedFrame]: \"\"\"Iterate through frames sequentially.\"\"\" self.reset_sequence() assert self._seq_decoder is not None for frame in self._seq_decoder: pts = frame.pts if frame.pts is not None else frame.dts img = frame.to_rgb().to_ndarray() if decode_rgb else frame.to_ndarray(format=\"bgr24\") cur = DecodedFrame( image=img, pts=pts, time_s=self._frame_time_s(pts), key_frame=bool(getattr(frame, \"key_frame\", False)), ) if pts is not None: self._frame_cache.put(int(pts), cur) self._current_frame_pos = float(self._seq_frame_index) self._seq_frame_index += 1 yield cur","title":"iter_frames"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend.pts_at_index","text":"Return the presentation timestamp (PTS) for a frame index. Source code in acvr/_pyav_backend.py def pts_at_index(self, index: int) -> Optional[int]: \"\"\"Return the presentation timestamp (PTS) for a frame index.\"\"\" self._ensure_frame_pts() assert self._frame_pts is not None if index < 0: index += self._frame_count if index < 0 or index >= self._frame_count: raise IndexError(\"frame index out of range\") return int(self._frame_pts[index])","title":"pts_at_index"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend.read_frame","text":"Read a frame using a selectable access mode. Source code in acvr/_pyav_backend.py def read_frame( self, *, index: Optional[int] = None, t_s: Optional[Number] = None, mode: str = \"accurate\", decode_rgb: bool = True, keyframe_mode: str = \"nearest\", use_sequential: bool = True, ) -> DecodedFrame: \"\"\"Read a frame using a selectable access mode.\"\"\" if mode not in {\"accurate\", \"accurate_timeline\", \"fast\", \"scrub\"}: raise ValueError(\"mode must be one of: 'accurate', 'accurate_timeline', 'fast', 'scrub'\") if index is None and t_s is None: raise ValueError(\"Provide either index or t_s\") if index is not None and t_s is not None: raise ValueError(\"Provide only one of index or t_s\") if mode == \"accurate\": if index is not None: return self._read_frame_at_index( int(index), decode_rgb=decode_rgb, use_sequential=use_sequential, ) assert t_s is not None return self.read_frame_at(float(t_s), use_index=False) if mode == \"accurate_timeline\": if t_s is None: fps = self._nominal_frame_rate or self._frame_rate or 1.0 t_s = float(index) / fps return self.read_frame_at(float(t_s)) if mode == \"scrub\": if t_s is None: fps = self._frame_rate or 1.0 t_s = float(index) / fps return self.read_keyframe_at(float(t_s), mode=keyframe_mode, decode_rgb=decode_rgb) return self.read_frame_fast( index=index, t_s=t_s, decode_rgb=decode_rgb, use_sequential=use_sequential, )","title":"read_frame"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend.read_frame_at","text":"Decode a frame near a timestamp with accurate seeking. Simplified and robust: always uses a fresh container and backward keyframe seek. Source code in acvr/_pyav_backend.py def read_frame_at( self, t_s: Number, *, return_first_after: bool = True, max_decode_frames: int = 10_000, use_index: bool = True, ) -> DecodedFrame: \"\"\"Decode a frame near a timestamp with accurate seeking. Simplified and robust: always uses a fresh container and backward keyframe seek. \"\"\" t_s = float(t_s) target_pts = self._secs_to_pts(t_s) cached = self._frame_cache.get(target_pts) if cached is not None: return cached # type: ignore[return-value] container = av.open(self._path) try: stream = container.streams.video[self._stream.index] self._configure_codec_context(stream) if use_index and self._index_built: idx = self._keyframe_index_at_or_before_pts(target_pts) anchor_pts = self._keyframes[idx].pts container.seek(anchor_pts, stream=stream, backward=True, any_frame=False) else: container.seek(target_pts, stream=stream, backward=True, any_frame=False) try: stream.codec_context.flush_buffers() except Exception: pass last: Optional[DecodedFrame] = None decoded = 0 for packet in container.demux(stream): for frame in packet.decode(): decoded += 1 if decoded > max_decode_frames: raise RuntimeError( \"Exceeded max_decode_frames while seeking; timestamps may be broken.\" ) pts = frame.pts cur = DecodedFrame( image=frame.to_rgb().to_ndarray(), pts=pts, time_s=self._frame_time_s(pts), key_frame=bool(getattr(frame, \"key_frame\", False)), ) if pts is not None: self._frame_cache.put(int(pts), cur) if pts is None: last = cur continue if return_first_after: if pts >= target_pts: return cur last = cur else: if pts <= target_pts: last = cur elif last is not None: return last if last is not None: return last raise RuntimeError(\"Could not decode any frames after seeking.\") finally: container.close()","title":"read_frame_at"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend.read_frame_fast","text":"Return a fast, approximate frame for an index or timestamp. Source code in acvr/_pyav_backend.py def read_frame_fast( self, *, index: Optional[int] = None, t_s: Optional[Number] = None, decode_rgb: bool = True, use_sequential: bool = True, ) -> DecodedFrame: \"\"\"Return a fast, approximate frame for an index or timestamp.\"\"\" if index is None and t_s is None: raise ValueError(\"Provide either index or t_s\") if index is not None and t_s is not None: raise ValueError(\"Provide only one of index or t_s\") if t_s is None: if index is None: raise ValueError(\"Provide either index or t_s\") if index < 0: index += self.number_of_frames target_frame = int(index) else: t_s = float(t_s) target_frame = int(round(t_s * (self._nominal_frame_rate or self._frame_rate or 1.0))) if use_sequential: decoded = self._read_frame_fast_like(target_frame, decode_rgb=decode_rgb) self._last_fast_index = target_frame return decoded fps = self._nominal_frame_rate or self._frame_rate or 1.0 target_pts = self._secs_to_pts(target_frame / fps) cached = self._frame_cache.get(target_pts) if cached is not None: self._last_fast_index = target_frame return cached # type: ignore[return-value] decoded = self._read_frame_fast_opencv_pyav(target_frame, decode_rgb=decode_rgb) self._last_fast_index = target_frame return decoded","title":"read_frame_fast"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend.read_keyframe_at","text":"Return a nearby keyframe without GOP forward decoding. Source code in acvr/_pyav_backend.py def read_keyframe_at( self, t_s: Number, *, mode: str = \"nearest\", decode_rgb: bool = True, ) -> DecodedFrame: \"\"\"Return a nearby keyframe without GOP forward decoding.\"\"\" t_s = float(t_s) idx = self._keyframe_index_for_time_fast(t_s, mode) key_pts = self._keyframes[idx].pts cached = self._frame_cache.get(key_pts) if cached is not None: return cached # type: ignore[return-value] # Use a fresh container for reliable keyframe seek, avoiding stateful issues container = av.open(self._path) try: stream = container.streams.video[self._stream.index] self._configure_codec_context(stream) # Use backward seek to land on or before the requested keyframe PTS reliably container.seek(key_pts, stream=stream, backward=True, any_frame=False) try: stream.codec_context.flush_buffers() except Exception: pass for packet in container.demux(stream): for frame in packet.decode(): pts = frame.pts img = frame.to_rgb().to_ndarray() if decode_rgb else frame.to_ndarray() cur = DecodedFrame( image=img, pts=pts, time_s=self._frame_time_s(pts), key_frame=bool(getattr(frame, \"key_frame\", False)), ) if pts is not None: self._frame_cache.put(int(pts), cur) return cur finally: container.close() raise RuntimeError(\"Failed to decode a frame after keyframe seek.\")","title":"read_keyframe_at"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend.read_next_frame","text":"Return the next frame using sequential decoding. Source code in acvr/_pyav_backend.py def read_next_frame(self, *, decode_rgb: bool = True) -> DecodedFrame: \"\"\"Return the next frame using sequential decoding.\"\"\" self._ensure_seq_container() assert self._seq_decoder is not None try: frame = next(self._seq_decoder) except StopIteration: raise pts = frame.pts if frame.pts is not None else frame.dts img = frame.to_rgb().to_ndarray() if decode_rgb else frame.to_ndarray(format=\"bgr24\") cur = DecodedFrame( image=img, pts=pts, time_s=self._frame_time_s(pts), key_frame=bool(getattr(frame, \"key_frame\", False)), ) if pts is not None: self._frame_cache.put(int(pts), cur) self._current_frame_pos = float(self._seq_frame_index) self._last_index = int(self._seq_frame_index) self._last_fast_index = int(self._seq_frame_index) self._seq_frame_index += 1 return cur","title":"read_next_frame"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend.reset_sequence","text":"Reset sequential decoding to the first frame. Source code in acvr/_pyav_backend.py def reset_sequence(self) -> None: \"\"\"Reset sequential decoding to the first frame.\"\"\" self._ensure_seq_container() assert self._seq_container is not None assert self._seq_stream is not None try: self._seq_container.seek(0) except Exception: pass self._seq_decoder = self._seq_container.decode(self._seq_stream) self._seq_frame_index = 0","title":"reset_sequence"},{"location":"api/#acvr._pyav_backend.PyAVVideoBackend.time_at_index","text":"Return the timestamp in seconds for a frame index. Source code in acvr/_pyav_backend.py def time_at_index(self, index: int) -> float: \"\"\"Return the timestamp in seconds for a frame index.\"\"\" pts = self.pts_at_index(index) return float(\"nan\") if pts is None else self._pts_to_secs(int(pts))","title":"time_at_index"},{"location":"benchmark/","text":"Use the benchmark suite to compare read modes, cache impact, and threading tradeoffs on your own videos. The CLI prints timing tables and accuracy statistics for every video it processes. Run on your own videos # Single video python -m acvr.benchmarks /path/to/video.mp4 --metric truth --compare-fastvideo # All supported videos in a directory python -m acvr.benchmarks /path/to/videos --metric truth --compare-fastvideo The legacy wrapper python -m scripts.benchmark_reader is still supported. Reproduce bundled results Run the benchmark on all bundled test assets: python -m acvr.benchmarks tests/data --metric truth --compare-fastvideo \\ --index-pattern sequential --use-sequential on --samples 120 --no-opencv Results (median ms/frame, local machine, PyAV 16.x): Video Sequential Accurate Accurate TL Scrub Fast FastVideo 10-03-22_Test 25_1-2v1-3.mp4 1.09 1.10 27.36 9.22 5.12 4.96 20190128_113421.mp4 1.37 1.37 37.13 37.51 1.44 1.39 localhost-20181120_144618.mp4 0.32 0.32 114.95 79.19 61.06 57.71 rpi9-20210409_093149.mp4 4.13 4.05 123.60 19.06 3.97 3.73 test_cfr_h264.mp4 0.29 0.28 24.34 5.37 0.28 0.27 test_vfr_h264.mp4 0.27 0.28 22.69 5.72 0.28 0.27 Sequential reads ( read_next / iteration) and use_sequential=True provide large speedups when accessing consecutive indices, bringing accurate and fast close to true sequential decode performance. LRU cache impact The decoded-frame LRU ( decoded_frame_cache_size ) helps when you revisit the same indices repeatedly (e.g., UI scrubbing or repeated random samples). The benchmark below repeats the same random index list three times to amplify cache hits: # No cache python -m acvr.benchmarks tests/data/test_vfr_h264.mp4 --metric truth \\ --index-pattern random --use-sequential off --samples 200 --passes 3 \\ --cache-size 0 --no-opencv # LRU cache enabled python -m acvr.benchmarks tests/data/test_vfr_h264.mp4 --metric truth \\ --index-pattern random --use-sequential off --samples 200 --passes 3 \\ --cache-size 512 --no-opencv Results (median ms/frame, local machine, PyAV 16.x): Mode Cache=0 Cache=512 Fast 15.95 0.00 Scrub 6.08 0.01 Cached reads return immediately after the first pass, which is especially useful for repeated random access patterns. Threading impact Threading defaults to on and generally helps on H.264 assets, but some videos may decode faster with threading disabled. The benchmark below uses random indices and compares on vs off : python -m acvr.benchmarks tests/data --metric truth --compare-fastvideo \\ --index-pattern random --use-sequential on --samples 40 --no-opencv --threading on python -m acvr.benchmarks tests/data --metric truth --compare-fastvideo \\ --index-pattern random --use-sequential on --samples 40 --no-opencv --threading off Results (median ms/frame, local machine, PyAV 16.x, --samples 40 ): Video Accurate (on) Accurate (off) Fast (on) Fast (off) 10-03-22_Test 25_1-2v1-3.mp4 21.06 28.18 5.44 12.47 20190128_113421.mp4 35.78 26.15 16.85 8.97 localhost-20181120_144618.mp4 131.26 251.78 89.44 182.65 rpi9-20210409_093149.mp4 103.46 212.26 28.57 123.90 test_cfr_h264.mp4 39.25 93.62 12.08 54.36 test_vfr_h264.mp4 31.48 77.59 12.07 50.65 Flags --index-pattern : sequential (0..N-1) or random indices. --use-sequential : on , off , or both to control sequential switching. --compare-fastvideo : include a FastVideoReader-like baseline. --threading : enable or disable decoder threading. --thread-count : explicit FFmpeg decoder thread count (0 = auto). --cache-size : LRU decoded-frame cache size (0 disables). --passes : repeat the same index list multiple times. --no-opencv : omit OpenCV timing and accuracy rows. --metric : embedded|pts|truth (default truth). --scrub-mode : previous|nearest|next (default nearest). --scrub-bucket-ms : scrub cache bucket (default 25).","title":"Benchmarking"},{"location":"benchmark/#run-on-your-own-videos","text":"# Single video python -m acvr.benchmarks /path/to/video.mp4 --metric truth --compare-fastvideo # All supported videos in a directory python -m acvr.benchmarks /path/to/videos --metric truth --compare-fastvideo The legacy wrapper python -m scripts.benchmark_reader is still supported.","title":"Run on your own videos"},{"location":"benchmark/#reproduce-bundled-results","text":"Run the benchmark on all bundled test assets: python -m acvr.benchmarks tests/data --metric truth --compare-fastvideo \\ --index-pattern sequential --use-sequential on --samples 120 --no-opencv Results (median ms/frame, local machine, PyAV 16.x): Video Sequential Accurate Accurate TL Scrub Fast FastVideo 10-03-22_Test 25_1-2v1-3.mp4 1.09 1.10 27.36 9.22 5.12 4.96 20190128_113421.mp4 1.37 1.37 37.13 37.51 1.44 1.39 localhost-20181120_144618.mp4 0.32 0.32 114.95 79.19 61.06 57.71 rpi9-20210409_093149.mp4 4.13 4.05 123.60 19.06 3.97 3.73 test_cfr_h264.mp4 0.29 0.28 24.34 5.37 0.28 0.27 test_vfr_h264.mp4 0.27 0.28 22.69 5.72 0.28 0.27 Sequential reads ( read_next / iteration) and use_sequential=True provide large speedups when accessing consecutive indices, bringing accurate and fast close to true sequential decode performance.","title":"Reproduce bundled results"},{"location":"benchmark/#lru-cache-impact","text":"The decoded-frame LRU ( decoded_frame_cache_size ) helps when you revisit the same indices repeatedly (e.g., UI scrubbing or repeated random samples). The benchmark below repeats the same random index list three times to amplify cache hits: # No cache python -m acvr.benchmarks tests/data/test_vfr_h264.mp4 --metric truth \\ --index-pattern random --use-sequential off --samples 200 --passes 3 \\ --cache-size 0 --no-opencv # LRU cache enabled python -m acvr.benchmarks tests/data/test_vfr_h264.mp4 --metric truth \\ --index-pattern random --use-sequential off --samples 200 --passes 3 \\ --cache-size 512 --no-opencv Results (median ms/frame, local machine, PyAV 16.x): Mode Cache=0 Cache=512 Fast 15.95 0.00 Scrub 6.08 0.01 Cached reads return immediately after the first pass, which is especially useful for repeated random access patterns.","title":"LRU cache impact"},{"location":"benchmark/#threading-impact","text":"Threading defaults to on and generally helps on H.264 assets, but some videos may decode faster with threading disabled. The benchmark below uses random indices and compares on vs off : python -m acvr.benchmarks tests/data --metric truth --compare-fastvideo \\ --index-pattern random --use-sequential on --samples 40 --no-opencv --threading on python -m acvr.benchmarks tests/data --metric truth --compare-fastvideo \\ --index-pattern random --use-sequential on --samples 40 --no-opencv --threading off Results (median ms/frame, local machine, PyAV 16.x, --samples 40 ): Video Accurate (on) Accurate (off) Fast (on) Fast (off) 10-03-22_Test 25_1-2v1-3.mp4 21.06 28.18 5.44 12.47 20190128_113421.mp4 35.78 26.15 16.85 8.97 localhost-20181120_144618.mp4 131.26 251.78 89.44 182.65 rpi9-20210409_093149.mp4 103.46 212.26 28.57 123.90 test_cfr_h264.mp4 39.25 93.62 12.08 54.36 test_vfr_h264.mp4 31.48 77.59 12.07 50.65","title":"Threading impact"},{"location":"benchmark/#flags","text":"--index-pattern : sequential (0..N-1) or random indices. --use-sequential : on , off , or both to control sequential switching. --compare-fastvideo : include a FastVideoReader-like baseline. --threading : enable or disable decoder threading. --thread-count : explicit FFmpeg decoder thread count (0 = auto). --cache-size : LRU decoded-frame cache size (0 disables). --passes : repeat the same index list multiple times. --no-opencv : omit OpenCV timing and accuracy rows. --metric : embedded|pts|truth (default truth). --scrub-mode : previous|nearest|next (default nearest). --scrub-bucket-ms : scrub cache bucket (default 25).","title":"Flags"},{"location":"indexing/","text":"This page explains how acvr interprets frame indices and how the different read modes trade off latency and precision, especially for variable-frame-rate (VFR) videos. Index policies acvr supports two ways to interpret an index i : decode: i refers to the decode-order frame number in the stream. This is exact and deterministic across reads. On constant-frame-rate (CFR) videos, decode-order aligns with the nominal timeline. On VFR videos, decode-order may differ from the nominal timeline. timeline: i is mapped to a timestamp using the nominal frame rate ( guessed_rate from PyAV when available). The reader then seeks accurately to the frame at/after that timestamp. This aligns better with the nominal timeline on VFR, but two assets with the same nominal rate might still differ due to encoder/gop structures. You can choose the policy for array-style access via: from acvr import VideoReader # Use timeline indexing globally for [] access (e.g., reader[100]) reader = VideoReader(path, index_policy=\"timeline\") frame = reader[100] # mapped via nominal FPS to timestamp Regardless of index_policy , you can always call mode-specific APIs. Read modes accurate: index is decode-order, or pass t_s to seek by timestamp. accurate_timeline: index is mapped to timestamp via nominal FPS; then performs the same accurate timestamp seeking as accurate . fast: approximate seek optimized for low latency; uses nominal timeline for good VFR alignment; exact on CFR for typical content. scrub: returns nearby keyframes; very fast and approximate; defaults to nearest keyframe and uses a small cache bucket for speed. sequential: decode in order using read_next or iteration; no seeking. Recommendations For full sequential processing (e.g., feature extraction), prefer read_next or for frame in reader , which uses the sequential decoder. CFR or strict decode-order tasks: use accurate (or default index_policy='decode' ). VFR and UI preview: use fast or scrub (nearest). For exact reads tied to nominal timeline, use accurate_timeline . If your project thinks in \u201ctimeline frames\u201d, set index_policy='timeline' on the reader to make reader[i] follow the nominal timeline.","title":"Indexing & Modes"},{"location":"indexing/#index-policies","text":"acvr supports two ways to interpret an index i : decode: i refers to the decode-order frame number in the stream. This is exact and deterministic across reads. On constant-frame-rate (CFR) videos, decode-order aligns with the nominal timeline. On VFR videos, decode-order may differ from the nominal timeline. timeline: i is mapped to a timestamp using the nominal frame rate ( guessed_rate from PyAV when available). The reader then seeks accurately to the frame at/after that timestamp. This aligns better with the nominal timeline on VFR, but two assets with the same nominal rate might still differ due to encoder/gop structures. You can choose the policy for array-style access via: from acvr import VideoReader # Use timeline indexing globally for [] access (e.g., reader[100]) reader = VideoReader(path, index_policy=\"timeline\") frame = reader[100] # mapped via nominal FPS to timestamp Regardless of index_policy , you can always call mode-specific APIs.","title":"Index policies"},{"location":"indexing/#read-modes","text":"accurate: index is decode-order, or pass t_s to seek by timestamp. accurate_timeline: index is mapped to timestamp via nominal FPS; then performs the same accurate timestamp seeking as accurate . fast: approximate seek optimized for low latency; uses nominal timeline for good VFR alignment; exact on CFR for typical content. scrub: returns nearby keyframes; very fast and approximate; defaults to nearest keyframe and uses a small cache bucket for speed. sequential: decode in order using read_next or iteration; no seeking.","title":"Read modes"},{"location":"indexing/#recommendations","text":"For full sequential processing (e.g., feature extraction), prefer read_next or for frame in reader , which uses the sequential decoder. CFR or strict decode-order tasks: use accurate (or default index_policy='decode' ). VFR and UI preview: use fast or scrub (nearest). For exact reads tied to nominal timeline, use accurate_timeline . If your project thinks in \u201ctimeline frames\u201d, set index_policy='timeline' on the reader to make reader[i] follow the nominal timeline.","title":"Recommendations"},{"location":"technical/","text":"This document explains how acvr achieves frame-accurate reads with PyAV/FFmpeg, why video access can be subtle, and how to choose the right mode for your workflow. It complements the \u201cUsage\u201d and \u201cIndexing & Modes\u201d docs with the underlying concepts. Core concepts Keyframes and GOPs Keyframes (I-frames) are independently decodable frames. Inter frames (P/B) depend on earlier (and sometimes later) frames. GOP (Group of Pictures) is the keyframe plus its dependent frames. Because P/B frames depend on context, random access to an arbitrary frame must first decode from a keyframe. Any \u201cseek-to-frame\u201d operation is therefore a combination of: Seek to a keyframe at or before the target. Decode forward until the target frame/time is reached. This is the root reason why na\u00efve random access can be slow or inaccurate in many video APIs. PTS, DTS, and time base PTS (Presentation Timestamp) is when a frame should appear on the timeline. DTS (Decoding Timestamp) is when a frame should be decoded. Time base is the unit in which PTS/DTS are expressed. acvr uses PyAV/FFmpeg\u2019s PTS values as the ground truth for time mapping. When PTS is missing, acvr falls back to DTS, and if both are missing it synthesizes monotonic timestamps during a full decode pass. The conversion is: time_s = (pts - start_pts) * time_base Because PTS is the authoritative timeline signal, acvr prefers PTS-based seeking rather than relying on frame index arithmetic alone. CFR vs VFR (constant vs variable frame rate) CFR : every frame advances the timeline by a constant duration. VFR : frame intervals vary; the nominal FPS is only an average. In VFR assets, \u201cframe 100\u201d does not necessarily map to 100 / fps seconds. The timeline is encoded in PTS values, not in frame counts. acvr therefore exposes two different indexing models: decode-order indexing and timeline-based indexing. Decode order vs timeline order Some codecs include B-frames, where decode order differs from presentation order. acvr relies on PTS to locate frames on the presentation timeline and separately maintains a decode-order index for deterministic frame-number reads. Indexing models in acvr Decode-order indexing Decode-order indexing treats index = 0 as \u201cfirst decoded frame\u201d and walks the stream in the order frames are produced. This is deterministic and exact for VideoReader[i] when index_policy=\"decode\" or when you use the accurate mode with an index. If you literally care about \u201cthe 100th decoded frame\u201d in a VFR asset, decode- order indexing is the right choice and does not require timestamps. acvr builds a decode-order lookup table ( frame_pts ) by decoding the stream once. This lets it map index \u2192 PTS reliably, even for VFR or B-frame content. Timeline indexing Timeline indexing treats index as a nominal frame on the timeline: t_s = index / nominal_fps The nominal FPS comes from guessed_rate when available (PyAV\u2019s best effort for VFR), falling back to average_rate or base_rate . Timeline indexing aligns better with \u201cframe N on the wall clock\u201d for VFR content, but it is still an approximation because the nominal FPS is not an exact timeline definition. For true timestamps, use read_frame_at(t_s) . Why random access can be inaccurate Random access is inherently approximate in many video APIs because: Keyframe seeking : decoders seek to a keyframe and decode forward, so returning the exact target depends on how the seek anchor is chosen. PTS rounding : timestamps are discrete in time_base units; mapping from seconds or indices can round up/down. VFR timelines : index / fps is not a reliable timestamp for VFR. B-frames : decode order differs from presentation order, so \u201cframe index\u201d is ambiguous without a defined model. acvr\u2019s accurate modes avoid these pitfalls by explicitly mapping index \u2192 PTS or timestamp \u2192 PTS and decoding forward from a keyframe anchor. Access modes and what they do Sequential (iteration / read_next) Purpose : fastest possible full pass. Mechanism : uses a dedicated sequential decoder, no seeks. Accuracy : exact decode order; ideal for dense processing pipelines. Accurate Input : index in decode order, or t_s for timestamp reads. Mechanism : resolve index \u2192 PTS, then keyframe-seek + decode forward. Accuracy : frame-accurate for decode-order indexing; robust on CFR/VFR. VideoReader[i] uses this behavior when index_policy=\"decode\" . Accurate timeline Input : index interpreted on nominal timeline, or t_s . Mechanism : map index \u2192 t_s via nominal FPS, then accurate timestamp seek. Accuracy : aligns with timeline on VFR better than decode-order indexing. Fast Input : index or t_s . Mechanism : approximate seek (PyAV/OpenCV-like) using nominal FPS. Accuracy : good for interactive previews; not guaranteed frame-accurate. Latency : lowest for random access. Scrub Input : index or t_s . Mechanism : returns keyframes only, using a cached bucketed keyframe map. Accuracy : approximate; best for thumbnails or timeline scrubbing. Dependency : requires a built keyframe index ( build_index=True ). Timeline access and index_policy VideoReader offers global indexing policy for reader[i] : index_policy=\"decode\" (default): i means decode-order frame index. index_policy=\"timeline\" : i means nominal timeline frame. Use timeline policy only when your application treats \u201cframe number\u201d as a position on a nominal timeline (e.g., UI frame counters for VFR content). Keyframe index and caches Keyframe index build_index=True triggers a full packet scan to record keyframe timestamps. This upfront cost can reduce per-seek latency because accurate modes can seek to the nearest known keyframe instead of the raw target timestamp. Frame cache acvr optionally caches decoded frames by PTS ( decoded_frame_cache_size ). This helps repeated access to nearby frames or repeated seeks to the same timestamp. Scrub bucket cache scrub_bucket_ms groups timestamps into coarse buckets for scrubbing. Smaller buckets improve precision at the cost of more cache churn. Practical guidance Need deterministic frame numbers? Use accurate with decode-order indexing or index_policy=\"decode\" . Need timeline-consistent reads on VFR? Use accurate_timeline or read_frame_at(t_s) . Interactive UI preview? Use fast or scrub (keyframes only). Batch processing? Use sequential iteration or read_next . Common pitfalls and how acvr avoids them Off-by-one frames : caused by rounding index \u2192 time or PTS rounding; accurate modes work in PTS units and return the first frame at/after target. Broken timestamps : some files have invalid PTS; acvr will raise if too many frames must be decoded to reach a timestamp ( max_decode_frames ). VFR confusion : decode-order indexing is not a timeline; use timeline modes when frame numbers are meant to track time. Choosing the right API read_frame_at(t_s) : best for exact timeline timestamp reads. read_frame(index=..., mode=\"accurate\") : exact decode-order access. read_frame(index=..., mode=\"accurate_timeline\") : timeline-aligned access. read_frame(index=..., mode=\"fast\") : low latency, approximate. read_frame(t_s=..., mode=\"scrub\") : keyframe scrubbing. read_next() / iteration: fastest sequential decode. For detailed usage examples, see docs/usage.md and docs/indexing.md .","title":"Technical"},{"location":"technical/#core-concepts","text":"","title":"Core concepts"},{"location":"technical/#keyframes-and-gops","text":"Keyframes (I-frames) are independently decodable frames. Inter frames (P/B) depend on earlier (and sometimes later) frames. GOP (Group of Pictures) is the keyframe plus its dependent frames. Because P/B frames depend on context, random access to an arbitrary frame must first decode from a keyframe. Any \u201cseek-to-frame\u201d operation is therefore a combination of: Seek to a keyframe at or before the target. Decode forward until the target frame/time is reached. This is the root reason why na\u00efve random access can be slow or inaccurate in many video APIs.","title":"Keyframes and GOPs"},{"location":"technical/#pts-dts-and-time-base","text":"PTS (Presentation Timestamp) is when a frame should appear on the timeline. DTS (Decoding Timestamp) is when a frame should be decoded. Time base is the unit in which PTS/DTS are expressed. acvr uses PyAV/FFmpeg\u2019s PTS values as the ground truth for time mapping. When PTS is missing, acvr falls back to DTS, and if both are missing it synthesizes monotonic timestamps during a full decode pass. The conversion is: time_s = (pts - start_pts) * time_base Because PTS is the authoritative timeline signal, acvr prefers PTS-based seeking rather than relying on frame index arithmetic alone.","title":"PTS, DTS, and time base"},{"location":"technical/#cfr-vs-vfr-constant-vs-variable-frame-rate","text":"CFR : every frame advances the timeline by a constant duration. VFR : frame intervals vary; the nominal FPS is only an average. In VFR assets, \u201cframe 100\u201d does not necessarily map to 100 / fps seconds. The timeline is encoded in PTS values, not in frame counts. acvr therefore exposes two different indexing models: decode-order indexing and timeline-based indexing.","title":"CFR vs VFR (constant vs variable frame rate)"},{"location":"technical/#decode-order-vs-timeline-order","text":"Some codecs include B-frames, where decode order differs from presentation order. acvr relies on PTS to locate frames on the presentation timeline and separately maintains a decode-order index for deterministic frame-number reads.","title":"Decode order vs timeline order"},{"location":"technical/#indexing-models-in-acvr","text":"","title":"Indexing models in acvr"},{"location":"technical/#decode-order-indexing","text":"Decode-order indexing treats index = 0 as \u201cfirst decoded frame\u201d and walks the stream in the order frames are produced. This is deterministic and exact for VideoReader[i] when index_policy=\"decode\" or when you use the accurate mode with an index. If you literally care about \u201cthe 100th decoded frame\u201d in a VFR asset, decode- order indexing is the right choice and does not require timestamps. acvr builds a decode-order lookup table ( frame_pts ) by decoding the stream once. This lets it map index \u2192 PTS reliably, even for VFR or B-frame content.","title":"Decode-order indexing"},{"location":"technical/#timeline-indexing","text":"Timeline indexing treats index as a nominal frame on the timeline: t_s = index / nominal_fps The nominal FPS comes from guessed_rate when available (PyAV\u2019s best effort for VFR), falling back to average_rate or base_rate . Timeline indexing aligns better with \u201cframe N on the wall clock\u201d for VFR content, but it is still an approximation because the nominal FPS is not an exact timeline definition. For true timestamps, use read_frame_at(t_s) .","title":"Timeline indexing"},{"location":"technical/#why-random-access-can-be-inaccurate","text":"Random access is inherently approximate in many video APIs because: Keyframe seeking : decoders seek to a keyframe and decode forward, so returning the exact target depends on how the seek anchor is chosen. PTS rounding : timestamps are discrete in time_base units; mapping from seconds or indices can round up/down. VFR timelines : index / fps is not a reliable timestamp for VFR. B-frames : decode order differs from presentation order, so \u201cframe index\u201d is ambiguous without a defined model. acvr\u2019s accurate modes avoid these pitfalls by explicitly mapping index \u2192 PTS or timestamp \u2192 PTS and decoding forward from a keyframe anchor.","title":"Why random access can be inaccurate"},{"location":"technical/#access-modes-and-what-they-do","text":"","title":"Access modes and what they do"},{"location":"technical/#sequential-iteration-read_next","text":"Purpose : fastest possible full pass. Mechanism : uses a dedicated sequential decoder, no seeks. Accuracy : exact decode order; ideal for dense processing pipelines.","title":"Sequential (iteration / read_next)"},{"location":"technical/#accurate","text":"Input : index in decode order, or t_s for timestamp reads. Mechanism : resolve index \u2192 PTS, then keyframe-seek + decode forward. Accuracy : frame-accurate for decode-order indexing; robust on CFR/VFR. VideoReader[i] uses this behavior when index_policy=\"decode\" .","title":"Accurate"},{"location":"technical/#accurate-timeline","text":"Input : index interpreted on nominal timeline, or t_s . Mechanism : map index \u2192 t_s via nominal FPS, then accurate timestamp seek. Accuracy : aligns with timeline on VFR better than decode-order indexing.","title":"Accurate timeline"},{"location":"technical/#fast","text":"Input : index or t_s . Mechanism : approximate seek (PyAV/OpenCV-like) using nominal FPS. Accuracy : good for interactive previews; not guaranteed frame-accurate. Latency : lowest for random access.","title":"Fast"},{"location":"technical/#scrub","text":"Input : index or t_s . Mechanism : returns keyframes only, using a cached bucketed keyframe map. Accuracy : approximate; best for thumbnails or timeline scrubbing. Dependency : requires a built keyframe index ( build_index=True ).","title":"Scrub"},{"location":"technical/#timeline-access-and-index_policy","text":"VideoReader offers global indexing policy for reader[i] : index_policy=\"decode\" (default): i means decode-order frame index. index_policy=\"timeline\" : i means nominal timeline frame. Use timeline policy only when your application treats \u201cframe number\u201d as a position on a nominal timeline (e.g., UI frame counters for VFR content).","title":"Timeline access and index_policy"},{"location":"technical/#keyframe-index-and-caches","text":"","title":"Keyframe index and caches"},{"location":"technical/#keyframe-index","text":"build_index=True triggers a full packet scan to record keyframe timestamps. This upfront cost can reduce per-seek latency because accurate modes can seek to the nearest known keyframe instead of the raw target timestamp.","title":"Keyframe index"},{"location":"technical/#frame-cache","text":"acvr optionally caches decoded frames by PTS ( decoded_frame_cache_size ). This helps repeated access to nearby frames or repeated seeks to the same timestamp.","title":"Frame cache"},{"location":"technical/#scrub-bucket-cache","text":"scrub_bucket_ms groups timestamps into coarse buckets for scrubbing. Smaller buckets improve precision at the cost of more cache churn.","title":"Scrub bucket cache"},{"location":"technical/#practical-guidance","text":"Need deterministic frame numbers? Use accurate with decode-order indexing or index_policy=\"decode\" . Need timeline-consistent reads on VFR? Use accurate_timeline or read_frame_at(t_s) . Interactive UI preview? Use fast or scrub (keyframes only). Batch processing? Use sequential iteration or read_next .","title":"Practical guidance"},{"location":"technical/#common-pitfalls-and-how-acvr-avoids-them","text":"Off-by-one frames : caused by rounding index \u2192 time or PTS rounding; accurate modes work in PTS units and return the first frame at/after target. Broken timestamps : some files have invalid PTS; acvr will raise if too many frames must be decoded to reach a timestamp ( max_decode_frames ). VFR confusion : decode-order indexing is not a timeline; use timeline modes when frame numbers are meant to track time.","title":"Common pitfalls and how acvr avoids them"},{"location":"technical/#choosing-the-right-api","text":"read_frame_at(t_s) : best for exact timeline timestamp reads. read_frame(index=..., mode=\"accurate\") : exact decode-order access. read_frame(index=..., mode=\"accurate_timeline\") : timeline-aligned access. read_frame(index=..., mode=\"fast\") : low latency, approximate. read_frame(t_s=..., mode=\"scrub\") : keyframe scrubbing. read_next() / iteration: fastest sequential decode. For detailed usage examples, see docs/usage.md and docs/indexing.md .","title":"Choosing the right API"},{"location":"usage/","text":"Basic access from acvr import VideoReader with VideoReader(\"/path/to/video.mp4\") as reader: frame = reader[100] print(reader.frame_rate) Iteration from acvr import VideoReader reader = VideoReader(\"/path/to/video.mp4\") for frame in reader: # process frame pass reader.close() Iteration uses the sequential decoder internally, which is much faster than per-frame seeks when you are processing the video in order. Sequential reads Sequential reads are the fastest path for in-order decoding. Restart the sequential decoder by creating a new reader. from acvr import VideoReader reader = VideoReader(\"/path/to/video.mp4\") frame0 = reader.read_next() frame1 = reader.read_next() reader.close() Sequential reads decode the next frame in the stream without seeking. Use them for dense, in-order processing pipelines (e.g., feature extraction, encoding). Accurate timestamp reads from acvr import VideoReader reader = VideoReader(\"/path/to/video.mp4\") frame = reader.read_frame_at(1.25) reader.close() Fast scrubbing Keyframe reads default to the nearest keyframe. from acvr import VideoReader reader = VideoReader(\"/path/to/video.mp4\") keyframe = reader.read_keyframe_at(2.0) reader.close() Selectable read modes Pick the access mode depending on accuracy and latency needs. from acvr import VideoReader reader = VideoReader(\"/path/to/video.mp4\") frame = reader.read_frame(index=120, mode=\"accurate\") frame_tl = reader.read_frame(index=120, mode=\"accurate_timeline\") frame = reader.read_frame(index=120, mode=\"fast\") frame = reader.read_frame(t_s=2.0, mode=\"scrub\") frame = reader.read_frame(index=121, mode=\"fast\", use_sequential=True) reader.close() Scrub tuning For tighter scrub accuracy, use nearest mode (default) and a smaller bucket. Smaller buckets improve precision but may increase memory churn. from acvr import VideoReader reader = VideoReader(\"/path/to/video.mp4\", scrub_bucket_ms=25) keyframe = reader.read_keyframe_at(1.5) preview = reader.read_frame(t_s=1.5, mode=\"scrub\") reader.close() Color conversion and performance All modes decode RGB by default for consistent pixel values. To squeeze out a small performance gain, set decode_rgb=False on read_frame/read_frame_fast/ read_keyframe_at to avoid RGB conversion. This typically improves speed marginally and returns BGR for fast paths. from acvr import VideoReader reader = VideoReader(\"/path/to/video.mp4\") frame = reader.read_frame(index=120, mode=\"fast\", decode_rgb=False) reader.close() Global indexing policy If your application thinks in timeline frames, [] indexing can use the nominal timeline mapping globally. from acvr import VideoReader reader = VideoReader(\"/path/to/video.mp4\", index_policy=\"timeline\") frame_100 = reader[100] reader.close() Indexing semantics: decode-order vs timeline accurate: index refers to decode-order frame number (exact on CFR; may differ from nominal timeline on VFR). Use when you need deterministic decode positions. accurate_timeline: index is mapped to timestamp using nominal FPS (guessed_rate), then the nearest frame at/after that timestamp is returned (better alignment on VFR assets). fast: approximate, timeline-oriented path with very low latency; aligns well with nominal timeline on VFR. scrub: returns keyframes only; very fast and approximate for preview. Sequential switching read_frame and read_frame_fast default to use_sequential=True , which means they switch to the sequential decoder when indices are consecutive. This preserves accuracy while avoiding per-frame seeks in ordered workloads. Disable it if you are mixing random and sequential access and want consistent seek behavior. See also: the \"Indexing & Modes\" page for a fuller discussion and recommendations. Choosing a read mode Sequential ( read_next or iteration): fastest for contiguous reads; no seeking. Accurate: exact decode-order frame access; use for deterministic per-frame analysis. Accurate timeline: aligns indices to nominal FPS timestamps; preferred for VFR timeline analysis. Fast: low-latency approximation; good for interactive previews. Scrub: keyframes only; best for rapid skimming/thumbnail previews. Benchmarking See the Benchmarking page for the full benchmark suite and reproducible runs: https://janclemenslab.org/acvr/benchmark/. Index build cost and random seeks build_index (default True) performs a full packet scan to build a keyframe index up front. That scan cost scales with video duration/bitrate, but it lets accurate modes seek from the nearest keyframe instead of from the requested PTS. That reduces decode work per random seek in accurate (index-based) and accurate_timeline modes, and it is required for scrub reads. Use the benchmark script below to quantify the tradeoff on your assets: python scripts/benchmark_index_build.py --samples 40 --max-frame-index 3000 It prints a Markdown table with per-video init time (with/without index), index build cost, and per-mode median read latency. Results are machine- and storage- dependent; regenerate them after hardware or codec changes. Benchmark (Mac M1, sample=40, max-frame-index=3000): | Video | Build index | Init (ms) | Build index (ms) | Accurate (ms/frame) | Accurate_tl (ms/frame) | Fast (ms/frame) | Scrub (ms/frame) | | --- | --- | --- | --- | --- | --- | --- | --- | | 10-03-22_Test 25_1-2v1-3.mp4 | no | 21.78 | n/a | 21.93 | 28.00 | 5.99 | n/a | | 10-03-22_Test 25_1-2v1-3.mp4 | yes | 149.02 | 124.15 | 22.00 | 29.23 | 5.95 | 8.78 | | 20190128_113421.mp4 | no | 19.52 | n/a | 37.96 | 38.07 | 17.59 | n/a | | 20190128_113421.mp4 | yes | 86.55 | 77.03 | 38.00 | 38.46 | 18.06 | 40.53 | | localhost-20181120_144618.mp4 | no | 40.06 | n/a | 151.87 | 157.86 | 88.62 | n/a | | localhost-20181120_144618.mp4 | yes | 286.39 | 176.90 | 135.79 | 138.40 | 84.34 | 89.11 | | rpi9-20210409_093149.mp4 | no | 5.21 | n/a | 108.27 | 105.72 | 29.59 | n/a | | rpi9-20210409_093149.mp4 | yes | 203.04 | 64.61 | 100.80 | 105.79 | 30.31 | 23.68 | | test_cfr_h264.mp4 | no | 3.08 | n/a | 46.78 | 49.50 | 14.24 | n/a | | test_cfr_h264.mp4 | yes | 24.08 | 19.01 | 42.60 | 43.40 | 14.99 | 9.49 | | test_noindex_h264.mp4 | no | 9.04 | n/a | 42.95 | 46.57 | 13.94 | n/a | | test_noindex_h264.mp4 | yes | 22.41 | 19.26 | 46.74 | 45.87 | 13.93 | 9.74 | | test_vfr_h264.mp4 | no | 3.19 | n/a | 46.77 | 49.32 | 14.92 | n/a | | test_vfr_h264.mp4 | yes | 21.84 | 18.17 | 43.71 | 48.36 | 17.26 | 11.04 | Decision checklist: - Enable build_index=True when you need scrub reads or you will issue many random accurate / accurate_timeline seeks on longer clips. - Keep build_index=False for one-off reads, short clips, or when startup latency matters more than per-seek speed.","title":"Usage"},{"location":"usage/#basic-access","text":"from acvr import VideoReader with VideoReader(\"/path/to/video.mp4\") as reader: frame = reader[100] print(reader.frame_rate)","title":"Basic access"},{"location":"usage/#iteration","text":"from acvr import VideoReader reader = VideoReader(\"/path/to/video.mp4\") for frame in reader: # process frame pass reader.close() Iteration uses the sequential decoder internally, which is much faster than per-frame seeks when you are processing the video in order.","title":"Iteration"},{"location":"usage/#sequential-reads","text":"Sequential reads are the fastest path for in-order decoding. Restart the sequential decoder by creating a new reader. from acvr import VideoReader reader = VideoReader(\"/path/to/video.mp4\") frame0 = reader.read_next() frame1 = reader.read_next() reader.close() Sequential reads decode the next frame in the stream without seeking. Use them for dense, in-order processing pipelines (e.g., feature extraction, encoding).","title":"Sequential reads"},{"location":"usage/#accurate-timestamp-reads","text":"from acvr import VideoReader reader = VideoReader(\"/path/to/video.mp4\") frame = reader.read_frame_at(1.25) reader.close()","title":"Accurate timestamp reads"},{"location":"usage/#fast-scrubbing","text":"Keyframe reads default to the nearest keyframe. from acvr import VideoReader reader = VideoReader(\"/path/to/video.mp4\") keyframe = reader.read_keyframe_at(2.0) reader.close()","title":"Fast scrubbing"},{"location":"usage/#selectable-read-modes","text":"Pick the access mode depending on accuracy and latency needs. from acvr import VideoReader reader = VideoReader(\"/path/to/video.mp4\") frame = reader.read_frame(index=120, mode=\"accurate\") frame_tl = reader.read_frame(index=120, mode=\"accurate_timeline\") frame = reader.read_frame(index=120, mode=\"fast\") frame = reader.read_frame(t_s=2.0, mode=\"scrub\") frame = reader.read_frame(index=121, mode=\"fast\", use_sequential=True) reader.close()","title":"Selectable read modes"},{"location":"usage/#scrub-tuning","text":"For tighter scrub accuracy, use nearest mode (default) and a smaller bucket. Smaller buckets improve precision but may increase memory churn. from acvr import VideoReader reader = VideoReader(\"/path/to/video.mp4\", scrub_bucket_ms=25) keyframe = reader.read_keyframe_at(1.5) preview = reader.read_frame(t_s=1.5, mode=\"scrub\") reader.close()","title":"Scrub tuning"},{"location":"usage/#color-conversion-and-performance","text":"All modes decode RGB by default for consistent pixel values. To squeeze out a small performance gain, set decode_rgb=False on read_frame/read_frame_fast/ read_keyframe_at to avoid RGB conversion. This typically improves speed marginally and returns BGR for fast paths. from acvr import VideoReader reader = VideoReader(\"/path/to/video.mp4\") frame = reader.read_frame(index=120, mode=\"fast\", decode_rgb=False) reader.close()","title":"Color conversion and performance"},{"location":"usage/#global-indexing-policy","text":"If your application thinks in timeline frames, [] indexing can use the nominal timeline mapping globally. from acvr import VideoReader reader = VideoReader(\"/path/to/video.mp4\", index_policy=\"timeline\") frame_100 = reader[100] reader.close()","title":"Global indexing policy"},{"location":"usage/#indexing-semantics-decode-order-vs-timeline","text":"accurate: index refers to decode-order frame number (exact on CFR; may differ from nominal timeline on VFR). Use when you need deterministic decode positions. accurate_timeline: index is mapped to timestamp using nominal FPS (guessed_rate), then the nearest frame at/after that timestamp is returned (better alignment on VFR assets). fast: approximate, timeline-oriented path with very low latency; aligns well with nominal timeline on VFR. scrub: returns keyframes only; very fast and approximate for preview.","title":"Indexing semantics: decode-order vs timeline"},{"location":"usage/#sequential-switching","text":"read_frame and read_frame_fast default to use_sequential=True , which means they switch to the sequential decoder when indices are consecutive. This preserves accuracy while avoiding per-frame seeks in ordered workloads. Disable it if you are mixing random and sequential access and want consistent seek behavior. See also: the \"Indexing & Modes\" page for a fuller discussion and recommendations.","title":"Sequential switching"},{"location":"usage/#choosing-a-read-mode","text":"Sequential ( read_next or iteration): fastest for contiguous reads; no seeking. Accurate: exact decode-order frame access; use for deterministic per-frame analysis. Accurate timeline: aligns indices to nominal FPS timestamps; preferred for VFR timeline analysis. Fast: low-latency approximation; good for interactive previews. Scrub: keyframes only; best for rapid skimming/thumbnail previews.","title":"Choosing a read mode"},{"location":"usage/#benchmarking","text":"See the Benchmarking page for the full benchmark suite and reproducible runs: https://janclemenslab.org/acvr/benchmark/.","title":"Benchmarking"},{"location":"usage/#index-build-cost-and-random-seeks","text":"build_index (default True) performs a full packet scan to build a keyframe index up front. That scan cost scales with video duration/bitrate, but it lets accurate modes seek from the nearest keyframe instead of from the requested PTS. That reduces decode work per random seek in accurate (index-based) and accurate_timeline modes, and it is required for scrub reads. Use the benchmark script below to quantify the tradeoff on your assets: python scripts/benchmark_index_build.py --samples 40 --max-frame-index 3000 It prints a Markdown table with per-video init time (with/without index), index build cost, and per-mode median read latency. Results are machine- and storage- dependent; regenerate them after hardware or codec changes. Benchmark (Mac M1, sample=40, max-frame-index=3000): | Video | Build index | Init (ms) | Build index (ms) | Accurate (ms/frame) | Accurate_tl (ms/frame) | Fast (ms/frame) | Scrub (ms/frame) | | --- | --- | --- | --- | --- | --- | --- | --- | | 10-03-22_Test 25_1-2v1-3.mp4 | no | 21.78 | n/a | 21.93 | 28.00 | 5.99 | n/a | | 10-03-22_Test 25_1-2v1-3.mp4 | yes | 149.02 | 124.15 | 22.00 | 29.23 | 5.95 | 8.78 | | 20190128_113421.mp4 | no | 19.52 | n/a | 37.96 | 38.07 | 17.59 | n/a | | 20190128_113421.mp4 | yes | 86.55 | 77.03 | 38.00 | 38.46 | 18.06 | 40.53 | | localhost-20181120_144618.mp4 | no | 40.06 | n/a | 151.87 | 157.86 | 88.62 | n/a | | localhost-20181120_144618.mp4 | yes | 286.39 | 176.90 | 135.79 | 138.40 | 84.34 | 89.11 | | rpi9-20210409_093149.mp4 | no | 5.21 | n/a | 108.27 | 105.72 | 29.59 | n/a | | rpi9-20210409_093149.mp4 | yes | 203.04 | 64.61 | 100.80 | 105.79 | 30.31 | 23.68 | | test_cfr_h264.mp4 | no | 3.08 | n/a | 46.78 | 49.50 | 14.24 | n/a | | test_cfr_h264.mp4 | yes | 24.08 | 19.01 | 42.60 | 43.40 | 14.99 | 9.49 | | test_noindex_h264.mp4 | no | 9.04 | n/a | 42.95 | 46.57 | 13.94 | n/a | | test_noindex_h264.mp4 | yes | 22.41 | 19.26 | 46.74 | 45.87 | 13.93 | 9.74 | | test_vfr_h264.mp4 | no | 3.19 | n/a | 46.77 | 49.32 | 14.92 | n/a | | test_vfr_h264.mp4 | yes | 21.84 | 18.17 | 43.71 | 48.36 | 17.26 | 11.04 | Decision checklist: - Enable build_index=True when you need scrub reads or you will issue many random accurate / accurate_timeline seeks on longer clips. - Keep build_index=False for one-off reads, short clips, or when startup latency matters more than per-seek speed.","title":"Index build cost and random seeks"}]}